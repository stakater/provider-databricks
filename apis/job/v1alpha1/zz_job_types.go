// SPDX-FileCopyrightText: 2023 The Crossplane Authors <https://crossplane.io>
//
// SPDX-License-Identifier: Apache-2.0

/*
Copyright 2022 Upbound Inc.
*/

// Code generated by upjet. DO NOT EDIT.

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type AbfssInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type AbfssObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type AbfssParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type AlertInitParameters struct {

	// (String) identifier of the Databricks SQL Alert.
	AlertID *string `json:"alertId,omitempty" tf:"alert_id,omitempty"`

	// flag that specifies if subscriptions are paused or not.
	PauseSubscriptions *bool `json:"pauseSubscriptions,omitempty" tf:"pause_subscriptions,omitempty"`

	// a list of subscription blocks consisting out of one of the required fields: user_name for user emails or destination_id - for Alert destination's identifier.
	Subscriptions []SubscriptionsInitParameters `json:"subscriptions,omitempty" tf:"subscriptions,omitempty"`
}

type AlertObservation struct {

	// (String) identifier of the Databricks SQL Alert.
	AlertID *string `json:"alertId,omitempty" tf:"alert_id,omitempty"`

	// flag that specifies if subscriptions are paused or not.
	PauseSubscriptions *bool `json:"pauseSubscriptions,omitempty" tf:"pause_subscriptions,omitempty"`

	// a list of subscription blocks consisting out of one of the required fields: user_name for user emails or destination_id - for Alert destination's identifier.
	Subscriptions []SubscriptionsObservation `json:"subscriptions,omitempty" tf:"subscriptions,omitempty"`
}

type AlertParameters struct {

	// (String) identifier of the Databricks SQL Alert.
	// +kubebuilder:validation:Optional
	AlertID *string `json:"alertId" tf:"alert_id,omitempty"`

	// flag that specifies if subscriptions are paused or not.
	// +kubebuilder:validation:Optional
	PauseSubscriptions *bool `json:"pauseSubscriptions,omitempty" tf:"pause_subscriptions,omitempty"`

	// a list of subscription blocks consisting out of one of the required fields: user_name for user emails or destination_id - for Alert destination's identifier.
	// +kubebuilder:validation:Optional
	Subscriptions []SubscriptionsParameters `json:"subscriptions" tf:"subscriptions,omitempty"`
}

type AlertSubscriptionsInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DestinationID *string `json:"destinationId,omitempty" tf:"destination_id,omitempty"`

	// The email of an active workspace user. Non-admin users can only set this field to their own email.
	UserName *string `json:"userName,omitempty" tf:"user_name,omitempty"`
}

type AlertSubscriptionsObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DestinationID *string `json:"destinationId,omitempty" tf:"destination_id,omitempty"`

	// The email of an active workspace user. Non-admin users can only set this field to their own email.
	UserName *string `json:"userName,omitempty" tf:"user_name,omitempty"`
}

type AlertSubscriptionsParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	DestinationID *string `json:"destinationId,omitempty" tf:"destination_id,omitempty"`

	// The email of an active workspace user. Non-admin users can only set this field to their own email.
	// +kubebuilder:validation:Optional
	UserName *string `json:"userName,omitempty" tf:"user_name,omitempty"`
}

type AutoscaleInitParameters struct {
	MaxWorkers *float64 `json:"maxWorkers,omitempty" tf:"max_workers,omitempty"`

	MinWorkers *float64 `json:"minWorkers,omitempty" tf:"min_workers,omitempty"`
}

type AutoscaleObservation struct {
	MaxWorkers *float64 `json:"maxWorkers,omitempty" tf:"max_workers,omitempty"`

	MinWorkers *float64 `json:"minWorkers,omitempty" tf:"min_workers,omitempty"`
}

type AutoscaleParameters struct {

	// +kubebuilder:validation:Optional
	MaxWorkers *float64 `json:"maxWorkers,omitempty" tf:"max_workers,omitempty"`

	// +kubebuilder:validation:Optional
	MinWorkers *float64 `json:"minWorkers,omitempty" tf:"min_workers,omitempty"`
}

type AwsAttributesInitParameters struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	EBSVolumeCount *float64 `json:"ebsVolumeCount,omitempty" tf:"ebs_volume_count,omitempty"`

	EBSVolumeSize *float64 `json:"ebsVolumeSize,omitempty" tf:"ebs_volume_size,omitempty"`

	EBSVolumeType *string `json:"ebsVolumeType,omitempty" tf:"ebs_volume_type,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	InstanceProfileArn *string `json:"instanceProfileArn,omitempty" tf:"instance_profile_arn,omitempty"`

	SpotBidPricePercent *float64 `json:"spotBidPricePercent,omitempty" tf:"spot_bid_price_percent,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type AwsAttributesObservation struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	EBSVolumeCount *float64 `json:"ebsVolumeCount,omitempty" tf:"ebs_volume_count,omitempty"`

	EBSVolumeSize *float64 `json:"ebsVolumeSize,omitempty" tf:"ebs_volume_size,omitempty"`

	EBSVolumeType *string `json:"ebsVolumeType,omitempty" tf:"ebs_volume_type,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	InstanceProfileArn *string `json:"instanceProfileArn,omitempty" tf:"instance_profile_arn,omitempty"`

	SpotBidPricePercent *float64 `json:"spotBidPricePercent,omitempty" tf:"spot_bid_price_percent,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type AwsAttributesParameters struct {

	// +kubebuilder:validation:Optional
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	// +kubebuilder:validation:Optional
	EBSVolumeCount *float64 `json:"ebsVolumeCount,omitempty" tf:"ebs_volume_count,omitempty"`

	// +kubebuilder:validation:Optional
	EBSVolumeSize *float64 `json:"ebsVolumeSize,omitempty" tf:"ebs_volume_size,omitempty"`

	// +kubebuilder:validation:Optional
	EBSVolumeType *string `json:"ebsVolumeType,omitempty" tf:"ebs_volume_type,omitempty"`

	// +kubebuilder:validation:Optional
	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	// +kubebuilder:validation:Optional
	InstanceProfileArn *string `json:"instanceProfileArn,omitempty" tf:"instance_profile_arn,omitempty"`

	// +kubebuilder:validation:Optional
	SpotBidPricePercent *float64 `json:"spotBidPricePercent,omitempty" tf:"spot_bid_price_percent,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type AzureAttributesInitParameters struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	SpotBidMaxPrice *float64 `json:"spotBidMaxPrice,omitempty" tf:"spot_bid_max_price,omitempty"`
}

type AzureAttributesObservation struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	SpotBidMaxPrice *float64 `json:"spotBidMaxPrice,omitempty" tf:"spot_bid_max_price,omitempty"`
}

type AzureAttributesParameters struct {

	// +kubebuilder:validation:Optional
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	// +kubebuilder:validation:Optional
	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	// +kubebuilder:validation:Optional
	SpotBidMaxPrice *float64 `json:"spotBidMaxPrice,omitempty" tf:"spot_bid_max_price,omitempty"`
}

type BasicAuthInitParameters struct {

	// An optional name for the job. The default value is Untitled.
	Username *string `json:"username,omitempty" tf:"username,omitempty"`
}

type BasicAuthObservation struct {

	// An optional name for the job. The default value is Untitled.
	Username *string `json:"username,omitempty" tf:"username,omitempty"`
}

type BasicAuthParameters struct {

	// +kubebuilder:validation:Required
	PasswordSecretRef v1.SecretKeySelector `json:"passwordSecretRef" tf:"-"`

	// An optional name for the job. The default value is Untitled.
	// +kubebuilder:validation:Optional
	Username *string `json:"username" tf:"username,omitempty"`
}

type ClientsInitParameters struct {
	Jobs *bool `json:"jobs,omitempty" tf:"jobs,omitempty"`

	Notebooks *bool `json:"notebooks,omitempty" tf:"notebooks,omitempty"`
}

type ClientsObservation struct {
	Jobs *bool `json:"jobs,omitempty" tf:"jobs,omitempty"`

	Notebooks *bool `json:"notebooks,omitempty" tf:"notebooks,omitempty"`
}

type ClientsParameters struct {

	// +kubebuilder:validation:Optional
	Jobs *bool `json:"jobs,omitempty" tf:"jobs,omitempty"`

	// +kubebuilder:validation:Optional
	Notebooks *bool `json:"notebooks,omitempty" tf:"notebooks,omitempty"`
}

type ClusterLogConfDbfsInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type ClusterLogConfDbfsObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type ClusterLogConfDbfsParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type ClusterLogConfInitParameters struct {
	Dbfs []DbfsInitParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	S3 []S3InitParameters `json:"s3,omitempty" tf:"s3,omitempty"`
}

type ClusterLogConfObservation struct {
	Dbfs []DbfsObservation `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	S3 []S3Observation `json:"s3,omitempty" tf:"s3,omitempty"`
}

type ClusterLogConfParameters struct {

	// +kubebuilder:validation:Optional
	Dbfs []DbfsParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// +kubebuilder:validation:Optional
	S3 []S3Parameters `json:"s3,omitempty" tf:"s3,omitempty"`
}

type ClusterLogConfS3InitParameters struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type ClusterLogConfS3Observation struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type ClusterLogConfS3Parameters struct {

	// +kubebuilder:validation:Optional
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`

	// +kubebuilder:validation:Optional
	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	// +kubebuilder:validation:Optional
	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	// +kubebuilder:validation:Optional
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// +kubebuilder:validation:Optional
	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	// +kubebuilder:validation:Optional
	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type ClusterMountInfoInitParameters struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	LocalMountDirPath *string `json:"localMountDirPath,omitempty" tf:"local_mount_dir_path,omitempty"`

	NetworkFilesystemInfo []NetworkFilesystemInfoInitParameters `json:"networkFilesystemInfo,omitempty" tf:"network_filesystem_info,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	RemoteMountDirPath *string `json:"remoteMountDirPath,omitempty" tf:"remote_mount_dir_path,omitempty"`
}

type ClusterMountInfoNetworkFilesystemInfoInitParameters struct {
	MountOptions *string `json:"mountOptions,omitempty" tf:"mount_options,omitempty"`

	ServerAddress *string `json:"serverAddress,omitempty" tf:"server_address,omitempty"`
}

type ClusterMountInfoNetworkFilesystemInfoObservation struct {
	MountOptions *string `json:"mountOptions,omitempty" tf:"mount_options,omitempty"`

	ServerAddress *string `json:"serverAddress,omitempty" tf:"server_address,omitempty"`
}

type ClusterMountInfoNetworkFilesystemInfoParameters struct {

	// +kubebuilder:validation:Optional
	MountOptions *string `json:"mountOptions,omitempty" tf:"mount_options,omitempty"`

	// +kubebuilder:validation:Optional
	ServerAddress *string `json:"serverAddress" tf:"server_address,omitempty"`
}

type ClusterMountInfoObservation struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	LocalMountDirPath *string `json:"localMountDirPath,omitempty" tf:"local_mount_dir_path,omitempty"`

	NetworkFilesystemInfo []NetworkFilesystemInfoObservation `json:"networkFilesystemInfo,omitempty" tf:"network_filesystem_info,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	RemoteMountDirPath *string `json:"remoteMountDirPath,omitempty" tf:"remote_mount_dir_path,omitempty"`
}

type ClusterMountInfoParameters struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	// +kubebuilder:validation:Optional
	LocalMountDirPath *string `json:"localMountDirPath" tf:"local_mount_dir_path,omitempty"`

	// +kubebuilder:validation:Optional
	NetworkFilesystemInfo []NetworkFilesystemInfoParameters `json:"networkFilesystemInfo" tf:"network_filesystem_info,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	// +kubebuilder:validation:Optional
	RemoteMountDirPath *string `json:"remoteMountDirPath,omitempty" tf:"remote_mount_dir_path,omitempty"`
}

type ComputeInitParameters struct {
	ComputeKey *string `json:"computeKey,omitempty" tf:"compute_key,omitempty"`

	Spec []SpecInitParameters `json:"spec,omitempty" tf:"spec,omitempty"`
}

type ComputeObservation struct {
	ComputeKey *string `json:"computeKey,omitempty" tf:"compute_key,omitempty"`

	Spec []SpecObservation `json:"spec,omitempty" tf:"spec,omitempty"`
}

type ComputeParameters struct {

	// +kubebuilder:validation:Optional
	ComputeKey *string `json:"computeKey,omitempty" tf:"compute_key,omitempty"`

	// +kubebuilder:validation:Optional
	Spec []SpecParameters `json:"spec,omitempty" tf:"spec,omitempty"`
}

type ConditionTaskInitParameters struct {

	// The left operand of the condition task. It could be a string value, job state, or a parameter reference.
	Left *string `json:"left,omitempty" tf:"left,omitempty"`

	// string specifying the operation used to evaluate the given metric. The only supported operation is GREATER_THAN.
	Op *string `json:"op,omitempty" tf:"op,omitempty"`

	// The right operand of the condition task. It could be a string value, job state, or parameter reference.
	Right *string `json:"right,omitempty" tf:"right,omitempty"`
}

type ConditionTaskObservation struct {

	// The left operand of the condition task. It could be a string value, job state, or a parameter reference.
	Left *string `json:"left,omitempty" tf:"left,omitempty"`

	// string specifying the operation used to evaluate the given metric. The only supported operation is GREATER_THAN.
	Op *string `json:"op,omitempty" tf:"op,omitempty"`

	// The right operand of the condition task. It could be a string value, job state, or parameter reference.
	Right *string `json:"right,omitempty" tf:"right,omitempty"`
}

type ConditionTaskParameters struct {

	// The left operand of the condition task. It could be a string value, job state, or a parameter reference.
	// +kubebuilder:validation:Optional
	Left *string `json:"left,omitempty" tf:"left,omitempty"`

	// string specifying the operation used to evaluate the given metric. The only supported operation is GREATER_THAN.
	// +kubebuilder:validation:Optional
	Op *string `json:"op,omitempty" tf:"op,omitempty"`

	// The right operand of the condition task. It could be a string value, job state, or parameter reference.
	// +kubebuilder:validation:Optional
	Right *string `json:"right,omitempty" tf:"right,omitempty"`
}

type ContinuousInitParameters struct {

	// Indicate whether this schedule is paused or not. Either PAUSED or UNPAUSED. When the pause_status field is omitted and a schedule is provided, the server will default to using UNPAUSED as a value for pause_status.
	PauseStatus *string `json:"pauseStatus,omitempty" tf:"pause_status,omitempty"`
}

type ContinuousObservation struct {

	// Indicate whether this schedule is paused or not. Either PAUSED or UNPAUSED. When the pause_status field is omitted and a schedule is provided, the server will default to using UNPAUSED as a value for pause_status.
	PauseStatus *string `json:"pauseStatus,omitempty" tf:"pause_status,omitempty"`
}

type ContinuousParameters struct {

	// Indicate whether this schedule is paused or not. Either PAUSED or UNPAUSED. When the pause_status field is omitted and a schedule is provided, the server will default to using UNPAUSED as a value for pause_status.
	// +kubebuilder:validation:Optional
	PauseStatus *string `json:"pauseStatus,omitempty" tf:"pause_status,omitempty"`
}

type CranInitParameters struct {
	Package *string `json:"package,omitempty" tf:"package,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type CranObservation struct {
	Package *string `json:"package,omitempty" tf:"package,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type CranParameters struct {

	// +kubebuilder:validation:Optional
	Package *string `json:"package" tf:"package,omitempty"`

	// +kubebuilder:validation:Optional
	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type DashboardInitParameters struct {

	// string specifying a custom subject of email sent.
	CustomSubject *string `json:"customSubject,omitempty" tf:"custom_subject,omitempty"`

	// (String) identifier of the Databricks SQL Dashboard databricks_sql_dashboard.
	DashboardID *string `json:"dashboardId,omitempty" tf:"dashboard_id,omitempty"`

	// flag that specifies if subscriptions are paused or not.
	PauseSubscriptions *bool `json:"pauseSubscriptions,omitempty" tf:"pause_subscriptions,omitempty"`

	// a list of subscription blocks consisting out of one of the required fields: user_name for user emails or destination_id - for Alert destination's identifier.
	Subscriptions []DashboardSubscriptionsInitParameters `json:"subscriptions,omitempty" tf:"subscriptions,omitempty"`
}

type DashboardObservation struct {

	// string specifying a custom subject of email sent.
	CustomSubject *string `json:"customSubject,omitempty" tf:"custom_subject,omitempty"`

	// (String) identifier of the Databricks SQL Dashboard databricks_sql_dashboard.
	DashboardID *string `json:"dashboardId,omitempty" tf:"dashboard_id,omitempty"`

	// flag that specifies if subscriptions are paused or not.
	PauseSubscriptions *bool `json:"pauseSubscriptions,omitempty" tf:"pause_subscriptions,omitempty"`

	// a list of subscription blocks consisting out of one of the required fields: user_name for user emails or destination_id - for Alert destination's identifier.
	Subscriptions []DashboardSubscriptionsObservation `json:"subscriptions,omitempty" tf:"subscriptions,omitempty"`
}

type DashboardParameters struct {

	// string specifying a custom subject of email sent.
	// +kubebuilder:validation:Optional
	CustomSubject *string `json:"customSubject,omitempty" tf:"custom_subject,omitempty"`

	// (String) identifier of the Databricks SQL Dashboard databricks_sql_dashboard.
	// +kubebuilder:validation:Optional
	DashboardID *string `json:"dashboardId" tf:"dashboard_id,omitempty"`

	// flag that specifies if subscriptions are paused or not.
	// +kubebuilder:validation:Optional
	PauseSubscriptions *bool `json:"pauseSubscriptions,omitempty" tf:"pause_subscriptions,omitempty"`

	// a list of subscription blocks consisting out of one of the required fields: user_name for user emails or destination_id - for Alert destination's identifier.
	// +kubebuilder:validation:Optional
	Subscriptions []DashboardSubscriptionsParameters `json:"subscriptions,omitempty" tf:"subscriptions,omitempty"`
}

type DashboardSubscriptionsInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DestinationID *string `json:"destinationId,omitempty" tf:"destination_id,omitempty"`

	// The email of an active workspace user. Non-admin users can only set this field to their own email.
	UserName *string `json:"userName,omitempty" tf:"user_name,omitempty"`
}

type DashboardSubscriptionsObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DestinationID *string `json:"destinationId,omitempty" tf:"destination_id,omitempty"`

	// The email of an active workspace user. Non-admin users can only set this field to their own email.
	UserName *string `json:"userName,omitempty" tf:"user_name,omitempty"`
}

type DashboardSubscriptionsParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	DestinationID *string `json:"destinationId,omitempty" tf:"destination_id,omitempty"`

	// The email of an active workspace user. Non-admin users can only set this field to their own email.
	// +kubebuilder:validation:Optional
	UserName *string `json:"userName,omitempty" tf:"user_name,omitempty"`
}

type DbfsInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type DbfsObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type DbfsParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type DbtTaskInitParameters struct {

	// The name of the catalog to use inside Unity Catalog.
	Catalog *string `json:"catalog,omitempty" tf:"catalog,omitempty"`

	// (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
	Commands []*string `json:"commands,omitempty" tf:"commands,omitempty"`

	// The relative path to the directory in the repository specified by git_source where dbt should look in for the profiles.yml file. If not specified, defaults to the repository's root directory. Equivalent to passing --profile-dir to a dbt command.
	ProfilesDirectory *string `json:"profilesDirectory,omitempty" tf:"profiles_directory,omitempty"`

	// The path where dbt should look for dbt_project.yml. Equivalent to passing --project-dir to the dbt CLI.
	ProjectDirectory *string `json:"projectDirectory,omitempty" tf:"project_directory,omitempty"`

	// The name of the schema dbt should run in. Defaults to default.
	Schema *string `json:"schema,omitempty" tf:"schema,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`

	// The ID of the SQL warehouse that dbt should execute against.
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type DbtTaskObservation struct {

	// The name of the catalog to use inside Unity Catalog.
	Catalog *string `json:"catalog,omitempty" tf:"catalog,omitempty"`

	// (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
	Commands []*string `json:"commands,omitempty" tf:"commands,omitempty"`

	// The relative path to the directory in the repository specified by git_source where dbt should look in for the profiles.yml file. If not specified, defaults to the repository's root directory. Equivalent to passing --profile-dir to a dbt command.
	ProfilesDirectory *string `json:"profilesDirectory,omitempty" tf:"profiles_directory,omitempty"`

	// The path where dbt should look for dbt_project.yml. Equivalent to passing --project-dir to the dbt CLI.
	ProjectDirectory *string `json:"projectDirectory,omitempty" tf:"project_directory,omitempty"`

	// The name of the schema dbt should run in. Defaults to default.
	Schema *string `json:"schema,omitempty" tf:"schema,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`

	// The ID of the SQL warehouse that dbt should execute against.
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type DbtTaskParameters struct {

	// The name of the catalog to use inside Unity Catalog.
	// +kubebuilder:validation:Optional
	Catalog *string `json:"catalog,omitempty" tf:"catalog,omitempty"`

	// (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
	// +kubebuilder:validation:Optional
	Commands []*string `json:"commands" tf:"commands,omitempty"`

	// The relative path to the directory in the repository specified by git_source where dbt should look in for the profiles.yml file. If not specified, defaults to the repository's root directory. Equivalent to passing --profile-dir to a dbt command.
	// +kubebuilder:validation:Optional
	ProfilesDirectory *string `json:"profilesDirectory,omitempty" tf:"profiles_directory,omitempty"`

	// The path where dbt should look for dbt_project.yml. Equivalent to passing --project-dir to the dbt CLI.
	// +kubebuilder:validation:Optional
	ProjectDirectory *string `json:"projectDirectory,omitempty" tf:"project_directory,omitempty"`

	// The name of the schema dbt should run in. Defaults to default.
	// +kubebuilder:validation:Optional
	Schema *string `json:"schema,omitempty" tf:"schema,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	// +kubebuilder:validation:Optional
	Source *string `json:"source,omitempty" tf:"source,omitempty"`

	// The ID of the SQL warehouse that dbt should execute against.
	// +kubebuilder:validation:Optional
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type DependsOnInitParameters struct {

	// Can only be specified on condition task dependencies. The outcome of the dependent task that must be met for this task to run. Possible values are "true" or "false".
	Outcome *string `json:"outcome,omitempty" tf:"outcome,omitempty"`

	// string specifying an unique key for a given task.
	TaskKey *string `json:"taskKey,omitempty" tf:"task_key,omitempty"`
}

type DependsOnObservation struct {

	// Can only be specified on condition task dependencies. The outcome of the dependent task that must be met for this task to run. Possible values are "true" or "false".
	Outcome *string `json:"outcome,omitempty" tf:"outcome,omitempty"`

	// string specifying an unique key for a given task.
	TaskKey *string `json:"taskKey,omitempty" tf:"task_key,omitempty"`
}

type DependsOnParameters struct {

	// Can only be specified on condition task dependencies. The outcome of the dependent task that must be met for this task to run. Possible values are "true" or "false".
	// +kubebuilder:validation:Optional
	Outcome *string `json:"outcome,omitempty" tf:"outcome,omitempty"`

	// string specifying an unique key for a given task.
	// +kubebuilder:validation:Optional
	TaskKey *string `json:"taskKey" tf:"task_key,omitempty"`
}

type DeploymentInitParameters struct {
	Kind *string `json:"kind,omitempty" tf:"kind,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	MetadataFilePath *string `json:"metadataFilePath,omitempty" tf:"metadata_file_path,omitempty"`
}

type DeploymentObservation struct {
	Kind *string `json:"kind,omitempty" tf:"kind,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	MetadataFilePath *string `json:"metadataFilePath,omitempty" tf:"metadata_file_path,omitempty"`
}

type DeploymentParameters struct {

	// +kubebuilder:validation:Optional
	Kind *string `json:"kind" tf:"kind,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	// +kubebuilder:validation:Optional
	MetadataFilePath *string `json:"metadataFilePath,omitempty" tf:"metadata_file_path,omitempty"`
}

type DockerImageBasicAuthInitParameters struct {

	// An optional name for the job. The default value is Untitled.
	Username *string `json:"username,omitempty" tf:"username,omitempty"`
}

type DockerImageBasicAuthObservation struct {

	// An optional name for the job. The default value is Untitled.
	Username *string `json:"username,omitempty" tf:"username,omitempty"`
}

type DockerImageBasicAuthParameters struct {

	// +kubebuilder:validation:Required
	PasswordSecretRef v1.SecretKeySelector `json:"passwordSecretRef" tf:"-"`

	// An optional name for the job. The default value is Untitled.
	// +kubebuilder:validation:Optional
	Username *string `json:"username" tf:"username,omitempty"`
}

type DockerImageInitParameters struct {
	BasicAuth []BasicAuthInitParameters `json:"basicAuth,omitempty" tf:"basic_auth,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	URL *string `json:"url,omitempty" tf:"url,omitempty"`
}

type DockerImageObservation struct {
	BasicAuth []BasicAuthObservation `json:"basicAuth,omitempty" tf:"basic_auth,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	URL *string `json:"url,omitempty" tf:"url,omitempty"`
}

type DockerImageParameters struct {

	// +kubebuilder:validation:Optional
	BasicAuth []BasicAuthParameters `json:"basicAuth,omitempty" tf:"basic_auth,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	// +kubebuilder:validation:Optional
	URL *string `json:"url" tf:"url,omitempty"`
}

type EmailNotificationsInitParameters struct {

	// (Bool) don't send alert for skipped runs. (It's recommended to use the corresponding setting in the notification_settings configuration block).
	NoAlertForSkippedRuns *bool `json:"noAlertForSkippedRuns,omitempty" tf:"no_alert_for_skipped_runs,omitempty"`

	// (List) list of emails to notify when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	OnDurationWarningThresholdExceeded []*string `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of emails to notify when the run fails.
	OnFailure []*string `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of emails to notify when the run starts.
	OnStart []*string `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of emails to notify when the run completes successfully.
	OnSuccess []*string `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type EmailNotificationsObservation struct {

	// (Bool) don't send alert for skipped runs. (It's recommended to use the corresponding setting in the notification_settings configuration block).
	NoAlertForSkippedRuns *bool `json:"noAlertForSkippedRuns,omitempty" tf:"no_alert_for_skipped_runs,omitempty"`

	// (List) list of emails to notify when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	OnDurationWarningThresholdExceeded []*string `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of emails to notify when the run fails.
	OnFailure []*string `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of emails to notify when the run starts.
	OnStart []*string `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of emails to notify when the run completes successfully.
	OnSuccess []*string `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type EmailNotificationsParameters struct {

	// (Bool) don't send alert for skipped runs. (It's recommended to use the corresponding setting in the notification_settings configuration block).
	// +kubebuilder:validation:Optional
	NoAlertForSkippedRuns *bool `json:"noAlertForSkippedRuns,omitempty" tf:"no_alert_for_skipped_runs,omitempty"`

	// (List) list of emails to notify when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	// +kubebuilder:validation:Optional
	OnDurationWarningThresholdExceeded []*string `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of emails to notify when the run fails.
	// +kubebuilder:validation:Optional
	OnFailure []*string `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of emails to notify when the run starts.
	// +kubebuilder:validation:Optional
	OnStart []*string `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of emails to notify when the run completes successfully.
	// +kubebuilder:validation:Optional
	OnSuccess []*string `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type FileArrivalInitParameters struct {

	// If set, the trigger starts a run only after the specified amount of time passed since the last time the trigger fired. The minimum allowed value is 60 seconds.
	MinTimeBetweenTriggersSeconds *float64 `json:"minTimeBetweenTriggersSeconds,omitempty" tf:"min_time_between_triggers_seconds,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	URL *string `json:"url,omitempty" tf:"url,omitempty"`

	// If set, the trigger starts a run only after no file activity has occurred for the specified amount of time. This makes it possible to wait for a batch of incoming files to arrive before triggering a run. The minimum allowed value is 60 seconds.
	WaitAfterLastChangeSeconds *float64 `json:"waitAfterLastChangeSeconds,omitempty" tf:"wait_after_last_change_seconds,omitempty"`
}

type FileArrivalObservation struct {

	// If set, the trigger starts a run only after the specified amount of time passed since the last time the trigger fired. The minimum allowed value is 60 seconds.
	MinTimeBetweenTriggersSeconds *float64 `json:"minTimeBetweenTriggersSeconds,omitempty" tf:"min_time_between_triggers_seconds,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	URL *string `json:"url,omitempty" tf:"url,omitempty"`

	// If set, the trigger starts a run only after no file activity has occurred for the specified amount of time. This makes it possible to wait for a batch of incoming files to arrive before triggering a run. The minimum allowed value is 60 seconds.
	WaitAfterLastChangeSeconds *float64 `json:"waitAfterLastChangeSeconds,omitempty" tf:"wait_after_last_change_seconds,omitempty"`
}

type FileArrivalParameters struct {

	// If set, the trigger starts a run only after the specified amount of time passed since the last time the trigger fired. The minimum allowed value is 60 seconds.
	// +kubebuilder:validation:Optional
	MinTimeBetweenTriggersSeconds *float64 `json:"minTimeBetweenTriggersSeconds,omitempty" tf:"min_time_between_triggers_seconds,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	// +kubebuilder:validation:Optional
	URL *string `json:"url" tf:"url,omitempty"`

	// If set, the trigger starts a run only after no file activity has occurred for the specified amount of time. This makes it possible to wait for a batch of incoming files to arrive before triggering a run. The minimum allowed value is 60 seconds.
	// +kubebuilder:validation:Optional
	WaitAfterLastChangeSeconds *float64 `json:"waitAfterLastChangeSeconds,omitempty" tf:"wait_after_last_change_seconds,omitempty"`
}

type FileInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type FileObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type FileParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type ForEachTaskInitParameters struct {

	// Controls the number of active iteration task runs. Default is 20, maximum allowed is 100.
	Concurrency *float64 `json:"concurrency,omitempty" tf:"concurrency,omitempty"`

	// (String) Array for task to iterate on. This can be a JSON string or a reference to an array parameter.
	Inputs *string `json:"inputs,omitempty" tf:"inputs,omitempty"`

	// Task to run against the inputs list.
	Task []ForEachTaskTaskInitParameters `json:"task,omitempty" tf:"task,omitempty"`
}

type ForEachTaskObservation struct {

	// Controls the number of active iteration task runs. Default is 20, maximum allowed is 100.
	Concurrency *float64 `json:"concurrency,omitempty" tf:"concurrency,omitempty"`

	// (String) Array for task to iterate on. This can be a JSON string or a reference to an array parameter.
	Inputs *string `json:"inputs,omitempty" tf:"inputs,omitempty"`

	// Task to run against the inputs list.
	Task []ForEachTaskTaskObservation `json:"task,omitempty" tf:"task,omitempty"`
}

type ForEachTaskParameters struct {

	// Controls the number of active iteration task runs. Default is 20, maximum allowed is 100.
	// +kubebuilder:validation:Optional
	Concurrency *float64 `json:"concurrency,omitempty" tf:"concurrency,omitempty"`

	// (String) Array for task to iterate on. This can be a JSON string or a reference to an array parameter.
	// +kubebuilder:validation:Optional
	Inputs *string `json:"inputs" tf:"inputs,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	Task []ForEachTaskTaskParameters `json:"task" tf:"task,omitempty"`
}

type ForEachTaskTaskDbtTaskInitParameters struct {

	// The name of the catalog to use inside Unity Catalog.
	Catalog *string `json:"catalog,omitempty" tf:"catalog,omitempty"`

	// (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
	Commands []*string `json:"commands,omitempty" tf:"commands,omitempty"`

	// The relative path to the directory in the repository specified by git_source where dbt should look in for the profiles.yml file. If not specified, defaults to the repository's root directory. Equivalent to passing --profile-dir to a dbt command.
	ProfilesDirectory *string `json:"profilesDirectory,omitempty" tf:"profiles_directory,omitempty"`

	// The path where dbt should look for dbt_project.yml. Equivalent to passing --project-dir to the dbt CLI.
	ProjectDirectory *string `json:"projectDirectory,omitempty" tf:"project_directory,omitempty"`

	// The name of the schema dbt should run in. Defaults to default.
	Schema *string `json:"schema,omitempty" tf:"schema,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`

	// The ID of the SQL warehouse that dbt should execute against.
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type ForEachTaskTaskDbtTaskObservation struct {

	// The name of the catalog to use inside Unity Catalog.
	Catalog *string `json:"catalog,omitempty" tf:"catalog,omitempty"`

	// (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
	Commands []*string `json:"commands,omitempty" tf:"commands,omitempty"`

	// The relative path to the directory in the repository specified by git_source where dbt should look in for the profiles.yml file. If not specified, defaults to the repository's root directory. Equivalent to passing --profile-dir to a dbt command.
	ProfilesDirectory *string `json:"profilesDirectory,omitempty" tf:"profiles_directory,omitempty"`

	// The path where dbt should look for dbt_project.yml. Equivalent to passing --project-dir to the dbt CLI.
	ProjectDirectory *string `json:"projectDirectory,omitempty" tf:"project_directory,omitempty"`

	// The name of the schema dbt should run in. Defaults to default.
	Schema *string `json:"schema,omitempty" tf:"schema,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`

	// The ID of the SQL warehouse that dbt should execute against.
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type ForEachTaskTaskDbtTaskParameters struct {

	// The name of the catalog to use inside Unity Catalog.
	// +kubebuilder:validation:Optional
	Catalog *string `json:"catalog,omitempty" tf:"catalog,omitempty"`

	// (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
	// +kubebuilder:validation:Optional
	Commands []*string `json:"commands" tf:"commands,omitempty"`

	// The relative path to the directory in the repository specified by git_source where dbt should look in for the profiles.yml file. If not specified, defaults to the repository's root directory. Equivalent to passing --profile-dir to a dbt command.
	// +kubebuilder:validation:Optional
	ProfilesDirectory *string `json:"profilesDirectory,omitempty" tf:"profiles_directory,omitempty"`

	// The path where dbt should look for dbt_project.yml. Equivalent to passing --project-dir to the dbt CLI.
	// +kubebuilder:validation:Optional
	ProjectDirectory *string `json:"projectDirectory,omitempty" tf:"project_directory,omitempty"`

	// The name of the schema dbt should run in. Defaults to default.
	// +kubebuilder:validation:Optional
	Schema *string `json:"schema,omitempty" tf:"schema,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	// +kubebuilder:validation:Optional
	Source *string `json:"source,omitempty" tf:"source,omitempty"`

	// The ID of the SQL warehouse that dbt should execute against.
	// +kubebuilder:validation:Optional
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type ForEachTaskTaskEmailNotificationsInitParameters struct {

	// (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	OnDurationWarningThresholdExceeded []*string `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
	OnFailure []*string `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
	OnStart []*string `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
	OnSuccess []*string `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type ForEachTaskTaskEmailNotificationsObservation struct {

	// (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	OnDurationWarningThresholdExceeded []*string `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
	OnFailure []*string `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
	OnStart []*string `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
	OnSuccess []*string `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type ForEachTaskTaskEmailNotificationsParameters struct {

	// (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	// +kubebuilder:validation:Optional
	OnDurationWarningThresholdExceeded []*string `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
	// +kubebuilder:validation:Optional
	OnFailure []*string `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
	// +kubebuilder:validation:Optional
	OnStart []*string `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
	// +kubebuilder:validation:Optional
	OnSuccess []*string `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type ForEachTaskTaskInitParameters struct {
	ComputeKey *string `json:"computeKey,omitempty" tf:"compute_key,omitempty"`

	// Task to run against the inputs list.
	ConditionTask []TaskConditionTaskInitParameters `json:"conditionTask,omitempty" tf:"condition_task,omitempty"`

	// Task to run against the inputs list.
	DbtTask []ForEachTaskTaskDbtTaskInitParameters `json:"dbtTask,omitempty" tf:"dbt_task,omitempty"`

	// block specifying dependency(-ies) for a given task.
	DependsOn []TaskDependsOnInitParameters `json:"dependsOn,omitempty" tf:"depends_on,omitempty"`

	// An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (List) An optional set of email addresses notified when runs of this job begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
	EmailNotifications []ForEachTaskTaskEmailNotificationsInitParameters `json:"emailNotifications,omitempty" tf:"email_notifications,omitempty"`

	// If existing_cluster_id, the ID of an existing cluster that will be used for all runs of this job. When running jobs on an existing cluster, you may need to manually restart the cluster if it stops responding. We strongly suggest to use new_cluster for greater reliability.
	ExistingClusterID *string `json:"existingClusterId,omitempty" tf:"existing_cluster_id,omitempty"`

	// An optional block that specifies the health conditions for the job (described below).
	Health []TaskHealthInitParameters `json:"health,omitempty" tf:"health,omitempty"`

	// Identifier that can be referenced in task block, so that cluster is shared between tasks
	JobClusterKey *string `json:"jobClusterKey,omitempty" tf:"job_cluster_key,omitempty"`

	// (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for databricks_cluster resource.
	Library []TaskLibraryInitParameters `json:"library,omitempty" tf:"library,omitempty"`

	// (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a FAILED or INTERNAL_ERROR lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: PENDING, RUNNING, TERMINATING, TERMINATED, SKIPPED or INTERNAL_ERROR.
	MaxRetries *float64 `json:"maxRetries,omitempty" tf:"max_retries,omitempty"`

	// (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
	MinRetryIntervalMillis *float64 `json:"minRetryIntervalMillis,omitempty" tf:"min_retry_interval_millis,omitempty"`

	// Same set of parameters as for databricks_cluster resource.
	NewCluster []TaskNewClusterInitParameters `json:"newCluster,omitempty" tf:"new_cluster,omitempty"`

	// Task to run against the inputs list.
	NotebookTask []TaskNotebookTaskInitParameters `json:"notebookTask,omitempty" tf:"notebook_task,omitempty"`

	// An optional block controlling the notification settings on the job level (described below).
	NotificationSettings []TaskNotificationSettingsInitParameters `json:"notificationSettings,omitempty" tf:"notification_settings,omitempty"`

	// Task to run against the inputs list.
	PipelineTask []TaskPipelineTaskInitParameters `json:"pipelineTask,omitempty" tf:"pipeline_task,omitempty"`

	// Task to run against the inputs list.
	PythonWheelTask []TaskPythonWheelTaskInitParameters `json:"pythonWheelTask,omitempty" tf:"python_wheel_task,omitempty"`

	// (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
	RetryOnTimeout *bool `json:"retryOnTimeout,omitempty" tf:"retry_on_timeout,omitempty"`

	// An optional value indicating the condition that determines whether the task should be run once its dependencies have been completed. When omitted, defaults to ALL_SUCCESS.
	RunIf *string `json:"runIf,omitempty" tf:"run_if,omitempty"`

	// Task to run against the inputs list.
	RunJobTask []TaskRunJobTaskInitParameters `json:"runJobTask,omitempty" tf:"run_job_task,omitempty"`

	// Task to run against the inputs list.
	SQLTask []SQLTaskInitParameters `json:"sqlTask,omitempty" tf:"sql_task,omitempty"`

	// Task to run against the inputs list.
	SparkJarTask []TaskSparkJarTaskInitParameters `json:"sparkJarTask,omitempty" tf:"spark_jar_task,omitempty"`

	// Task to run against the inputs list.
	SparkPythonTask []TaskSparkPythonTaskInitParameters `json:"sparkPythonTask,omitempty" tf:"spark_python_task,omitempty"`

	// Task to run against the inputs list.
	SparkSubmitTask []TaskSparkSubmitTaskInitParameters `json:"sparkSubmitTask,omitempty" tf:"spark_submit_task,omitempty"`

	// string specifying an unique key for a given task.
	TaskKey *string `json:"taskKey,omitempty" tf:"task_key,omitempty"`

	// (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
	TimeoutSeconds *float64 `json:"timeoutSeconds,omitempty" tf:"timeout_seconds,omitempty"`

	// (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this job begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
	WebhookNotifications []WebhookNotificationsInitParameters `json:"webhookNotifications,omitempty" tf:"webhook_notifications,omitempty"`
}

type ForEachTaskTaskObservation struct {
	ComputeKey *string `json:"computeKey,omitempty" tf:"compute_key,omitempty"`

	// Task to run against the inputs list.
	ConditionTask []TaskConditionTaskObservation `json:"conditionTask,omitempty" tf:"condition_task,omitempty"`

	// Task to run against the inputs list.
	DbtTask []ForEachTaskTaskDbtTaskObservation `json:"dbtTask,omitempty" tf:"dbt_task,omitempty"`

	// block specifying dependency(-ies) for a given task.
	DependsOn []TaskDependsOnObservation `json:"dependsOn,omitempty" tf:"depends_on,omitempty"`

	// An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (List) An optional set of email addresses notified when runs of this job begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
	EmailNotifications []ForEachTaskTaskEmailNotificationsObservation `json:"emailNotifications,omitempty" tf:"email_notifications,omitempty"`

	// If existing_cluster_id, the ID of an existing cluster that will be used for all runs of this job. When running jobs on an existing cluster, you may need to manually restart the cluster if it stops responding. We strongly suggest to use new_cluster for greater reliability.
	ExistingClusterID *string `json:"existingClusterId,omitempty" tf:"existing_cluster_id,omitempty"`

	// An optional block that specifies the health conditions for the job (described below).
	Health []TaskHealthObservation `json:"health,omitempty" tf:"health,omitempty"`

	// Identifier that can be referenced in task block, so that cluster is shared between tasks
	JobClusterKey *string `json:"jobClusterKey,omitempty" tf:"job_cluster_key,omitempty"`

	// (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for databricks_cluster resource.
	Library []TaskLibraryObservation `json:"library,omitempty" tf:"library,omitempty"`

	// (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a FAILED or INTERNAL_ERROR lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: PENDING, RUNNING, TERMINATING, TERMINATED, SKIPPED or INTERNAL_ERROR.
	MaxRetries *float64 `json:"maxRetries,omitempty" tf:"max_retries,omitempty"`

	// (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
	MinRetryIntervalMillis *float64 `json:"minRetryIntervalMillis,omitempty" tf:"min_retry_interval_millis,omitempty"`

	// Same set of parameters as for databricks_cluster resource.
	NewCluster []TaskNewClusterObservation `json:"newCluster,omitempty" tf:"new_cluster,omitempty"`

	// Task to run against the inputs list.
	NotebookTask []TaskNotebookTaskObservation `json:"notebookTask,omitempty" tf:"notebook_task,omitempty"`

	// An optional block controlling the notification settings on the job level (described below).
	NotificationSettings []TaskNotificationSettingsObservation `json:"notificationSettings,omitempty" tf:"notification_settings,omitempty"`

	// Task to run against the inputs list.
	PipelineTask []TaskPipelineTaskObservation `json:"pipelineTask,omitempty" tf:"pipeline_task,omitempty"`

	// Task to run against the inputs list.
	PythonWheelTask []TaskPythonWheelTaskObservation `json:"pythonWheelTask,omitempty" tf:"python_wheel_task,omitempty"`

	// (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
	RetryOnTimeout *bool `json:"retryOnTimeout,omitempty" tf:"retry_on_timeout,omitempty"`

	// An optional value indicating the condition that determines whether the task should be run once its dependencies have been completed. When omitted, defaults to ALL_SUCCESS.
	RunIf *string `json:"runIf,omitempty" tf:"run_if,omitempty"`

	// Task to run against the inputs list.
	RunJobTask []TaskRunJobTaskObservation `json:"runJobTask,omitempty" tf:"run_job_task,omitempty"`

	// Task to run against the inputs list.
	SQLTask []SQLTaskObservation `json:"sqlTask,omitempty" tf:"sql_task,omitempty"`

	// Task to run against the inputs list.
	SparkJarTask []TaskSparkJarTaskObservation `json:"sparkJarTask,omitempty" tf:"spark_jar_task,omitempty"`

	// Task to run against the inputs list.
	SparkPythonTask []TaskSparkPythonTaskObservation `json:"sparkPythonTask,omitempty" tf:"spark_python_task,omitempty"`

	// Task to run against the inputs list.
	SparkSubmitTask []TaskSparkSubmitTaskObservation `json:"sparkSubmitTask,omitempty" tf:"spark_submit_task,omitempty"`

	// string specifying an unique key for a given task.
	TaskKey *string `json:"taskKey,omitempty" tf:"task_key,omitempty"`

	// (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
	TimeoutSeconds *float64 `json:"timeoutSeconds,omitempty" tf:"timeout_seconds,omitempty"`

	// (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this job begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
	WebhookNotifications []WebhookNotificationsObservation `json:"webhookNotifications,omitempty" tf:"webhook_notifications,omitempty"`
}

type ForEachTaskTaskParameters struct {

	// +kubebuilder:validation:Optional
	ComputeKey *string `json:"computeKey,omitempty" tf:"compute_key,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	ConditionTask []TaskConditionTaskParameters `json:"conditionTask,omitempty" tf:"condition_task,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	DbtTask []ForEachTaskTaskDbtTaskParameters `json:"dbtTask,omitempty" tf:"dbt_task,omitempty"`

	// block specifying dependency(-ies) for a given task.
	// +kubebuilder:validation:Optional
	DependsOn []TaskDependsOnParameters `json:"dependsOn,omitempty" tf:"depends_on,omitempty"`

	// An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
	// +kubebuilder:validation:Optional
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (List) An optional set of email addresses notified when runs of this job begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
	// +kubebuilder:validation:Optional
	EmailNotifications []ForEachTaskTaskEmailNotificationsParameters `json:"emailNotifications,omitempty" tf:"email_notifications,omitempty"`

	// If existing_cluster_id, the ID of an existing cluster that will be used for all runs of this job. When running jobs on an existing cluster, you may need to manually restart the cluster if it stops responding. We strongly suggest to use new_cluster for greater reliability.
	// +kubebuilder:validation:Optional
	ExistingClusterID *string `json:"existingClusterId,omitempty" tf:"existing_cluster_id,omitempty"`

	// An optional block that specifies the health conditions for the job (described below).
	// +kubebuilder:validation:Optional
	Health []TaskHealthParameters `json:"health,omitempty" tf:"health,omitempty"`

	// Identifier that can be referenced in task block, so that cluster is shared between tasks
	// +kubebuilder:validation:Optional
	JobClusterKey *string `json:"jobClusterKey,omitempty" tf:"job_cluster_key,omitempty"`

	// (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for databricks_cluster resource.
	// +kubebuilder:validation:Optional
	Library []TaskLibraryParameters `json:"library,omitempty" tf:"library,omitempty"`

	// (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a FAILED or INTERNAL_ERROR lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: PENDING, RUNNING, TERMINATING, TERMINATED, SKIPPED or INTERNAL_ERROR.
	// +kubebuilder:validation:Optional
	MaxRetries *float64 `json:"maxRetries,omitempty" tf:"max_retries,omitempty"`

	// (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
	// +kubebuilder:validation:Optional
	MinRetryIntervalMillis *float64 `json:"minRetryIntervalMillis,omitempty" tf:"min_retry_interval_millis,omitempty"`

	// Same set of parameters as for databricks_cluster resource.
	// +kubebuilder:validation:Optional
	NewCluster []TaskNewClusterParameters `json:"newCluster,omitempty" tf:"new_cluster,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	NotebookTask []TaskNotebookTaskParameters `json:"notebookTask,omitempty" tf:"notebook_task,omitempty"`

	// An optional block controlling the notification settings on the job level (described below).
	// +kubebuilder:validation:Optional
	NotificationSettings []TaskNotificationSettingsParameters `json:"notificationSettings,omitempty" tf:"notification_settings,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	PipelineTask []TaskPipelineTaskParameters `json:"pipelineTask,omitempty" tf:"pipeline_task,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	PythonWheelTask []TaskPythonWheelTaskParameters `json:"pythonWheelTask,omitempty" tf:"python_wheel_task,omitempty"`

	// (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
	// +kubebuilder:validation:Optional
	RetryOnTimeout *bool `json:"retryOnTimeout,omitempty" tf:"retry_on_timeout,omitempty"`

	// An optional value indicating the condition that determines whether the task should be run once its dependencies have been completed. When omitted, defaults to ALL_SUCCESS.
	// +kubebuilder:validation:Optional
	RunIf *string `json:"runIf,omitempty" tf:"run_if,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	RunJobTask []TaskRunJobTaskParameters `json:"runJobTask,omitempty" tf:"run_job_task,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	SQLTask []SQLTaskParameters `json:"sqlTask,omitempty" tf:"sql_task,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	SparkJarTask []TaskSparkJarTaskParameters `json:"sparkJarTask,omitempty" tf:"spark_jar_task,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	SparkPythonTask []TaskSparkPythonTaskParameters `json:"sparkPythonTask,omitempty" tf:"spark_python_task,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	SparkSubmitTask []TaskSparkSubmitTaskParameters `json:"sparkSubmitTask,omitempty" tf:"spark_submit_task,omitempty"`

	// string specifying an unique key for a given task.
	// +kubebuilder:validation:Optional
	TaskKey *string `json:"taskKey,omitempty" tf:"task_key,omitempty"`

	// (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
	// +kubebuilder:validation:Optional
	TimeoutSeconds *float64 `json:"timeoutSeconds,omitempty" tf:"timeout_seconds,omitempty"`

	// (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this job begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
	// +kubebuilder:validation:Optional
	WebhookNotifications []WebhookNotificationsParameters `json:"webhookNotifications,omitempty" tf:"webhook_notifications,omitempty"`
}

type GCPAttributesInitParameters struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	BootDiskSize *float64 `json:"bootDiskSize,omitempty" tf:"boot_disk_size,omitempty"`

	GoogleServiceAccount *string `json:"googleServiceAccount,omitempty" tf:"google_service_account,omitempty"`

	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`

	UsePreemptibleExecutors *bool `json:"usePreemptibleExecutors,omitempty" tf:"use_preemptible_executors,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type GCPAttributesObservation struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	BootDiskSize *float64 `json:"bootDiskSize,omitempty" tf:"boot_disk_size,omitempty"`

	GoogleServiceAccount *string `json:"googleServiceAccount,omitempty" tf:"google_service_account,omitempty"`

	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`

	UsePreemptibleExecutors *bool `json:"usePreemptibleExecutors,omitempty" tf:"use_preemptible_executors,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type GCPAttributesParameters struct {

	// +kubebuilder:validation:Optional
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	// +kubebuilder:validation:Optional
	BootDiskSize *float64 `json:"bootDiskSize,omitempty" tf:"boot_disk_size,omitempty"`

	// +kubebuilder:validation:Optional
	GoogleServiceAccount *string `json:"googleServiceAccount,omitempty" tf:"google_service_account,omitempty"`

	// +kubebuilder:validation:Optional
	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`

	// +kubebuilder:validation:Optional
	UsePreemptibleExecutors *bool `json:"usePreemptibleExecutors,omitempty" tf:"use_preemptible_executors,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type GcsInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type GcsObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type GcsParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type GitSourceInitParameters struct {

	// name of the Git branch to use. Conflicts with tag and commit.
	Branch *string `json:"branch,omitempty" tf:"branch,omitempty"`

	// hash of Git commit to use. Conflicts with branch and tag.
	Commit *string `json:"commit,omitempty" tf:"commit,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	JobSource []JobSourceInitParameters `json:"jobSource,omitempty" tf:"job_source,omitempty"`

	// case insensitive name of the Git provider.  Following values are supported right now (could be a subject for change, consult Repos API documentation): gitHub, gitHubEnterprise, bitbucketCloud, bitbucketServer, azureDevOpsServices, gitLab, gitLabEnterpriseEdition.
	Provider *string `json:"provider,omitempty" tf:"provider,omitempty"`

	// name of the Git branch to use. Conflicts with branch and commit.
	Tag *string `json:"tag,omitempty" tf:"tag,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	URL *string `json:"url,omitempty" tf:"url,omitempty"`
}

type GitSourceObservation struct {

	// name of the Git branch to use. Conflicts with tag and commit.
	Branch *string `json:"branch,omitempty" tf:"branch,omitempty"`

	// hash of Git commit to use. Conflicts with branch and tag.
	Commit *string `json:"commit,omitempty" tf:"commit,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	JobSource []JobSourceObservation `json:"jobSource,omitempty" tf:"job_source,omitempty"`

	// case insensitive name of the Git provider.  Following values are supported right now (could be a subject for change, consult Repos API documentation): gitHub, gitHubEnterprise, bitbucketCloud, bitbucketServer, azureDevOpsServices, gitLab, gitLabEnterpriseEdition.
	Provider *string `json:"provider,omitempty" tf:"provider,omitempty"`

	// name of the Git branch to use. Conflicts with branch and commit.
	Tag *string `json:"tag,omitempty" tf:"tag,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	URL *string `json:"url,omitempty" tf:"url,omitempty"`
}

type GitSourceParameters struct {

	// name of the Git branch to use. Conflicts with tag and commit.
	// +kubebuilder:validation:Optional
	Branch *string `json:"branch,omitempty" tf:"branch,omitempty"`

	// hash of Git commit to use. Conflicts with branch and tag.
	// +kubebuilder:validation:Optional
	Commit *string `json:"commit,omitempty" tf:"commit,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	// +kubebuilder:validation:Optional
	JobSource []JobSourceParameters `json:"jobSource,omitempty" tf:"job_source,omitempty"`

	// case insensitive name of the Git provider.  Following values are supported right now (could be a subject for change, consult Repos API documentation): gitHub, gitHubEnterprise, bitbucketCloud, bitbucketServer, azureDevOpsServices, gitLab, gitLabEnterpriseEdition.
	// +kubebuilder:validation:Optional
	Provider *string `json:"provider,omitempty" tf:"provider,omitempty"`

	// name of the Git branch to use. Conflicts with branch and commit.
	// +kubebuilder:validation:Optional
	Tag *string `json:"tag,omitempty" tf:"tag,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	// +kubebuilder:validation:Optional
	URL *string `json:"url" tf:"url,omitempty"`
}

type HealthInitParameters struct {

	// (List) list of rules that are represented as objects with the following attributes:
	Rules []RulesInitParameters `json:"rules,omitempty" tf:"rules,omitempty"`
}

type HealthObservation struct {

	// (List) list of rules that are represented as objects with the following attributes:
	Rules []RulesObservation `json:"rules,omitempty" tf:"rules,omitempty"`
}

type HealthParameters struct {

	// (List) list of rules that are represented as objects with the following attributes:
	// +kubebuilder:validation:Optional
	Rules []RulesParameters `json:"rules" tf:"rules,omitempty"`
}

type HealthRulesInitParameters struct {

	// string specifying the metric to check.  The only supported metric is RUN_DURATION_SECONDS (check Jobs REST API documentation for the latest information).
	Metric *string `json:"metric,omitempty" tf:"metric,omitempty"`

	// string specifying the operation used to evaluate the given metric. The only supported operation is GREATER_THAN.
	Op *string `json:"op,omitempty" tf:"op,omitempty"`

	// integer value used to compare to the given metric.
	Value *float64 `json:"value,omitempty" tf:"value,omitempty"`
}

type HealthRulesObservation struct {

	// string specifying the metric to check.  The only supported metric is RUN_DURATION_SECONDS (check Jobs REST API documentation for the latest information).
	Metric *string `json:"metric,omitempty" tf:"metric,omitempty"`

	// string specifying the operation used to evaluate the given metric. The only supported operation is GREATER_THAN.
	Op *string `json:"op,omitempty" tf:"op,omitempty"`

	// integer value used to compare to the given metric.
	Value *float64 `json:"value,omitempty" tf:"value,omitempty"`
}

type HealthRulesParameters struct {

	// string specifying the metric to check.  The only supported metric is RUN_DURATION_SECONDS (check Jobs REST API documentation for the latest information).
	// +kubebuilder:validation:Optional
	Metric *string `json:"metric,omitempty" tf:"metric,omitempty"`

	// string specifying the operation used to evaluate the given metric. The only supported operation is GREATER_THAN.
	// +kubebuilder:validation:Optional
	Op *string `json:"op,omitempty" tf:"op,omitempty"`

	// integer value used to compare to the given metric.
	// +kubebuilder:validation:Optional
	Value *float64 `json:"value,omitempty" tf:"value,omitempty"`
}

type InitScriptsAbfssInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type InitScriptsAbfssObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type InitScriptsAbfssParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type InitScriptsDbfsInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type InitScriptsDbfsObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type InitScriptsDbfsParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type InitScriptsFileInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type InitScriptsFileObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type InitScriptsFileParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type InitScriptsGcsInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type InitScriptsGcsObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type InitScriptsGcsParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type InitScriptsInitParameters struct {
	Abfss []AbfssInitParameters `json:"abfss,omitempty" tf:"abfss,omitempty"`

	Dbfs []InitScriptsDbfsInitParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// block consisting of single string fields:
	File []FileInitParameters `json:"file,omitempty" tf:"file,omitempty"`

	Gcs []GcsInitParameters `json:"gcs,omitempty" tf:"gcs,omitempty"`

	S3 []InitScriptsS3InitParameters `json:"s3,omitempty" tf:"s3,omitempty"`

	Volumes []VolumesInitParameters `json:"volumes,omitempty" tf:"volumes,omitempty"`

	Workspace []WorkspaceInitParameters `json:"workspace,omitempty" tf:"workspace,omitempty"`
}

type InitScriptsObservation struct {
	Abfss []AbfssObservation `json:"abfss,omitempty" tf:"abfss,omitempty"`

	Dbfs []InitScriptsDbfsObservation `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// block consisting of single string fields:
	File []FileObservation `json:"file,omitempty" tf:"file,omitempty"`

	Gcs []GcsObservation `json:"gcs,omitempty" tf:"gcs,omitempty"`

	S3 []InitScriptsS3Observation `json:"s3,omitempty" tf:"s3,omitempty"`

	Volumes []VolumesObservation `json:"volumes,omitempty" tf:"volumes,omitempty"`

	Workspace []WorkspaceObservation `json:"workspace,omitempty" tf:"workspace,omitempty"`
}

type InitScriptsParameters struct {

	// +kubebuilder:validation:Optional
	Abfss []AbfssParameters `json:"abfss,omitempty" tf:"abfss,omitempty"`

	// +kubebuilder:validation:Optional
	Dbfs []InitScriptsDbfsParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// block consisting of single string fields:
	// +kubebuilder:validation:Optional
	File []FileParameters `json:"file,omitempty" tf:"file,omitempty"`

	// +kubebuilder:validation:Optional
	Gcs []GcsParameters `json:"gcs,omitempty" tf:"gcs,omitempty"`

	// +kubebuilder:validation:Optional
	S3 []InitScriptsS3Parameters `json:"s3,omitempty" tf:"s3,omitempty"`

	// +kubebuilder:validation:Optional
	Volumes []VolumesParameters `json:"volumes,omitempty" tf:"volumes,omitempty"`

	// +kubebuilder:validation:Optional
	Workspace []WorkspaceParameters `json:"workspace,omitempty" tf:"workspace,omitempty"`
}

type InitScriptsS3InitParameters struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type InitScriptsS3Observation struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type InitScriptsS3Parameters struct {

	// +kubebuilder:validation:Optional
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`

	// +kubebuilder:validation:Optional
	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	// +kubebuilder:validation:Optional
	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	// +kubebuilder:validation:Optional
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// +kubebuilder:validation:Optional
	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	// +kubebuilder:validation:Optional
	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type InitScriptsVolumesInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type InitScriptsVolumesObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type InitScriptsVolumesParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type InitScriptsWorkspaceInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type InitScriptsWorkspaceObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type InitScriptsWorkspaceParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type JobClusterInitParameters struct {

	// Identifier that can be referenced in task block, so that cluster is shared between tasks
	JobClusterKey *string `json:"jobClusterKey,omitempty" tf:"job_cluster_key,omitempty"`

	// Same set of parameters as for databricks_cluster resource.
	NewCluster []NewClusterInitParameters `json:"newCluster,omitempty" tf:"new_cluster,omitempty"`
}

type JobClusterObservation struct {

	// Identifier that can be referenced in task block, so that cluster is shared between tasks
	JobClusterKey *string `json:"jobClusterKey,omitempty" tf:"job_cluster_key,omitempty"`

	// Same set of parameters as for databricks_cluster resource.
	NewCluster []NewClusterObservation `json:"newCluster,omitempty" tf:"new_cluster,omitempty"`
}

type JobClusterParameters struct {

	// Identifier that can be referenced in task block, so that cluster is shared between tasks
	// +kubebuilder:validation:Optional
	JobClusterKey *string `json:"jobClusterKey,omitempty" tf:"job_cluster_key,omitempty"`

	// Same set of parameters as for databricks_cluster resource.
	// +kubebuilder:validation:Optional
	NewCluster []NewClusterParameters `json:"newCluster,omitempty" tf:"new_cluster,omitempty"`
}

type JobInitParameters struct {

	// (Bool) Whenever the job is always running, like a Spark Streaming application, on every update restart the current active run or start it again, if nothing it is not running. False by default. Any job runs are started with parameters specified in spark_jar_task or spark_submit_task or spark_python_task or notebook_task blocks.
	AlwaysRunning *bool `json:"alwaysRunning,omitempty" tf:"always_running,omitempty"`

	Compute []ComputeInitParameters `json:"compute,omitempty" tf:"compute,omitempty"`

	Continuous []ContinuousInitParameters `json:"continuous,omitempty" tf:"continuous,omitempty"`

	// (Bool) If true, the Databricks provider will stop and start the job as needed to ensure that the active run for the job reflects the deployed configuration. For continuous jobs, the provider respects the pause_status by stopping the current active run. This flag cannot be set for non-continuous jobs.
	ControlRunState *bool `json:"controlRunState,omitempty" tf:"control_run_state,omitempty"`

	// Task to run against the inputs list.
	DbtTask []DbtTaskInitParameters `json:"dbtTask,omitempty" tf:"dbt_task,omitempty"`

	Deployment []DeploymentInitParameters `json:"deployment,omitempty" tf:"deployment,omitempty"`

	// An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	EditMode *string `json:"editMode,omitempty" tf:"edit_mode,omitempty"`

	// (List) An optional set of email addresses notified when runs of this job begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
	EmailNotifications []EmailNotificationsInitParameters `json:"emailNotifications,omitempty" tf:"email_notifications,omitempty"`

	// If existing_cluster_id, the ID of an existing cluster that will be used for all runs of this job. When running jobs on an existing cluster, you may need to manually restart the cluster if it stops responding. We strongly suggest to use new_cluster for greater reliability.
	ExistingClusterID *string `json:"existingClusterId,omitempty" tf:"existing_cluster_id,omitempty"`

	Format *string `json:"format,omitempty" tf:"format,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	GitSource []GitSourceInitParameters `json:"gitSource,omitempty" tf:"git_source,omitempty"`

	// An optional block that specifies the health conditions for the job (described below).
	Health []HealthInitParameters `json:"health,omitempty" tf:"health,omitempty"`

	// A list of job databricks_cluster specifications that can be shared and reused by tasks of this job. Libraries cannot be declared in a shared job cluster. You must declare dependent libraries in task settings. Multi-task syntax
	JobCluster []JobClusterInitParameters `json:"jobCluster,omitempty" tf:"job_cluster,omitempty"`

	// (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for databricks_cluster resource.
	Library []LibraryInitParameters `json:"library,omitempty" tf:"library,omitempty"`

	// (Integer) An optional maximum allowed number of concurrent runs of the job. Defaults to 1.
	MaxConcurrentRuns *float64 `json:"maxConcurrentRuns,omitempty" tf:"max_concurrent_runs,omitempty"`

	// (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a FAILED or INTERNAL_ERROR lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: PENDING, RUNNING, TERMINATING, TERMINATED, SKIPPED or INTERNAL_ERROR.
	MaxRetries *float64 `json:"maxRetries,omitempty" tf:"max_retries,omitempty"`

	// (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
	MinRetryIntervalMillis *float64 `json:"minRetryIntervalMillis,omitempty" tf:"min_retry_interval_millis,omitempty"`

	// An optional name for the job. The default value is Untitled.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Same set of parameters as for databricks_cluster resource.
	NewCluster []JobNewClusterInitParameters `json:"newCluster,omitempty" tf:"new_cluster,omitempty"`

	// Task to run against the inputs list.
	NotebookTask []NotebookTaskInitParameters `json:"notebookTask,omitempty" tf:"notebook_task,omitempty"`

	// An optional block controlling the notification settings on the job level (described below).
	NotificationSettings []NotificationSettingsInitParameters `json:"notificationSettings,omitempty" tf:"notification_settings,omitempty"`

	Parameter []ParameterInitParameters `json:"parameter,omitempty" tf:"parameter,omitempty"`

	// Task to run against the inputs list.
	PipelineTask []PipelineTaskInitParameters `json:"pipelineTask,omitempty" tf:"pipeline_task,omitempty"`

	// Task to run against the inputs list.
	PythonWheelTask []PythonWheelTaskInitParameters `json:"pythonWheelTask,omitempty" tf:"python_wheel_task,omitempty"`

	Queue []QueueInitParameters `json:"queue,omitempty" tf:"queue,omitempty"`

	// (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
	RetryOnTimeout *bool `json:"retryOnTimeout,omitempty" tf:"retry_on_timeout,omitempty"`

	RunAs []RunAsInitParameters `json:"runAs,omitempty" tf:"run_as,omitempty"`

	// Task to run against the inputs list.
	RunJobTask []RunJobTaskInitParameters `json:"runJobTask,omitempty" tf:"run_job_task,omitempty"`

	// (List) An optional periodic schedule for this job. The default behavior is that the job runs when triggered by clicking Run Now in the Jobs UI or sending an API request to runNow. This field is a block and is documented below.
	Schedule []ScheduleInitParameters `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// Task to run against the inputs list.
	SparkJarTask []SparkJarTaskInitParameters `json:"sparkJarTask,omitempty" tf:"spark_jar_task,omitempty"`

	// Task to run against the inputs list.
	SparkPythonTask []SparkPythonTaskInitParameters `json:"sparkPythonTask,omitempty" tf:"spark_python_task,omitempty"`

	// Task to run against the inputs list.
	SparkSubmitTask []SparkSubmitTaskInitParameters `json:"sparkSubmitTask,omitempty" tf:"spark_submit_task,omitempty"`

	Tags map[string]*string `json:"tags,omitempty" tf:"tags,omitempty"`

	// Task to run against the inputs list.
	Task []TaskInitParameters `json:"task,omitempty" tf:"task,omitempty"`

	// (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
	TimeoutSeconds *float64 `json:"timeoutSeconds,omitempty" tf:"timeout_seconds,omitempty"`

	Trigger []TriggerInitParameters `json:"trigger,omitempty" tf:"trigger,omitempty"`

	// (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this job begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
	WebhookNotifications []JobWebhookNotificationsInitParameters `json:"webhookNotifications,omitempty" tf:"webhook_notifications,omitempty"`
}

type JobNewClusterInitParameters struct {
	ApplyPolicyDefaultValues *bool `json:"applyPolicyDefaultValues,omitempty" tf:"apply_policy_default_values,omitempty"`

	Autoscale []NewClusterAutoscaleInitParameters `json:"autoscale,omitempty" tf:"autoscale,omitempty"`

	AutoterminationMinutes *float64 `json:"autoterminationMinutes,omitempty" tf:"autotermination_minutes,omitempty"`

	AwsAttributes []NewClusterAwsAttributesInitParameters `json:"awsAttributes,omitempty" tf:"aws_attributes,omitempty"`

	AzureAttributes []NewClusterAzureAttributesInitParameters `json:"azureAttributes,omitempty" tf:"azure_attributes,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	ClusterLogConf []NewClusterClusterLogConfInitParameters `json:"clusterLogConf,omitempty" tf:"cluster_log_conf,omitempty"`

	ClusterMountInfo []NewClusterClusterMountInfoInitParameters `json:"clusterMountInfo,omitempty" tf:"cluster_mount_info,omitempty"`

	// An optional name for the job. The default value is Untitled.
	ClusterName *string `json:"clusterName,omitempty" tf:"cluster_name,omitempty"`

	CustomTags map[string]*string `json:"customTags,omitempty" tf:"custom_tags,omitempty"`

	DataSecurityMode *string `json:"dataSecurityMode,omitempty" tf:"data_security_mode,omitempty"`

	DockerImage []NewClusterDockerImageInitParameters `json:"dockerImage,omitempty" tf:"docker_image,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverInstancePoolID *string `json:"driverInstancePoolId,omitempty" tf:"driver_instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverNodeTypeID *string `json:"driverNodeTypeId,omitempty" tf:"driver_node_type_id,omitempty"`

	EnableElasticDisk *bool `json:"enableElasticDisk,omitempty" tf:"enable_elastic_disk,omitempty"`

	EnableLocalDiskEncryption *bool `json:"enableLocalDiskEncryption,omitempty" tf:"enable_local_disk_encryption,omitempty"`

	GCPAttributes []NewClusterGCPAttributesInitParameters `json:"gcpAttributes,omitempty" tf:"gcp_attributes,omitempty"`

	IdempotencyToken *string `json:"idempotencyToken,omitempty" tf:"idempotency_token,omitempty"`

	InitScripts []NewClusterInitScriptsInitParameters `json:"initScripts,omitempty" tf:"init_scripts,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	InstancePoolID *string `json:"instancePoolId,omitempty" tf:"instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	NodeTypeID *string `json:"nodeTypeId,omitempty" tf:"node_type_id,omitempty"`

	NumWorkers *float64 `json:"numWorkers,omitempty" tf:"num_workers,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	PolicyID *string `json:"policyId,omitempty" tf:"policy_id,omitempty"`

	RuntimeEngine *string `json:"runtimeEngine,omitempty" tf:"runtime_engine,omitempty"`

	SSHPublicKeys []*string `json:"sshPublicKeys,omitempty" tf:"ssh_public_keys,omitempty"`

	// An optional name for the job. The default value is Untitled.
	SingleUserName *string `json:"singleUserName,omitempty" tf:"single_user_name,omitempty"`

	SparkConf map[string]*string `json:"sparkConf,omitempty" tf:"spark_conf,omitempty"`

	SparkEnvVars map[string]*string `json:"sparkEnvVars,omitempty" tf:"spark_env_vars,omitempty"`

	// parameter in databricks_cluster and other resources.
	SparkVersion *string `json:"sparkVersion,omitempty" tf:"spark_version,omitempty"`

	WorkloadType []NewClusterWorkloadTypeInitParameters `json:"workloadType,omitempty" tf:"workload_type,omitempty"`
}

type JobNewClusterObservation struct {
	ApplyPolicyDefaultValues *bool `json:"applyPolicyDefaultValues,omitempty" tf:"apply_policy_default_values,omitempty"`

	Autoscale []NewClusterAutoscaleObservation `json:"autoscale,omitempty" tf:"autoscale,omitempty"`

	AutoterminationMinutes *float64 `json:"autoterminationMinutes,omitempty" tf:"autotermination_minutes,omitempty"`

	AwsAttributes []NewClusterAwsAttributesObservation `json:"awsAttributes,omitempty" tf:"aws_attributes,omitempty"`

	AzureAttributes []NewClusterAzureAttributesObservation `json:"azureAttributes,omitempty" tf:"azure_attributes,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	ClusterLogConf []NewClusterClusterLogConfObservation `json:"clusterLogConf,omitempty" tf:"cluster_log_conf,omitempty"`

	ClusterMountInfo []NewClusterClusterMountInfoObservation `json:"clusterMountInfo,omitempty" tf:"cluster_mount_info,omitempty"`

	// An optional name for the job. The default value is Untitled.
	ClusterName *string `json:"clusterName,omitempty" tf:"cluster_name,omitempty"`

	CustomTags map[string]*string `json:"customTags,omitempty" tf:"custom_tags,omitempty"`

	DataSecurityMode *string `json:"dataSecurityMode,omitempty" tf:"data_security_mode,omitempty"`

	DockerImage []NewClusterDockerImageObservation `json:"dockerImage,omitempty" tf:"docker_image,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverInstancePoolID *string `json:"driverInstancePoolId,omitempty" tf:"driver_instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverNodeTypeID *string `json:"driverNodeTypeId,omitempty" tf:"driver_node_type_id,omitempty"`

	EnableElasticDisk *bool `json:"enableElasticDisk,omitempty" tf:"enable_elastic_disk,omitempty"`

	EnableLocalDiskEncryption *bool `json:"enableLocalDiskEncryption,omitempty" tf:"enable_local_disk_encryption,omitempty"`

	GCPAttributes []NewClusterGCPAttributesObservation `json:"gcpAttributes,omitempty" tf:"gcp_attributes,omitempty"`

	IdempotencyToken *string `json:"idempotencyToken,omitempty" tf:"idempotency_token,omitempty"`

	InitScripts []NewClusterInitScriptsObservation `json:"initScripts,omitempty" tf:"init_scripts,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	InstancePoolID *string `json:"instancePoolId,omitempty" tf:"instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	NodeTypeID *string `json:"nodeTypeId,omitempty" tf:"node_type_id,omitempty"`

	NumWorkers *float64 `json:"numWorkers,omitempty" tf:"num_workers,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	PolicyID *string `json:"policyId,omitempty" tf:"policy_id,omitempty"`

	RuntimeEngine *string `json:"runtimeEngine,omitempty" tf:"runtime_engine,omitempty"`

	SSHPublicKeys []*string `json:"sshPublicKeys,omitempty" tf:"ssh_public_keys,omitempty"`

	// An optional name for the job. The default value is Untitled.
	SingleUserName *string `json:"singleUserName,omitempty" tf:"single_user_name,omitempty"`

	SparkConf map[string]*string `json:"sparkConf,omitempty" tf:"spark_conf,omitempty"`

	SparkEnvVars map[string]*string `json:"sparkEnvVars,omitempty" tf:"spark_env_vars,omitempty"`

	// parameter in databricks_cluster and other resources.
	SparkVersion *string `json:"sparkVersion,omitempty" tf:"spark_version,omitempty"`

	WorkloadType []NewClusterWorkloadTypeObservation `json:"workloadType,omitempty" tf:"workload_type,omitempty"`
}

type JobNewClusterParameters struct {

	// +kubebuilder:validation:Optional
	ApplyPolicyDefaultValues *bool `json:"applyPolicyDefaultValues,omitempty" tf:"apply_policy_default_values,omitempty"`

	// +kubebuilder:validation:Optional
	Autoscale []NewClusterAutoscaleParameters `json:"autoscale,omitempty" tf:"autoscale,omitempty"`

	// +kubebuilder:validation:Optional
	AutoterminationMinutes *float64 `json:"autoterminationMinutes,omitempty" tf:"autotermination_minutes,omitempty"`

	// +kubebuilder:validation:Optional
	AwsAttributes []NewClusterAwsAttributesParameters `json:"awsAttributes,omitempty" tf:"aws_attributes,omitempty"`

	// +kubebuilder:validation:Optional
	AzureAttributes []NewClusterAzureAttributesParameters `json:"azureAttributes,omitempty" tf:"azure_attributes,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// +kubebuilder:validation:Optional
	ClusterLogConf []NewClusterClusterLogConfParameters `json:"clusterLogConf,omitempty" tf:"cluster_log_conf,omitempty"`

	// +kubebuilder:validation:Optional
	ClusterMountInfo []NewClusterClusterMountInfoParameters `json:"clusterMountInfo,omitempty" tf:"cluster_mount_info,omitempty"`

	// An optional name for the job. The default value is Untitled.
	// +kubebuilder:validation:Optional
	ClusterName *string `json:"clusterName,omitempty" tf:"cluster_name,omitempty"`

	// +kubebuilder:validation:Optional
	CustomTags map[string]*string `json:"customTags,omitempty" tf:"custom_tags,omitempty"`

	// +kubebuilder:validation:Optional
	DataSecurityMode *string `json:"dataSecurityMode,omitempty" tf:"data_security_mode,omitempty"`

	// +kubebuilder:validation:Optional
	DockerImage []NewClusterDockerImageParameters `json:"dockerImage,omitempty" tf:"docker_image,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	DriverInstancePoolID *string `json:"driverInstancePoolId,omitempty" tf:"driver_instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	DriverNodeTypeID *string `json:"driverNodeTypeId,omitempty" tf:"driver_node_type_id,omitempty"`

	// +kubebuilder:validation:Optional
	EnableElasticDisk *bool `json:"enableElasticDisk,omitempty" tf:"enable_elastic_disk,omitempty"`

	// +kubebuilder:validation:Optional
	EnableLocalDiskEncryption *bool `json:"enableLocalDiskEncryption,omitempty" tf:"enable_local_disk_encryption,omitempty"`

	// +kubebuilder:validation:Optional
	GCPAttributes []NewClusterGCPAttributesParameters `json:"gcpAttributes,omitempty" tf:"gcp_attributes,omitempty"`

	// +kubebuilder:validation:Optional
	IdempotencyToken *string `json:"idempotencyToken,omitempty" tf:"idempotency_token,omitempty"`

	// +kubebuilder:validation:Optional
	InitScripts []NewClusterInitScriptsParameters `json:"initScripts,omitempty" tf:"init_scripts,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	InstancePoolID *string `json:"instancePoolId,omitempty" tf:"instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	NodeTypeID *string `json:"nodeTypeId,omitempty" tf:"node_type_id,omitempty"`

	// +kubebuilder:validation:Optional
	NumWorkers *float64 `json:"numWorkers,omitempty" tf:"num_workers,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	PolicyID *string `json:"policyId,omitempty" tf:"policy_id,omitempty"`

	// +kubebuilder:validation:Optional
	RuntimeEngine *string `json:"runtimeEngine,omitempty" tf:"runtime_engine,omitempty"`

	// +kubebuilder:validation:Optional
	SSHPublicKeys []*string `json:"sshPublicKeys,omitempty" tf:"ssh_public_keys,omitempty"`

	// An optional name for the job. The default value is Untitled.
	// +kubebuilder:validation:Optional
	SingleUserName *string `json:"singleUserName,omitempty" tf:"single_user_name,omitempty"`

	// +kubebuilder:validation:Optional
	SparkConf map[string]*string `json:"sparkConf,omitempty" tf:"spark_conf,omitempty"`

	// +kubebuilder:validation:Optional
	SparkEnvVars map[string]*string `json:"sparkEnvVars,omitempty" tf:"spark_env_vars,omitempty"`

	// parameter in databricks_cluster and other resources.
	// +kubebuilder:validation:Optional
	SparkVersion *string `json:"sparkVersion" tf:"spark_version,omitempty"`

	// +kubebuilder:validation:Optional
	WorkloadType []NewClusterWorkloadTypeParameters `json:"workloadType,omitempty" tf:"workload_type,omitempty"`
}

type JobObservation struct {

	// (Bool) Whenever the job is always running, like a Spark Streaming application, on every update restart the current active run or start it again, if nothing it is not running. False by default. Any job runs are started with parameters specified in spark_jar_task or spark_submit_task or spark_python_task or notebook_task blocks.
	AlwaysRunning *bool `json:"alwaysRunning,omitempty" tf:"always_running,omitempty"`

	Compute []ComputeObservation `json:"compute,omitempty" tf:"compute,omitempty"`

	Continuous []ContinuousObservation `json:"continuous,omitempty" tf:"continuous,omitempty"`

	// (Bool) If true, the Databricks provider will stop and start the job as needed to ensure that the active run for the job reflects the deployed configuration. For continuous jobs, the provider respects the pause_status by stopping the current active run. This flag cannot be set for non-continuous jobs.
	ControlRunState *bool `json:"controlRunState,omitempty" tf:"control_run_state,omitempty"`

	// Task to run against the inputs list.
	DbtTask []DbtTaskObservation `json:"dbtTask,omitempty" tf:"dbt_task,omitempty"`

	Deployment []DeploymentObservation `json:"deployment,omitempty" tf:"deployment,omitempty"`

	// An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	EditMode *string `json:"editMode,omitempty" tf:"edit_mode,omitempty"`

	// (List) An optional set of email addresses notified when runs of this job begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
	EmailNotifications []EmailNotificationsObservation `json:"emailNotifications,omitempty" tf:"email_notifications,omitempty"`

	// If existing_cluster_id, the ID of an existing cluster that will be used for all runs of this job. When running jobs on an existing cluster, you may need to manually restart the cluster if it stops responding. We strongly suggest to use new_cluster for greater reliability.
	ExistingClusterID *string `json:"existingClusterId,omitempty" tf:"existing_cluster_id,omitempty"`

	Format *string `json:"format,omitempty" tf:"format,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	GitSource []GitSourceObservation `json:"gitSource,omitempty" tf:"git_source,omitempty"`

	// An optional block that specifies the health conditions for the job (described below).
	Health []HealthObservation `json:"health,omitempty" tf:"health,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// A list of job databricks_cluster specifications that can be shared and reused by tasks of this job. Libraries cannot be declared in a shared job cluster. You must declare dependent libraries in task settings. Multi-task syntax
	JobCluster []JobClusterObservation `json:"jobCluster,omitempty" tf:"job_cluster,omitempty"`

	// (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for databricks_cluster resource.
	Library []LibraryObservation `json:"library,omitempty" tf:"library,omitempty"`

	// (Integer) An optional maximum allowed number of concurrent runs of the job. Defaults to 1.
	MaxConcurrentRuns *float64 `json:"maxConcurrentRuns,omitempty" tf:"max_concurrent_runs,omitempty"`

	// (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a FAILED or INTERNAL_ERROR lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: PENDING, RUNNING, TERMINATING, TERMINATED, SKIPPED or INTERNAL_ERROR.
	MaxRetries *float64 `json:"maxRetries,omitempty" tf:"max_retries,omitempty"`

	// (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
	MinRetryIntervalMillis *float64 `json:"minRetryIntervalMillis,omitempty" tf:"min_retry_interval_millis,omitempty"`

	// An optional name for the job. The default value is Untitled.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Same set of parameters as for databricks_cluster resource.
	NewCluster []JobNewClusterObservation `json:"newCluster,omitempty" tf:"new_cluster,omitempty"`

	// Task to run against the inputs list.
	NotebookTask []NotebookTaskObservation `json:"notebookTask,omitempty" tf:"notebook_task,omitempty"`

	// An optional block controlling the notification settings on the job level (described below).
	NotificationSettings []NotificationSettingsObservation `json:"notificationSettings,omitempty" tf:"notification_settings,omitempty"`

	Parameter []ParameterObservation `json:"parameter,omitempty" tf:"parameter,omitempty"`

	// Task to run against the inputs list.
	PipelineTask []PipelineTaskObservation `json:"pipelineTask,omitempty" tf:"pipeline_task,omitempty"`

	// Task to run against the inputs list.
	PythonWheelTask []PythonWheelTaskObservation `json:"pythonWheelTask,omitempty" tf:"python_wheel_task,omitempty"`

	Queue []QueueObservation `json:"queue,omitempty" tf:"queue,omitempty"`

	// (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
	RetryOnTimeout *bool `json:"retryOnTimeout,omitempty" tf:"retry_on_timeout,omitempty"`

	RunAs []RunAsObservation `json:"runAs,omitempty" tf:"run_as,omitempty"`

	// Task to run against the inputs list.
	RunJobTask []RunJobTaskObservation `json:"runJobTask,omitempty" tf:"run_job_task,omitempty"`

	// (List) An optional periodic schedule for this job. The default behavior is that the job runs when triggered by clicking Run Now in the Jobs UI or sending an API request to runNow. This field is a block and is documented below.
	Schedule []ScheduleObservation `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// Task to run against the inputs list.
	SparkJarTask []SparkJarTaskObservation `json:"sparkJarTask,omitempty" tf:"spark_jar_task,omitempty"`

	// Task to run against the inputs list.
	SparkPythonTask []SparkPythonTaskObservation `json:"sparkPythonTask,omitempty" tf:"spark_python_task,omitempty"`

	// Task to run against the inputs list.
	SparkSubmitTask []SparkSubmitTaskObservation `json:"sparkSubmitTask,omitempty" tf:"spark_submit_task,omitempty"`

	Tags map[string]*string `json:"tags,omitempty" tf:"tags,omitempty"`

	// Task to run against the inputs list.
	Task []TaskObservation `json:"task,omitempty" tf:"task,omitempty"`

	// (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
	TimeoutSeconds *float64 `json:"timeoutSeconds,omitempty" tf:"timeout_seconds,omitempty"`

	Trigger []TriggerObservation `json:"trigger,omitempty" tf:"trigger,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	URL *string `json:"url,omitempty" tf:"url,omitempty"`

	// (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this job begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
	WebhookNotifications []JobWebhookNotificationsObservation `json:"webhookNotifications,omitempty" tf:"webhook_notifications,omitempty"`
}

type JobParameters struct {

	// (Bool) Whenever the job is always running, like a Spark Streaming application, on every update restart the current active run or start it again, if nothing it is not running. False by default. Any job runs are started with parameters specified in spark_jar_task or spark_submit_task or spark_python_task or notebook_task blocks.
	// +kubebuilder:validation:Optional
	AlwaysRunning *bool `json:"alwaysRunning,omitempty" tf:"always_running,omitempty"`

	// +kubebuilder:validation:Optional
	Compute []ComputeParameters `json:"compute,omitempty" tf:"compute,omitempty"`

	// +kubebuilder:validation:Optional
	Continuous []ContinuousParameters `json:"continuous,omitempty" tf:"continuous,omitempty"`

	// (Bool) If true, the Databricks provider will stop and start the job as needed to ensure that the active run for the job reflects the deployed configuration. For continuous jobs, the provider respects the pause_status by stopping the current active run. This flag cannot be set for non-continuous jobs.
	// +kubebuilder:validation:Optional
	ControlRunState *bool `json:"controlRunState,omitempty" tf:"control_run_state,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	DbtTask []DbtTaskParameters `json:"dbtTask,omitempty" tf:"dbt_task,omitempty"`

	// +kubebuilder:validation:Optional
	Deployment []DeploymentParameters `json:"deployment,omitempty" tf:"deployment,omitempty"`

	// An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
	// +kubebuilder:validation:Optional
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// +kubebuilder:validation:Optional
	EditMode *string `json:"editMode,omitempty" tf:"edit_mode,omitempty"`

	// (List) An optional set of email addresses notified when runs of this job begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
	// +kubebuilder:validation:Optional
	EmailNotifications []EmailNotificationsParameters `json:"emailNotifications,omitempty" tf:"email_notifications,omitempty"`

	// If existing_cluster_id, the ID of an existing cluster that will be used for all runs of this job. When running jobs on an existing cluster, you may need to manually restart the cluster if it stops responding. We strongly suggest to use new_cluster for greater reliability.
	// +kubebuilder:validation:Optional
	ExistingClusterID *string `json:"existingClusterId,omitempty" tf:"existing_cluster_id,omitempty"`

	// +kubebuilder:validation:Optional
	Format *string `json:"format,omitempty" tf:"format,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	// +kubebuilder:validation:Optional
	GitSource []GitSourceParameters `json:"gitSource,omitempty" tf:"git_source,omitempty"`

	// An optional block that specifies the health conditions for the job (described below).
	// +kubebuilder:validation:Optional
	Health []HealthParameters `json:"health,omitempty" tf:"health,omitempty"`

	// A list of job databricks_cluster specifications that can be shared and reused by tasks of this job. Libraries cannot be declared in a shared job cluster. You must declare dependent libraries in task settings. Multi-task syntax
	// +kubebuilder:validation:Optional
	JobCluster []JobClusterParameters `json:"jobCluster,omitempty" tf:"job_cluster,omitempty"`

	// (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for databricks_cluster resource.
	// +kubebuilder:validation:Optional
	Library []LibraryParameters `json:"library,omitempty" tf:"library,omitempty"`

	// (Integer) An optional maximum allowed number of concurrent runs of the job. Defaults to 1.
	// +kubebuilder:validation:Optional
	MaxConcurrentRuns *float64 `json:"maxConcurrentRuns,omitempty" tf:"max_concurrent_runs,omitempty"`

	// (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a FAILED or INTERNAL_ERROR lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: PENDING, RUNNING, TERMINATING, TERMINATED, SKIPPED or INTERNAL_ERROR.
	// +kubebuilder:validation:Optional
	MaxRetries *float64 `json:"maxRetries,omitempty" tf:"max_retries,omitempty"`

	// (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
	// +kubebuilder:validation:Optional
	MinRetryIntervalMillis *float64 `json:"minRetryIntervalMillis,omitempty" tf:"min_retry_interval_millis,omitempty"`

	// An optional name for the job. The default value is Untitled.
	// +kubebuilder:validation:Optional
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// Same set of parameters as for databricks_cluster resource.
	// +kubebuilder:validation:Optional
	NewCluster []JobNewClusterParameters `json:"newCluster,omitempty" tf:"new_cluster,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	NotebookTask []NotebookTaskParameters `json:"notebookTask,omitempty" tf:"notebook_task,omitempty"`

	// An optional block controlling the notification settings on the job level (described below).
	// +kubebuilder:validation:Optional
	NotificationSettings []NotificationSettingsParameters `json:"notificationSettings,omitempty" tf:"notification_settings,omitempty"`

	// +kubebuilder:validation:Optional
	Parameter []ParameterParameters `json:"parameter,omitempty" tf:"parameter,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	PipelineTask []PipelineTaskParameters `json:"pipelineTask,omitempty" tf:"pipeline_task,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	PythonWheelTask []PythonWheelTaskParameters `json:"pythonWheelTask,omitempty" tf:"python_wheel_task,omitempty"`

	// +kubebuilder:validation:Optional
	Queue []QueueParameters `json:"queue,omitempty" tf:"queue,omitempty"`

	// (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
	// +kubebuilder:validation:Optional
	RetryOnTimeout *bool `json:"retryOnTimeout,omitempty" tf:"retry_on_timeout,omitempty"`

	// +kubebuilder:validation:Optional
	RunAs []RunAsParameters `json:"runAs,omitempty" tf:"run_as,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	RunJobTask []RunJobTaskParameters `json:"runJobTask,omitempty" tf:"run_job_task,omitempty"`

	// (List) An optional periodic schedule for this job. The default behavior is that the job runs when triggered by clicking Run Now in the Jobs UI or sending an API request to runNow. This field is a block and is documented below.
	// +kubebuilder:validation:Optional
	Schedule []ScheduleParameters `json:"schedule,omitempty" tf:"schedule,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	SparkJarTask []SparkJarTaskParameters `json:"sparkJarTask,omitempty" tf:"spark_jar_task,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	SparkPythonTask []SparkPythonTaskParameters `json:"sparkPythonTask,omitempty" tf:"spark_python_task,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	SparkSubmitTask []SparkSubmitTaskParameters `json:"sparkSubmitTask,omitempty" tf:"spark_submit_task,omitempty"`

	// +kubebuilder:validation:Optional
	Tags map[string]*string `json:"tags,omitempty" tf:"tags,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	Task []TaskParameters `json:"task,omitempty" tf:"task,omitempty"`

	// (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
	// +kubebuilder:validation:Optional
	TimeoutSeconds *float64 `json:"timeoutSeconds,omitempty" tf:"timeout_seconds,omitempty"`

	// +kubebuilder:validation:Optional
	Trigger []TriggerParameters `json:"trigger,omitempty" tf:"trigger,omitempty"`

	// (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this job begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
	// +kubebuilder:validation:Optional
	WebhookNotifications []JobWebhookNotificationsParameters `json:"webhookNotifications,omitempty" tf:"webhook_notifications,omitempty"`
}

type JobSourceInitParameters struct {
	DirtyState *string `json:"dirtyState,omitempty" tf:"dirty_state,omitempty"`

	// name of the Git branch to use. Conflicts with tag and commit.
	ImportFromGitBranch *string `json:"importFromGitBranch,omitempty" tf:"import_from_git_branch,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	JobConfigPath *string `json:"jobConfigPath,omitempty" tf:"job_config_path,omitempty"`
}

type JobSourceObservation struct {
	DirtyState *string `json:"dirtyState,omitempty" tf:"dirty_state,omitempty"`

	// name of the Git branch to use. Conflicts with tag and commit.
	ImportFromGitBranch *string `json:"importFromGitBranch,omitempty" tf:"import_from_git_branch,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	JobConfigPath *string `json:"jobConfigPath,omitempty" tf:"job_config_path,omitempty"`
}

type JobSourceParameters struct {

	// +kubebuilder:validation:Optional
	DirtyState *string `json:"dirtyState,omitempty" tf:"dirty_state,omitempty"`

	// name of the Git branch to use. Conflicts with tag and commit.
	// +kubebuilder:validation:Optional
	ImportFromGitBranch *string `json:"importFromGitBranch" tf:"import_from_git_branch,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	// +kubebuilder:validation:Optional
	JobConfigPath *string `json:"jobConfigPath" tf:"job_config_path,omitempty"`
}

type JobTaskHealthInitParameters struct {

	// (List) list of rules that are represented as objects with the following attributes:
	Rules []TaskHealthRulesInitParameters `json:"rules,omitempty" tf:"rules,omitempty"`
}

type JobTaskHealthObservation struct {

	// (List) list of rules that are represented as objects with the following attributes:
	Rules []TaskHealthRulesObservation `json:"rules,omitempty" tf:"rules,omitempty"`
}

type JobTaskHealthParameters struct {

	// (List) list of rules that are represented as objects with the following attributes:
	// +kubebuilder:validation:Optional
	Rules []TaskHealthRulesParameters `json:"rules" tf:"rules,omitempty"`
}

type JobTaskLibraryInitParameters struct {
	Cran []TaskLibraryCranInitParameters `json:"cran,omitempty" tf:"cran,omitempty"`

	Egg *string `json:"egg,omitempty" tf:"egg,omitempty"`

	Jar *string `json:"jar,omitempty" tf:"jar,omitempty"`

	Maven []TaskLibraryMavenInitParameters `json:"maven,omitempty" tf:"maven,omitempty"`

	Pypi []TaskLibraryPypiInitParameters `json:"pypi,omitempty" tf:"pypi,omitempty"`

	Whl *string `json:"whl,omitempty" tf:"whl,omitempty"`
}

type JobTaskLibraryObservation struct {
	Cran []TaskLibraryCranObservation `json:"cran,omitempty" tf:"cran,omitempty"`

	Egg *string `json:"egg,omitempty" tf:"egg,omitempty"`

	Jar *string `json:"jar,omitempty" tf:"jar,omitempty"`

	Maven []TaskLibraryMavenObservation `json:"maven,omitempty" tf:"maven,omitempty"`

	Pypi []TaskLibraryPypiObservation `json:"pypi,omitempty" tf:"pypi,omitempty"`

	Whl *string `json:"whl,omitempty" tf:"whl,omitempty"`
}

type JobTaskLibraryParameters struct {

	// +kubebuilder:validation:Optional
	Cran []TaskLibraryCranParameters `json:"cran,omitempty" tf:"cran,omitempty"`

	// +kubebuilder:validation:Optional
	Egg *string `json:"egg,omitempty" tf:"egg,omitempty"`

	// +kubebuilder:validation:Optional
	Jar *string `json:"jar,omitempty" tf:"jar,omitempty"`

	// +kubebuilder:validation:Optional
	Maven []TaskLibraryMavenParameters `json:"maven,omitempty" tf:"maven,omitempty"`

	// +kubebuilder:validation:Optional
	Pypi []TaskLibraryPypiParameters `json:"pypi,omitempty" tf:"pypi,omitempty"`

	// +kubebuilder:validation:Optional
	Whl *string `json:"whl,omitempty" tf:"whl,omitempty"`
}

type JobTaskNewClusterAutoscaleInitParameters struct {
	MaxWorkers *float64 `json:"maxWorkers,omitempty" tf:"max_workers,omitempty"`

	MinWorkers *float64 `json:"minWorkers,omitempty" tf:"min_workers,omitempty"`
}

type JobTaskNewClusterAutoscaleObservation struct {
	MaxWorkers *float64 `json:"maxWorkers,omitempty" tf:"max_workers,omitempty"`

	MinWorkers *float64 `json:"minWorkers,omitempty" tf:"min_workers,omitempty"`
}

type JobTaskNewClusterAutoscaleParameters struct {

	// +kubebuilder:validation:Optional
	MaxWorkers *float64 `json:"maxWorkers,omitempty" tf:"max_workers,omitempty"`

	// +kubebuilder:validation:Optional
	MinWorkers *float64 `json:"minWorkers,omitempty" tf:"min_workers,omitempty"`
}

type JobTaskNewClusterAwsAttributesInitParameters struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	EBSVolumeCount *float64 `json:"ebsVolumeCount,omitempty" tf:"ebs_volume_count,omitempty"`

	EBSVolumeSize *float64 `json:"ebsVolumeSize,omitempty" tf:"ebs_volume_size,omitempty"`

	EBSVolumeType *string `json:"ebsVolumeType,omitempty" tf:"ebs_volume_type,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	InstanceProfileArn *string `json:"instanceProfileArn,omitempty" tf:"instance_profile_arn,omitempty"`

	SpotBidPricePercent *float64 `json:"spotBidPricePercent,omitempty" tf:"spot_bid_price_percent,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type JobTaskNewClusterAwsAttributesObservation struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	EBSVolumeCount *float64 `json:"ebsVolumeCount,omitempty" tf:"ebs_volume_count,omitempty"`

	EBSVolumeSize *float64 `json:"ebsVolumeSize,omitempty" tf:"ebs_volume_size,omitempty"`

	EBSVolumeType *string `json:"ebsVolumeType,omitempty" tf:"ebs_volume_type,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	InstanceProfileArn *string `json:"instanceProfileArn,omitempty" tf:"instance_profile_arn,omitempty"`

	SpotBidPricePercent *float64 `json:"spotBidPricePercent,omitempty" tf:"spot_bid_price_percent,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type JobTaskNewClusterAwsAttributesParameters struct {

	// +kubebuilder:validation:Optional
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	// +kubebuilder:validation:Optional
	EBSVolumeCount *float64 `json:"ebsVolumeCount,omitempty" tf:"ebs_volume_count,omitempty"`

	// +kubebuilder:validation:Optional
	EBSVolumeSize *float64 `json:"ebsVolumeSize,omitempty" tf:"ebs_volume_size,omitempty"`

	// +kubebuilder:validation:Optional
	EBSVolumeType *string `json:"ebsVolumeType,omitempty" tf:"ebs_volume_type,omitempty"`

	// +kubebuilder:validation:Optional
	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	// +kubebuilder:validation:Optional
	InstanceProfileArn *string `json:"instanceProfileArn,omitempty" tf:"instance_profile_arn,omitempty"`

	// +kubebuilder:validation:Optional
	SpotBidPricePercent *float64 `json:"spotBidPricePercent,omitempty" tf:"spot_bid_price_percent,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type JobTaskNewClusterAzureAttributesInitParameters struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	SpotBidMaxPrice *float64 `json:"spotBidMaxPrice,omitempty" tf:"spot_bid_max_price,omitempty"`
}

type JobTaskNewClusterAzureAttributesObservation struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	SpotBidMaxPrice *float64 `json:"spotBidMaxPrice,omitempty" tf:"spot_bid_max_price,omitempty"`
}

type JobTaskNewClusterAzureAttributesParameters struct {

	// +kubebuilder:validation:Optional
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	// +kubebuilder:validation:Optional
	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	// +kubebuilder:validation:Optional
	SpotBidMaxPrice *float64 `json:"spotBidMaxPrice,omitempty" tf:"spot_bid_max_price,omitempty"`
}

type JobTaskNewClusterClusterLogConfInitParameters struct {
	Dbfs []TaskNewClusterClusterLogConfDbfsInitParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	S3 []TaskNewClusterClusterLogConfS3InitParameters `json:"s3,omitempty" tf:"s3,omitempty"`
}

type JobTaskNewClusterClusterLogConfObservation struct {
	Dbfs []TaskNewClusterClusterLogConfDbfsObservation `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	S3 []TaskNewClusterClusterLogConfS3Observation `json:"s3,omitempty" tf:"s3,omitempty"`
}

type JobTaskNewClusterClusterLogConfParameters struct {

	// +kubebuilder:validation:Optional
	Dbfs []TaskNewClusterClusterLogConfDbfsParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// +kubebuilder:validation:Optional
	S3 []TaskNewClusterClusterLogConfS3Parameters `json:"s3,omitempty" tf:"s3,omitempty"`
}

type JobTaskNewClusterClusterMountInfoInitParameters struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	LocalMountDirPath *string `json:"localMountDirPath,omitempty" tf:"local_mount_dir_path,omitempty"`

	NetworkFilesystemInfo []TaskNewClusterClusterMountInfoNetworkFilesystemInfoInitParameters `json:"networkFilesystemInfo,omitempty" tf:"network_filesystem_info,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	RemoteMountDirPath *string `json:"remoteMountDirPath,omitempty" tf:"remote_mount_dir_path,omitempty"`
}

type JobTaskNewClusterClusterMountInfoObservation struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	LocalMountDirPath *string `json:"localMountDirPath,omitempty" tf:"local_mount_dir_path,omitempty"`

	NetworkFilesystemInfo []TaskNewClusterClusterMountInfoNetworkFilesystemInfoObservation `json:"networkFilesystemInfo,omitempty" tf:"network_filesystem_info,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	RemoteMountDirPath *string `json:"remoteMountDirPath,omitempty" tf:"remote_mount_dir_path,omitempty"`
}

type JobTaskNewClusterClusterMountInfoParameters struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	// +kubebuilder:validation:Optional
	LocalMountDirPath *string `json:"localMountDirPath" tf:"local_mount_dir_path,omitempty"`

	// +kubebuilder:validation:Optional
	NetworkFilesystemInfo []TaskNewClusterClusterMountInfoNetworkFilesystemInfoParameters `json:"networkFilesystemInfo" tf:"network_filesystem_info,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	// +kubebuilder:validation:Optional
	RemoteMountDirPath *string `json:"remoteMountDirPath,omitempty" tf:"remote_mount_dir_path,omitempty"`
}

type JobTaskNewClusterDockerImageInitParameters struct {
	BasicAuth []TaskNewClusterDockerImageBasicAuthInitParameters `json:"basicAuth,omitempty" tf:"basic_auth,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	URL *string `json:"url,omitempty" tf:"url,omitempty"`
}

type JobTaskNewClusterDockerImageObservation struct {
	BasicAuth []TaskNewClusterDockerImageBasicAuthObservation `json:"basicAuth,omitempty" tf:"basic_auth,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	URL *string `json:"url,omitempty" tf:"url,omitempty"`
}

type JobTaskNewClusterDockerImageParameters struct {

	// +kubebuilder:validation:Optional
	BasicAuth []TaskNewClusterDockerImageBasicAuthParameters `json:"basicAuth,omitempty" tf:"basic_auth,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	// +kubebuilder:validation:Optional
	URL *string `json:"url" tf:"url,omitempty"`
}

type JobTaskNewClusterGCPAttributesInitParameters struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	BootDiskSize *float64 `json:"bootDiskSize,omitempty" tf:"boot_disk_size,omitempty"`

	GoogleServiceAccount *string `json:"googleServiceAccount,omitempty" tf:"google_service_account,omitempty"`

	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`

	UsePreemptibleExecutors *bool `json:"usePreemptibleExecutors,omitempty" tf:"use_preemptible_executors,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type JobTaskNewClusterGCPAttributesObservation struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	BootDiskSize *float64 `json:"bootDiskSize,omitempty" tf:"boot_disk_size,omitempty"`

	GoogleServiceAccount *string `json:"googleServiceAccount,omitempty" tf:"google_service_account,omitempty"`

	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`

	UsePreemptibleExecutors *bool `json:"usePreemptibleExecutors,omitempty" tf:"use_preemptible_executors,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type JobTaskNewClusterGCPAttributesParameters struct {

	// +kubebuilder:validation:Optional
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	// +kubebuilder:validation:Optional
	BootDiskSize *float64 `json:"bootDiskSize,omitempty" tf:"boot_disk_size,omitempty"`

	// +kubebuilder:validation:Optional
	GoogleServiceAccount *string `json:"googleServiceAccount,omitempty" tf:"google_service_account,omitempty"`

	// +kubebuilder:validation:Optional
	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`

	// +kubebuilder:validation:Optional
	UsePreemptibleExecutors *bool `json:"usePreemptibleExecutors,omitempty" tf:"use_preemptible_executors,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type JobTaskNewClusterInitParameters struct {
	ApplyPolicyDefaultValues *bool `json:"applyPolicyDefaultValues,omitempty" tf:"apply_policy_default_values,omitempty"`

	Autoscale []JobTaskNewClusterAutoscaleInitParameters `json:"autoscale,omitempty" tf:"autoscale,omitempty"`

	AutoterminationMinutes *float64 `json:"autoterminationMinutes,omitempty" tf:"autotermination_minutes,omitempty"`

	AwsAttributes []JobTaskNewClusterAwsAttributesInitParameters `json:"awsAttributes,omitempty" tf:"aws_attributes,omitempty"`

	AzureAttributes []JobTaskNewClusterAzureAttributesInitParameters `json:"azureAttributes,omitempty" tf:"azure_attributes,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	ClusterLogConf []JobTaskNewClusterClusterLogConfInitParameters `json:"clusterLogConf,omitempty" tf:"cluster_log_conf,omitempty"`

	ClusterMountInfo []JobTaskNewClusterClusterMountInfoInitParameters `json:"clusterMountInfo,omitempty" tf:"cluster_mount_info,omitempty"`

	// An optional name for the job. The default value is Untitled.
	ClusterName *string `json:"clusterName,omitempty" tf:"cluster_name,omitempty"`

	CustomTags map[string]*string `json:"customTags,omitempty" tf:"custom_tags,omitempty"`

	DataSecurityMode *string `json:"dataSecurityMode,omitempty" tf:"data_security_mode,omitempty"`

	DockerImage []JobTaskNewClusterDockerImageInitParameters `json:"dockerImage,omitempty" tf:"docker_image,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverInstancePoolID *string `json:"driverInstancePoolId,omitempty" tf:"driver_instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverNodeTypeID *string `json:"driverNodeTypeId,omitempty" tf:"driver_node_type_id,omitempty"`

	EnableElasticDisk *bool `json:"enableElasticDisk,omitempty" tf:"enable_elastic_disk,omitempty"`

	EnableLocalDiskEncryption *bool `json:"enableLocalDiskEncryption,omitempty" tf:"enable_local_disk_encryption,omitempty"`

	GCPAttributes []JobTaskNewClusterGCPAttributesInitParameters `json:"gcpAttributes,omitempty" tf:"gcp_attributes,omitempty"`

	IdempotencyToken *string `json:"idempotencyToken,omitempty" tf:"idempotency_token,omitempty"`

	InitScripts []JobTaskNewClusterInitScriptsInitParameters `json:"initScripts,omitempty" tf:"init_scripts,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	InstancePoolID *string `json:"instancePoolId,omitempty" tf:"instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	NodeTypeID *string `json:"nodeTypeId,omitempty" tf:"node_type_id,omitempty"`

	NumWorkers *float64 `json:"numWorkers,omitempty" tf:"num_workers,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	PolicyID *string `json:"policyId,omitempty" tf:"policy_id,omitempty"`

	RuntimeEngine *string `json:"runtimeEngine,omitempty" tf:"runtime_engine,omitempty"`

	SSHPublicKeys []*string `json:"sshPublicKeys,omitempty" tf:"ssh_public_keys,omitempty"`

	// An optional name for the job. The default value is Untitled.
	SingleUserName *string `json:"singleUserName,omitempty" tf:"single_user_name,omitempty"`

	SparkConf map[string]*string `json:"sparkConf,omitempty" tf:"spark_conf,omitempty"`

	SparkEnvVars map[string]*string `json:"sparkEnvVars,omitempty" tf:"spark_env_vars,omitempty"`

	// parameter in databricks_cluster and other resources.
	SparkVersion *string `json:"sparkVersion,omitempty" tf:"spark_version,omitempty"`

	WorkloadType []JobTaskNewClusterWorkloadTypeInitParameters `json:"workloadType,omitempty" tf:"workload_type,omitempty"`
}

type JobTaskNewClusterInitScriptsDbfsInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type JobTaskNewClusterInitScriptsDbfsObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type JobTaskNewClusterInitScriptsDbfsParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type JobTaskNewClusterInitScriptsInitParameters struct {
	Abfss []TaskNewClusterInitScriptsAbfssInitParameters `json:"abfss,omitempty" tf:"abfss,omitempty"`

	Dbfs []JobTaskNewClusterInitScriptsDbfsInitParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// block consisting of single string fields:
	File []TaskNewClusterInitScriptsFileInitParameters `json:"file,omitempty" tf:"file,omitempty"`

	Gcs []TaskNewClusterInitScriptsGcsInitParameters `json:"gcs,omitempty" tf:"gcs,omitempty"`

	S3 []JobTaskNewClusterInitScriptsS3InitParameters `json:"s3,omitempty" tf:"s3,omitempty"`

	Volumes []TaskNewClusterInitScriptsVolumesInitParameters `json:"volumes,omitempty" tf:"volumes,omitempty"`

	Workspace []TaskNewClusterInitScriptsWorkspaceInitParameters `json:"workspace,omitempty" tf:"workspace,omitempty"`
}

type JobTaskNewClusterInitScriptsObservation struct {
	Abfss []TaskNewClusterInitScriptsAbfssObservation `json:"abfss,omitempty" tf:"abfss,omitempty"`

	Dbfs []JobTaskNewClusterInitScriptsDbfsObservation `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// block consisting of single string fields:
	File []TaskNewClusterInitScriptsFileObservation `json:"file,omitempty" tf:"file,omitempty"`

	Gcs []TaskNewClusterInitScriptsGcsObservation `json:"gcs,omitempty" tf:"gcs,omitempty"`

	S3 []JobTaskNewClusterInitScriptsS3Observation `json:"s3,omitempty" tf:"s3,omitempty"`

	Volumes []TaskNewClusterInitScriptsVolumesObservation `json:"volumes,omitempty" tf:"volumes,omitempty"`

	Workspace []TaskNewClusterInitScriptsWorkspaceObservation `json:"workspace,omitempty" tf:"workspace,omitempty"`
}

type JobTaskNewClusterInitScriptsParameters struct {

	// +kubebuilder:validation:Optional
	Abfss []TaskNewClusterInitScriptsAbfssParameters `json:"abfss,omitempty" tf:"abfss,omitempty"`

	// +kubebuilder:validation:Optional
	Dbfs []JobTaskNewClusterInitScriptsDbfsParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// block consisting of single string fields:
	// +kubebuilder:validation:Optional
	File []TaskNewClusterInitScriptsFileParameters `json:"file,omitempty" tf:"file,omitempty"`

	// +kubebuilder:validation:Optional
	Gcs []TaskNewClusterInitScriptsGcsParameters `json:"gcs,omitempty" tf:"gcs,omitempty"`

	// +kubebuilder:validation:Optional
	S3 []JobTaskNewClusterInitScriptsS3Parameters `json:"s3,omitempty" tf:"s3,omitempty"`

	// +kubebuilder:validation:Optional
	Volumes []TaskNewClusterInitScriptsVolumesParameters `json:"volumes,omitempty" tf:"volumes,omitempty"`

	// +kubebuilder:validation:Optional
	Workspace []TaskNewClusterInitScriptsWorkspaceParameters `json:"workspace,omitempty" tf:"workspace,omitempty"`
}

type JobTaskNewClusterInitScriptsS3InitParameters struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type JobTaskNewClusterInitScriptsS3Observation struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type JobTaskNewClusterInitScriptsS3Parameters struct {

	// +kubebuilder:validation:Optional
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`

	// +kubebuilder:validation:Optional
	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	// +kubebuilder:validation:Optional
	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	// +kubebuilder:validation:Optional
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// +kubebuilder:validation:Optional
	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	// +kubebuilder:validation:Optional
	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type JobTaskNewClusterObservation struct {
	ApplyPolicyDefaultValues *bool `json:"applyPolicyDefaultValues,omitempty" tf:"apply_policy_default_values,omitempty"`

	Autoscale []JobTaskNewClusterAutoscaleObservation `json:"autoscale,omitempty" tf:"autoscale,omitempty"`

	AutoterminationMinutes *float64 `json:"autoterminationMinutes,omitempty" tf:"autotermination_minutes,omitempty"`

	AwsAttributes []JobTaskNewClusterAwsAttributesObservation `json:"awsAttributes,omitempty" tf:"aws_attributes,omitempty"`

	AzureAttributes []JobTaskNewClusterAzureAttributesObservation `json:"azureAttributes,omitempty" tf:"azure_attributes,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	ClusterLogConf []JobTaskNewClusterClusterLogConfObservation `json:"clusterLogConf,omitempty" tf:"cluster_log_conf,omitempty"`

	ClusterMountInfo []JobTaskNewClusterClusterMountInfoObservation `json:"clusterMountInfo,omitempty" tf:"cluster_mount_info,omitempty"`

	// An optional name for the job. The default value is Untitled.
	ClusterName *string `json:"clusterName,omitempty" tf:"cluster_name,omitempty"`

	CustomTags map[string]*string `json:"customTags,omitempty" tf:"custom_tags,omitempty"`

	DataSecurityMode *string `json:"dataSecurityMode,omitempty" tf:"data_security_mode,omitempty"`

	DockerImage []JobTaskNewClusterDockerImageObservation `json:"dockerImage,omitempty" tf:"docker_image,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverInstancePoolID *string `json:"driverInstancePoolId,omitempty" tf:"driver_instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverNodeTypeID *string `json:"driverNodeTypeId,omitempty" tf:"driver_node_type_id,omitempty"`

	EnableElasticDisk *bool `json:"enableElasticDisk,omitempty" tf:"enable_elastic_disk,omitempty"`

	EnableLocalDiskEncryption *bool `json:"enableLocalDiskEncryption,omitempty" tf:"enable_local_disk_encryption,omitempty"`

	GCPAttributes []JobTaskNewClusterGCPAttributesObservation `json:"gcpAttributes,omitempty" tf:"gcp_attributes,omitempty"`

	IdempotencyToken *string `json:"idempotencyToken,omitempty" tf:"idempotency_token,omitempty"`

	InitScripts []JobTaskNewClusterInitScriptsObservation `json:"initScripts,omitempty" tf:"init_scripts,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	InstancePoolID *string `json:"instancePoolId,omitempty" tf:"instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	NodeTypeID *string `json:"nodeTypeId,omitempty" tf:"node_type_id,omitempty"`

	NumWorkers *float64 `json:"numWorkers,omitempty" tf:"num_workers,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	PolicyID *string `json:"policyId,omitempty" tf:"policy_id,omitempty"`

	RuntimeEngine *string `json:"runtimeEngine,omitempty" tf:"runtime_engine,omitempty"`

	SSHPublicKeys []*string `json:"sshPublicKeys,omitempty" tf:"ssh_public_keys,omitempty"`

	// An optional name for the job. The default value is Untitled.
	SingleUserName *string `json:"singleUserName,omitempty" tf:"single_user_name,omitempty"`

	SparkConf map[string]*string `json:"sparkConf,omitempty" tf:"spark_conf,omitempty"`

	SparkEnvVars map[string]*string `json:"sparkEnvVars,omitempty" tf:"spark_env_vars,omitempty"`

	// parameter in databricks_cluster and other resources.
	SparkVersion *string `json:"sparkVersion,omitempty" tf:"spark_version,omitempty"`

	WorkloadType []JobTaskNewClusterWorkloadTypeObservation `json:"workloadType,omitempty" tf:"workload_type,omitempty"`
}

type JobTaskNewClusterParameters struct {

	// +kubebuilder:validation:Optional
	ApplyPolicyDefaultValues *bool `json:"applyPolicyDefaultValues,omitempty" tf:"apply_policy_default_values,omitempty"`

	// +kubebuilder:validation:Optional
	Autoscale []JobTaskNewClusterAutoscaleParameters `json:"autoscale,omitempty" tf:"autoscale,omitempty"`

	// +kubebuilder:validation:Optional
	AutoterminationMinutes *float64 `json:"autoterminationMinutes,omitempty" tf:"autotermination_minutes,omitempty"`

	// +kubebuilder:validation:Optional
	AwsAttributes []JobTaskNewClusterAwsAttributesParameters `json:"awsAttributes,omitempty" tf:"aws_attributes,omitempty"`

	// +kubebuilder:validation:Optional
	AzureAttributes []JobTaskNewClusterAzureAttributesParameters `json:"azureAttributes,omitempty" tf:"azure_attributes,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// +kubebuilder:validation:Optional
	ClusterLogConf []JobTaskNewClusterClusterLogConfParameters `json:"clusterLogConf,omitempty" tf:"cluster_log_conf,omitempty"`

	// +kubebuilder:validation:Optional
	ClusterMountInfo []JobTaskNewClusterClusterMountInfoParameters `json:"clusterMountInfo,omitempty" tf:"cluster_mount_info,omitempty"`

	// An optional name for the job. The default value is Untitled.
	// +kubebuilder:validation:Optional
	ClusterName *string `json:"clusterName,omitempty" tf:"cluster_name,omitempty"`

	// +kubebuilder:validation:Optional
	CustomTags map[string]*string `json:"customTags,omitempty" tf:"custom_tags,omitempty"`

	// +kubebuilder:validation:Optional
	DataSecurityMode *string `json:"dataSecurityMode,omitempty" tf:"data_security_mode,omitempty"`

	// +kubebuilder:validation:Optional
	DockerImage []JobTaskNewClusterDockerImageParameters `json:"dockerImage,omitempty" tf:"docker_image,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	DriverInstancePoolID *string `json:"driverInstancePoolId,omitempty" tf:"driver_instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	DriverNodeTypeID *string `json:"driverNodeTypeId,omitempty" tf:"driver_node_type_id,omitempty"`

	// +kubebuilder:validation:Optional
	EnableElasticDisk *bool `json:"enableElasticDisk,omitempty" tf:"enable_elastic_disk,omitempty"`

	// +kubebuilder:validation:Optional
	EnableLocalDiskEncryption *bool `json:"enableLocalDiskEncryption,omitempty" tf:"enable_local_disk_encryption,omitempty"`

	// +kubebuilder:validation:Optional
	GCPAttributes []JobTaskNewClusterGCPAttributesParameters `json:"gcpAttributes,omitempty" tf:"gcp_attributes,omitempty"`

	// +kubebuilder:validation:Optional
	IdempotencyToken *string `json:"idempotencyToken,omitempty" tf:"idempotency_token,omitempty"`

	// +kubebuilder:validation:Optional
	InitScripts []JobTaskNewClusterInitScriptsParameters `json:"initScripts,omitempty" tf:"init_scripts,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	InstancePoolID *string `json:"instancePoolId,omitempty" tf:"instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	NodeTypeID *string `json:"nodeTypeId,omitempty" tf:"node_type_id,omitempty"`

	// +kubebuilder:validation:Optional
	NumWorkers *float64 `json:"numWorkers,omitempty" tf:"num_workers,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	PolicyID *string `json:"policyId,omitempty" tf:"policy_id,omitempty"`

	// +kubebuilder:validation:Optional
	RuntimeEngine *string `json:"runtimeEngine,omitempty" tf:"runtime_engine,omitempty"`

	// +kubebuilder:validation:Optional
	SSHPublicKeys []*string `json:"sshPublicKeys,omitempty" tf:"ssh_public_keys,omitempty"`

	// An optional name for the job. The default value is Untitled.
	// +kubebuilder:validation:Optional
	SingleUserName *string `json:"singleUserName,omitempty" tf:"single_user_name,omitempty"`

	// +kubebuilder:validation:Optional
	SparkConf map[string]*string `json:"sparkConf,omitempty" tf:"spark_conf,omitempty"`

	// +kubebuilder:validation:Optional
	SparkEnvVars map[string]*string `json:"sparkEnvVars,omitempty" tf:"spark_env_vars,omitempty"`

	// parameter in databricks_cluster and other resources.
	// +kubebuilder:validation:Optional
	SparkVersion *string `json:"sparkVersion" tf:"spark_version,omitempty"`

	// +kubebuilder:validation:Optional
	WorkloadType []JobTaskNewClusterWorkloadTypeParameters `json:"workloadType,omitempty" tf:"workload_type,omitempty"`
}

type JobTaskNewClusterWorkloadTypeInitParameters struct {
	Clients []TaskNewClusterWorkloadTypeClientsInitParameters `json:"clients,omitempty" tf:"clients,omitempty"`
}

type JobTaskNewClusterWorkloadTypeObservation struct {
	Clients []TaskNewClusterWorkloadTypeClientsObservation `json:"clients,omitempty" tf:"clients,omitempty"`
}

type JobTaskNewClusterWorkloadTypeParameters struct {

	// +kubebuilder:validation:Optional
	Clients []TaskNewClusterWorkloadTypeClientsParameters `json:"clients" tf:"clients,omitempty"`
}

type JobTaskNotebookTaskInitParameters struct {

	// (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the jobs base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using dbutils.widgets.get.
	BaseParameters map[string]*string `json:"baseParameters,omitempty" tf:"base_parameters,omitempty"`

	// The path of the databricks_notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
	NotebookPath *string `json:"notebookPath,omitempty" tf:"notebook_path,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type JobTaskNotebookTaskObservation struct {

	// (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the jobs base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using dbutils.widgets.get.
	BaseParameters map[string]*string `json:"baseParameters,omitempty" tf:"base_parameters,omitempty"`

	// The path of the databricks_notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
	NotebookPath *string `json:"notebookPath,omitempty" tf:"notebook_path,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type JobTaskNotebookTaskParameters struct {

	// (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the jobs base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using dbutils.widgets.get.
	// +kubebuilder:validation:Optional
	BaseParameters map[string]*string `json:"baseParameters,omitempty" tf:"base_parameters,omitempty"`

	// The path of the databricks_notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
	// +kubebuilder:validation:Optional
	NotebookPath *string `json:"notebookPath" tf:"notebook_path,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	// +kubebuilder:validation:Optional
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type JobTaskNotificationSettingsInitParameters struct {

	// (Bool) do not send notifications to recipients specified in on_start for the retried runs and do not send notifications to recipients specified in on_failure until the last retry of the run.
	AlertOnLastAttempt *bool `json:"alertOnLastAttempt,omitempty" tf:"alert_on_last_attempt,omitempty"`

	// (Bool) don't send alert for cancelled runs.
	NoAlertForCanceledRuns *bool `json:"noAlertForCanceledRuns,omitempty" tf:"no_alert_for_canceled_runs,omitempty"`

	// (Bool) don't send alert for skipped runs.
	NoAlertForSkippedRuns *bool `json:"noAlertForSkippedRuns,omitempty" tf:"no_alert_for_skipped_runs,omitempty"`
}

type JobTaskNotificationSettingsObservation struct {

	// (Bool) do not send notifications to recipients specified in on_start for the retried runs and do not send notifications to recipients specified in on_failure until the last retry of the run.
	AlertOnLastAttempt *bool `json:"alertOnLastAttempt,omitempty" tf:"alert_on_last_attempt,omitempty"`

	// (Bool) don't send alert for cancelled runs.
	NoAlertForCanceledRuns *bool `json:"noAlertForCanceledRuns,omitempty" tf:"no_alert_for_canceled_runs,omitempty"`

	// (Bool) don't send alert for skipped runs.
	NoAlertForSkippedRuns *bool `json:"noAlertForSkippedRuns,omitempty" tf:"no_alert_for_skipped_runs,omitempty"`
}

type JobTaskNotificationSettingsParameters struct {

	// (Bool) do not send notifications to recipients specified in on_start for the retried runs and do not send notifications to recipients specified in on_failure until the last retry of the run.
	// +kubebuilder:validation:Optional
	AlertOnLastAttempt *bool `json:"alertOnLastAttempt,omitempty" tf:"alert_on_last_attempt,omitempty"`

	// (Bool) don't send alert for cancelled runs.
	// +kubebuilder:validation:Optional
	NoAlertForCanceledRuns *bool `json:"noAlertForCanceledRuns,omitempty" tf:"no_alert_for_canceled_runs,omitempty"`

	// (Bool) don't send alert for skipped runs.
	// +kubebuilder:validation:Optional
	NoAlertForSkippedRuns *bool `json:"noAlertForSkippedRuns,omitempty" tf:"no_alert_for_skipped_runs,omitempty"`
}

type JobTaskPipelineTaskInitParameters struct {

	// (Bool) Specifies if there should be full refresh of the pipeline.
	FullRefresh *bool `json:"fullRefresh,omitempty" tf:"full_refresh,omitempty"`

	// The pipeline's unique ID.
	PipelineID *string `json:"pipelineId,omitempty" tf:"pipeline_id,omitempty"`
}

type JobTaskPipelineTaskObservation struct {

	// (Bool) Specifies if there should be full refresh of the pipeline.
	FullRefresh *bool `json:"fullRefresh,omitempty" tf:"full_refresh,omitempty"`

	// The pipeline's unique ID.
	PipelineID *string `json:"pipelineId,omitempty" tf:"pipeline_id,omitempty"`
}

type JobTaskPipelineTaskParameters struct {

	// (Bool) Specifies if there should be full refresh of the pipeline.
	// +kubebuilder:validation:Optional
	FullRefresh *bool `json:"fullRefresh,omitempty" tf:"full_refresh,omitempty"`

	// The pipeline's unique ID.
	// +kubebuilder:validation:Optional
	PipelineID *string `json:"pipelineId" tf:"pipeline_id,omitempty"`
}

type JobTaskPythonWheelTaskInitParameters struct {

	// Python function as entry point for the task
	EntryPoint *string `json:"entryPoint,omitempty" tf:"entry_point,omitempty"`

	// Named parameters for the task
	NamedParameters map[string]*string `json:"namedParameters,omitempty" tf:"named_parameters,omitempty"`

	// Name of Python package
	PackageName *string `json:"packageName,omitempty" tf:"package_name,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type JobTaskPythonWheelTaskObservation struct {

	// Python function as entry point for the task
	EntryPoint *string `json:"entryPoint,omitempty" tf:"entry_point,omitempty"`

	// Named parameters for the task
	NamedParameters map[string]*string `json:"namedParameters,omitempty" tf:"named_parameters,omitempty"`

	// Name of Python package
	PackageName *string `json:"packageName,omitempty" tf:"package_name,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type JobTaskPythonWheelTaskParameters struct {

	// Python function as entry point for the task
	// +kubebuilder:validation:Optional
	EntryPoint *string `json:"entryPoint,omitempty" tf:"entry_point,omitempty"`

	// Named parameters for the task
	// +kubebuilder:validation:Optional
	NamedParameters map[string]*string `json:"namedParameters,omitempty" tf:"named_parameters,omitempty"`

	// Name of Python package
	// +kubebuilder:validation:Optional
	PackageName *string `json:"packageName,omitempty" tf:"package_name,omitempty"`

	// (List) Parameters passed to the main method.
	// +kubebuilder:validation:Optional
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type JobTaskRunJobTaskInitParameters struct {

	// (String) ID of the job
	JobID *float64 `json:"jobId,omitempty" tf:"job_id,omitempty"`

	// (Map) Job parameters for the task
	JobParameters map[string]*string `json:"jobParameters,omitempty" tf:"job_parameters,omitempty"`
}

type JobTaskRunJobTaskObservation struct {

	// (String) ID of the job
	JobID *float64 `json:"jobId,omitempty" tf:"job_id,omitempty"`

	// (Map) Job parameters for the task
	JobParameters map[string]*string `json:"jobParameters,omitempty" tf:"job_parameters,omitempty"`
}

type JobTaskRunJobTaskParameters struct {

	// (String) ID of the job
	// +kubebuilder:validation:Optional
	JobID *float64 `json:"jobId" tf:"job_id,omitempty"`

	// (Map) Job parameters for the task
	// +kubebuilder:validation:Optional
	JobParameters map[string]*string `json:"jobParameters,omitempty" tf:"job_parameters,omitempty"`
}

type JobTaskSparkJarTaskInitParameters struct {
	JarURI *string `json:"jarUri,omitempty" tf:"jar_uri,omitempty"`

	// The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use SparkContext.getOrCreate to obtain a Spark context; otherwise, runs of the job will fail.
	MainClassName *string `json:"mainClassName,omitempty" tf:"main_class_name,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type JobTaskSparkJarTaskObservation struct {
	JarURI *string `json:"jarUri,omitempty" tf:"jar_uri,omitempty"`

	// The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use SparkContext.getOrCreate to obtain a Spark context; otherwise, runs of the job will fail.
	MainClassName *string `json:"mainClassName,omitempty" tf:"main_class_name,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type JobTaskSparkJarTaskParameters struct {

	// +kubebuilder:validation:Optional
	JarURI *string `json:"jarUri,omitempty" tf:"jar_uri,omitempty"`

	// The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use SparkContext.getOrCreate to obtain a Spark context; otherwise, runs of the job will fail.
	// +kubebuilder:validation:Optional
	MainClassName *string `json:"mainClassName,omitempty" tf:"main_class_name,omitempty"`

	// (List) Parameters passed to the main method.
	// +kubebuilder:validation:Optional
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type JobTaskSparkPythonTaskInitParameters struct {

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. s3:/, abfss:/, gs:/), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with /Repos. For files stored in a remote repository, the path must be relative. This field is required.
	PythonFile *string `json:"pythonFile,omitempty" tf:"python_file,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type JobTaskSparkPythonTaskObservation struct {

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. s3:/, abfss:/, gs:/), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with /Repos. For files stored in a remote repository, the path must be relative. This field is required.
	PythonFile *string `json:"pythonFile,omitempty" tf:"python_file,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type JobTaskSparkPythonTaskParameters struct {

	// (List) Parameters passed to the main method.
	// +kubebuilder:validation:Optional
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. s3:/, abfss:/, gs:/), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with /Repos. For files stored in a remote repository, the path must be relative. This field is required.
	// +kubebuilder:validation:Optional
	PythonFile *string `json:"pythonFile" tf:"python_file,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	// +kubebuilder:validation:Optional
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type JobTaskSparkSubmitTaskInitParameters struct {

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type JobTaskSparkSubmitTaskObservation struct {

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type JobTaskSparkSubmitTaskParameters struct {

	// (List) Parameters passed to the main method.
	// +kubebuilder:validation:Optional
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type JobWebhookNotificationsInitParameters struct {

	// (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	OnDurationWarningThresholdExceeded []JobWebhookNotificationsOnDurationWarningThresholdExceededInitParameters `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
	OnFailure []JobWebhookNotificationsOnFailureInitParameters `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
	OnStart []JobWebhookNotificationsOnStartInitParameters `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
	OnSuccess []JobWebhookNotificationsOnSuccessInitParameters `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type JobWebhookNotificationsObservation struct {

	// (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	OnDurationWarningThresholdExceeded []JobWebhookNotificationsOnDurationWarningThresholdExceededObservation `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
	OnFailure []JobWebhookNotificationsOnFailureObservation `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
	OnStart []JobWebhookNotificationsOnStartObservation `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
	OnSuccess []JobWebhookNotificationsOnSuccessObservation `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type JobWebhookNotificationsOnDurationWarningThresholdExceededInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type JobWebhookNotificationsOnDurationWarningThresholdExceededObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type JobWebhookNotificationsOnDurationWarningThresholdExceededParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type JobWebhookNotificationsOnFailureInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type JobWebhookNotificationsOnFailureObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type JobWebhookNotificationsOnFailureParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type JobWebhookNotificationsOnStartInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type JobWebhookNotificationsOnStartObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type JobWebhookNotificationsOnStartParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type JobWebhookNotificationsOnSuccessInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type JobWebhookNotificationsOnSuccessObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type JobWebhookNotificationsOnSuccessParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type JobWebhookNotificationsParameters struct {

	// (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	// +kubebuilder:validation:Optional
	OnDurationWarningThresholdExceeded []JobWebhookNotificationsOnDurationWarningThresholdExceededParameters `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
	// +kubebuilder:validation:Optional
	OnFailure []JobWebhookNotificationsOnFailureParameters `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
	// +kubebuilder:validation:Optional
	OnStart []JobWebhookNotificationsOnStartParameters `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
	// +kubebuilder:validation:Optional
	OnSuccess []JobWebhookNotificationsOnSuccessParameters `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type LibraryCranInitParameters struct {
	Package *string `json:"package,omitempty" tf:"package,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type LibraryCranObservation struct {
	Package *string `json:"package,omitempty" tf:"package,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type LibraryCranParameters struct {

	// +kubebuilder:validation:Optional
	Package *string `json:"package" tf:"package,omitempty"`

	// +kubebuilder:validation:Optional
	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type LibraryInitParameters struct {
	Cran []CranInitParameters `json:"cran,omitempty" tf:"cran,omitempty"`

	Egg *string `json:"egg,omitempty" tf:"egg,omitempty"`

	Jar *string `json:"jar,omitempty" tf:"jar,omitempty"`

	Maven []MavenInitParameters `json:"maven,omitempty" tf:"maven,omitempty"`

	Pypi []PypiInitParameters `json:"pypi,omitempty" tf:"pypi,omitempty"`

	Whl *string `json:"whl,omitempty" tf:"whl,omitempty"`
}

type LibraryMavenInitParameters struct {
	Coordinates *string `json:"coordinates,omitempty" tf:"coordinates,omitempty"`

	Exclusions []*string `json:"exclusions,omitempty" tf:"exclusions,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type LibraryMavenObservation struct {
	Coordinates *string `json:"coordinates,omitempty" tf:"coordinates,omitempty"`

	Exclusions []*string `json:"exclusions,omitempty" tf:"exclusions,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type LibraryMavenParameters struct {

	// +kubebuilder:validation:Optional
	Coordinates *string `json:"coordinates" tf:"coordinates,omitempty"`

	// +kubebuilder:validation:Optional
	Exclusions []*string `json:"exclusions,omitempty" tf:"exclusions,omitempty"`

	// +kubebuilder:validation:Optional
	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type LibraryObservation struct {
	Cran []CranObservation `json:"cran,omitempty" tf:"cran,omitempty"`

	Egg *string `json:"egg,omitempty" tf:"egg,omitempty"`

	Jar *string `json:"jar,omitempty" tf:"jar,omitempty"`

	Maven []MavenObservation `json:"maven,omitempty" tf:"maven,omitempty"`

	Pypi []PypiObservation `json:"pypi,omitempty" tf:"pypi,omitempty"`

	Whl *string `json:"whl,omitempty" tf:"whl,omitempty"`
}

type LibraryParameters struct {

	// +kubebuilder:validation:Optional
	Cran []CranParameters `json:"cran,omitempty" tf:"cran,omitempty"`

	// +kubebuilder:validation:Optional
	Egg *string `json:"egg,omitempty" tf:"egg,omitempty"`

	// +kubebuilder:validation:Optional
	Jar *string `json:"jar,omitempty" tf:"jar,omitempty"`

	// +kubebuilder:validation:Optional
	Maven []MavenParameters `json:"maven,omitempty" tf:"maven,omitempty"`

	// +kubebuilder:validation:Optional
	Pypi []PypiParameters `json:"pypi,omitempty" tf:"pypi,omitempty"`

	// +kubebuilder:validation:Optional
	Whl *string `json:"whl,omitempty" tf:"whl,omitempty"`
}

type LibraryPypiInitParameters struct {
	Package *string `json:"package,omitempty" tf:"package,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type LibraryPypiObservation struct {
	Package *string `json:"package,omitempty" tf:"package,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type LibraryPypiParameters struct {

	// +kubebuilder:validation:Optional
	Package *string `json:"package" tf:"package,omitempty"`

	// +kubebuilder:validation:Optional
	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type MavenInitParameters struct {
	Coordinates *string `json:"coordinates,omitempty" tf:"coordinates,omitempty"`

	Exclusions []*string `json:"exclusions,omitempty" tf:"exclusions,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type MavenObservation struct {
	Coordinates *string `json:"coordinates,omitempty" tf:"coordinates,omitempty"`

	Exclusions []*string `json:"exclusions,omitempty" tf:"exclusions,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type MavenParameters struct {

	// +kubebuilder:validation:Optional
	Coordinates *string `json:"coordinates" tf:"coordinates,omitempty"`

	// +kubebuilder:validation:Optional
	Exclusions []*string `json:"exclusions,omitempty" tf:"exclusions,omitempty"`

	// +kubebuilder:validation:Optional
	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type NetworkFilesystemInfoInitParameters struct {
	MountOptions *string `json:"mountOptions,omitempty" tf:"mount_options,omitempty"`

	ServerAddress *string `json:"serverAddress,omitempty" tf:"server_address,omitempty"`
}

type NetworkFilesystemInfoObservation struct {
	MountOptions *string `json:"mountOptions,omitempty" tf:"mount_options,omitempty"`

	ServerAddress *string `json:"serverAddress,omitempty" tf:"server_address,omitempty"`
}

type NetworkFilesystemInfoParameters struct {

	// +kubebuilder:validation:Optional
	MountOptions *string `json:"mountOptions,omitempty" tf:"mount_options,omitempty"`

	// +kubebuilder:validation:Optional
	ServerAddress *string `json:"serverAddress" tf:"server_address,omitempty"`
}

type NewClusterAutoscaleInitParameters struct {
	MaxWorkers *float64 `json:"maxWorkers,omitempty" tf:"max_workers,omitempty"`

	MinWorkers *float64 `json:"minWorkers,omitempty" tf:"min_workers,omitempty"`
}

type NewClusterAutoscaleObservation struct {
	MaxWorkers *float64 `json:"maxWorkers,omitempty" tf:"max_workers,omitempty"`

	MinWorkers *float64 `json:"minWorkers,omitempty" tf:"min_workers,omitempty"`
}

type NewClusterAutoscaleParameters struct {

	// +kubebuilder:validation:Optional
	MaxWorkers *float64 `json:"maxWorkers,omitempty" tf:"max_workers,omitempty"`

	// +kubebuilder:validation:Optional
	MinWorkers *float64 `json:"minWorkers,omitempty" tf:"min_workers,omitempty"`
}

type NewClusterAwsAttributesInitParameters struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	EBSVolumeCount *float64 `json:"ebsVolumeCount,omitempty" tf:"ebs_volume_count,omitempty"`

	EBSVolumeSize *float64 `json:"ebsVolumeSize,omitempty" tf:"ebs_volume_size,omitempty"`

	EBSVolumeType *string `json:"ebsVolumeType,omitempty" tf:"ebs_volume_type,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	InstanceProfileArn *string `json:"instanceProfileArn,omitempty" tf:"instance_profile_arn,omitempty"`

	SpotBidPricePercent *float64 `json:"spotBidPricePercent,omitempty" tf:"spot_bid_price_percent,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type NewClusterAwsAttributesObservation struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	EBSVolumeCount *float64 `json:"ebsVolumeCount,omitempty" tf:"ebs_volume_count,omitempty"`

	EBSVolumeSize *float64 `json:"ebsVolumeSize,omitempty" tf:"ebs_volume_size,omitempty"`

	EBSVolumeType *string `json:"ebsVolumeType,omitempty" tf:"ebs_volume_type,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	InstanceProfileArn *string `json:"instanceProfileArn,omitempty" tf:"instance_profile_arn,omitempty"`

	SpotBidPricePercent *float64 `json:"spotBidPricePercent,omitempty" tf:"spot_bid_price_percent,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type NewClusterAwsAttributesParameters struct {

	// +kubebuilder:validation:Optional
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	// +kubebuilder:validation:Optional
	EBSVolumeCount *float64 `json:"ebsVolumeCount,omitempty" tf:"ebs_volume_count,omitempty"`

	// +kubebuilder:validation:Optional
	EBSVolumeSize *float64 `json:"ebsVolumeSize,omitempty" tf:"ebs_volume_size,omitempty"`

	// +kubebuilder:validation:Optional
	EBSVolumeType *string `json:"ebsVolumeType,omitempty" tf:"ebs_volume_type,omitempty"`

	// +kubebuilder:validation:Optional
	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	// +kubebuilder:validation:Optional
	InstanceProfileArn *string `json:"instanceProfileArn,omitempty" tf:"instance_profile_arn,omitempty"`

	// +kubebuilder:validation:Optional
	SpotBidPricePercent *float64 `json:"spotBidPricePercent,omitempty" tf:"spot_bid_price_percent,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type NewClusterAzureAttributesInitParameters struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	SpotBidMaxPrice *float64 `json:"spotBidMaxPrice,omitempty" tf:"spot_bid_max_price,omitempty"`
}

type NewClusterAzureAttributesObservation struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	SpotBidMaxPrice *float64 `json:"spotBidMaxPrice,omitempty" tf:"spot_bid_max_price,omitempty"`
}

type NewClusterAzureAttributesParameters struct {

	// +kubebuilder:validation:Optional
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	// +kubebuilder:validation:Optional
	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	// +kubebuilder:validation:Optional
	SpotBidMaxPrice *float64 `json:"spotBidMaxPrice,omitempty" tf:"spot_bid_max_price,omitempty"`
}

type NewClusterClusterLogConfDbfsInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type NewClusterClusterLogConfDbfsObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type NewClusterClusterLogConfDbfsParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type NewClusterClusterLogConfInitParameters struct {
	Dbfs []ClusterLogConfDbfsInitParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	S3 []ClusterLogConfS3InitParameters `json:"s3,omitempty" tf:"s3,omitempty"`
}

type NewClusterClusterLogConfObservation struct {
	Dbfs []ClusterLogConfDbfsObservation `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	S3 []ClusterLogConfS3Observation `json:"s3,omitempty" tf:"s3,omitempty"`
}

type NewClusterClusterLogConfParameters struct {

	// +kubebuilder:validation:Optional
	Dbfs []ClusterLogConfDbfsParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// +kubebuilder:validation:Optional
	S3 []ClusterLogConfS3Parameters `json:"s3,omitempty" tf:"s3,omitempty"`
}

type NewClusterClusterLogConfS3InitParameters struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type NewClusterClusterLogConfS3Observation struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type NewClusterClusterLogConfS3Parameters struct {

	// +kubebuilder:validation:Optional
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`

	// +kubebuilder:validation:Optional
	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	// +kubebuilder:validation:Optional
	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	// +kubebuilder:validation:Optional
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// +kubebuilder:validation:Optional
	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	// +kubebuilder:validation:Optional
	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type NewClusterClusterMountInfoInitParameters struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	LocalMountDirPath *string `json:"localMountDirPath,omitempty" tf:"local_mount_dir_path,omitempty"`

	NetworkFilesystemInfo []ClusterMountInfoNetworkFilesystemInfoInitParameters `json:"networkFilesystemInfo,omitempty" tf:"network_filesystem_info,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	RemoteMountDirPath *string `json:"remoteMountDirPath,omitempty" tf:"remote_mount_dir_path,omitempty"`
}

type NewClusterClusterMountInfoNetworkFilesystemInfoInitParameters struct {
	MountOptions *string `json:"mountOptions,omitempty" tf:"mount_options,omitempty"`

	ServerAddress *string `json:"serverAddress,omitempty" tf:"server_address,omitempty"`
}

type NewClusterClusterMountInfoNetworkFilesystemInfoObservation struct {
	MountOptions *string `json:"mountOptions,omitempty" tf:"mount_options,omitempty"`

	ServerAddress *string `json:"serverAddress,omitempty" tf:"server_address,omitempty"`
}

type NewClusterClusterMountInfoNetworkFilesystemInfoParameters struct {

	// +kubebuilder:validation:Optional
	MountOptions *string `json:"mountOptions,omitempty" tf:"mount_options,omitempty"`

	// +kubebuilder:validation:Optional
	ServerAddress *string `json:"serverAddress" tf:"server_address,omitempty"`
}

type NewClusterClusterMountInfoObservation struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	LocalMountDirPath *string `json:"localMountDirPath,omitempty" tf:"local_mount_dir_path,omitempty"`

	NetworkFilesystemInfo []ClusterMountInfoNetworkFilesystemInfoObservation `json:"networkFilesystemInfo,omitempty" tf:"network_filesystem_info,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	RemoteMountDirPath *string `json:"remoteMountDirPath,omitempty" tf:"remote_mount_dir_path,omitempty"`
}

type NewClusterClusterMountInfoParameters struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	// +kubebuilder:validation:Optional
	LocalMountDirPath *string `json:"localMountDirPath" tf:"local_mount_dir_path,omitempty"`

	// +kubebuilder:validation:Optional
	NetworkFilesystemInfo []ClusterMountInfoNetworkFilesystemInfoParameters `json:"networkFilesystemInfo" tf:"network_filesystem_info,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	// +kubebuilder:validation:Optional
	RemoteMountDirPath *string `json:"remoteMountDirPath,omitempty" tf:"remote_mount_dir_path,omitempty"`
}

type NewClusterDockerImageBasicAuthInitParameters struct {

	// An optional name for the job. The default value is Untitled.
	Username *string `json:"username,omitempty" tf:"username,omitempty"`
}

type NewClusterDockerImageBasicAuthObservation struct {

	// An optional name for the job. The default value is Untitled.
	Username *string `json:"username,omitempty" tf:"username,omitempty"`
}

type NewClusterDockerImageBasicAuthParameters struct {

	// +kubebuilder:validation:Required
	PasswordSecretRef v1.SecretKeySelector `json:"passwordSecretRef" tf:"-"`

	// An optional name for the job. The default value is Untitled.
	// +kubebuilder:validation:Optional
	Username *string `json:"username" tf:"username,omitempty"`
}

type NewClusterDockerImageInitParameters struct {
	BasicAuth []DockerImageBasicAuthInitParameters `json:"basicAuth,omitempty" tf:"basic_auth,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	URL *string `json:"url,omitempty" tf:"url,omitempty"`
}

type NewClusterDockerImageObservation struct {
	BasicAuth []DockerImageBasicAuthObservation `json:"basicAuth,omitempty" tf:"basic_auth,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	URL *string `json:"url,omitempty" tf:"url,omitempty"`
}

type NewClusterDockerImageParameters struct {

	// +kubebuilder:validation:Optional
	BasicAuth []DockerImageBasicAuthParameters `json:"basicAuth,omitempty" tf:"basic_auth,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	// +kubebuilder:validation:Optional
	URL *string `json:"url" tf:"url,omitempty"`
}

type NewClusterGCPAttributesInitParameters struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	BootDiskSize *float64 `json:"bootDiskSize,omitempty" tf:"boot_disk_size,omitempty"`

	GoogleServiceAccount *string `json:"googleServiceAccount,omitempty" tf:"google_service_account,omitempty"`

	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`

	UsePreemptibleExecutors *bool `json:"usePreemptibleExecutors,omitempty" tf:"use_preemptible_executors,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type NewClusterGCPAttributesObservation struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	BootDiskSize *float64 `json:"bootDiskSize,omitempty" tf:"boot_disk_size,omitempty"`

	GoogleServiceAccount *string `json:"googleServiceAccount,omitempty" tf:"google_service_account,omitempty"`

	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`

	UsePreemptibleExecutors *bool `json:"usePreemptibleExecutors,omitempty" tf:"use_preemptible_executors,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type NewClusterGCPAttributesParameters struct {

	// +kubebuilder:validation:Optional
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	// +kubebuilder:validation:Optional
	BootDiskSize *float64 `json:"bootDiskSize,omitempty" tf:"boot_disk_size,omitempty"`

	// +kubebuilder:validation:Optional
	GoogleServiceAccount *string `json:"googleServiceAccount,omitempty" tf:"google_service_account,omitempty"`

	// +kubebuilder:validation:Optional
	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`

	// +kubebuilder:validation:Optional
	UsePreemptibleExecutors *bool `json:"usePreemptibleExecutors,omitempty" tf:"use_preemptible_executors,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type NewClusterInitParameters struct {
	ApplyPolicyDefaultValues *bool `json:"applyPolicyDefaultValues,omitempty" tf:"apply_policy_default_values,omitempty"`

	Autoscale []AutoscaleInitParameters `json:"autoscale,omitempty" tf:"autoscale,omitempty"`

	AutoterminationMinutes *float64 `json:"autoterminationMinutes,omitempty" tf:"autotermination_minutes,omitempty"`

	AwsAttributes []AwsAttributesInitParameters `json:"awsAttributes,omitempty" tf:"aws_attributes,omitempty"`

	AzureAttributes []AzureAttributesInitParameters `json:"azureAttributes,omitempty" tf:"azure_attributes,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	ClusterLogConf []ClusterLogConfInitParameters `json:"clusterLogConf,omitempty" tf:"cluster_log_conf,omitempty"`

	ClusterMountInfo []ClusterMountInfoInitParameters `json:"clusterMountInfo,omitempty" tf:"cluster_mount_info,omitempty"`

	// An optional name for the job. The default value is Untitled.
	ClusterName *string `json:"clusterName,omitempty" tf:"cluster_name,omitempty"`

	CustomTags map[string]*string `json:"customTags,omitempty" tf:"custom_tags,omitempty"`

	DataSecurityMode *string `json:"dataSecurityMode,omitempty" tf:"data_security_mode,omitempty"`

	DockerImage []DockerImageInitParameters `json:"dockerImage,omitempty" tf:"docker_image,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverInstancePoolID *string `json:"driverInstancePoolId,omitempty" tf:"driver_instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverNodeTypeID *string `json:"driverNodeTypeId,omitempty" tf:"driver_node_type_id,omitempty"`

	EnableElasticDisk *bool `json:"enableElasticDisk,omitempty" tf:"enable_elastic_disk,omitempty"`

	EnableLocalDiskEncryption *bool `json:"enableLocalDiskEncryption,omitempty" tf:"enable_local_disk_encryption,omitempty"`

	GCPAttributes []GCPAttributesInitParameters `json:"gcpAttributes,omitempty" tf:"gcp_attributes,omitempty"`

	IdempotencyToken *string `json:"idempotencyToken,omitempty" tf:"idempotency_token,omitempty"`

	InitScripts []InitScriptsInitParameters `json:"initScripts,omitempty" tf:"init_scripts,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	InstancePoolID *string `json:"instancePoolId,omitempty" tf:"instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	NodeTypeID *string `json:"nodeTypeId,omitempty" tf:"node_type_id,omitempty"`

	NumWorkers *float64 `json:"numWorkers,omitempty" tf:"num_workers,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	PolicyID *string `json:"policyId,omitempty" tf:"policy_id,omitempty"`

	RuntimeEngine *string `json:"runtimeEngine,omitempty" tf:"runtime_engine,omitempty"`

	SSHPublicKeys []*string `json:"sshPublicKeys,omitempty" tf:"ssh_public_keys,omitempty"`

	// An optional name for the job. The default value is Untitled.
	SingleUserName *string `json:"singleUserName,omitempty" tf:"single_user_name,omitempty"`

	SparkConf map[string]*string `json:"sparkConf,omitempty" tf:"spark_conf,omitempty"`

	SparkEnvVars map[string]*string `json:"sparkEnvVars,omitempty" tf:"spark_env_vars,omitempty"`

	// parameter in databricks_cluster and other resources.
	SparkVersion *string `json:"sparkVersion,omitempty" tf:"spark_version,omitempty"`

	WorkloadType []WorkloadTypeInitParameters `json:"workloadType,omitempty" tf:"workload_type,omitempty"`
}

type NewClusterInitScriptsAbfssInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type NewClusterInitScriptsAbfssObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type NewClusterInitScriptsAbfssParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type NewClusterInitScriptsDbfsInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type NewClusterInitScriptsDbfsObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type NewClusterInitScriptsDbfsParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type NewClusterInitScriptsFileInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type NewClusterInitScriptsFileObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type NewClusterInitScriptsFileParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type NewClusterInitScriptsGcsInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type NewClusterInitScriptsGcsObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type NewClusterInitScriptsGcsParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type NewClusterInitScriptsInitParameters struct {
	Abfss []InitScriptsAbfssInitParameters `json:"abfss,omitempty" tf:"abfss,omitempty"`

	Dbfs []NewClusterInitScriptsDbfsInitParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// block consisting of single string fields:
	File []InitScriptsFileInitParameters `json:"file,omitempty" tf:"file,omitempty"`

	Gcs []InitScriptsGcsInitParameters `json:"gcs,omitempty" tf:"gcs,omitempty"`

	S3 []NewClusterInitScriptsS3InitParameters `json:"s3,omitempty" tf:"s3,omitempty"`

	Volumes []InitScriptsVolumesInitParameters `json:"volumes,omitempty" tf:"volumes,omitempty"`

	Workspace []InitScriptsWorkspaceInitParameters `json:"workspace,omitempty" tf:"workspace,omitempty"`
}

type NewClusterInitScriptsObservation struct {
	Abfss []InitScriptsAbfssObservation `json:"abfss,omitempty" tf:"abfss,omitempty"`

	Dbfs []NewClusterInitScriptsDbfsObservation `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// block consisting of single string fields:
	File []InitScriptsFileObservation `json:"file,omitempty" tf:"file,omitempty"`

	Gcs []InitScriptsGcsObservation `json:"gcs,omitempty" tf:"gcs,omitempty"`

	S3 []NewClusterInitScriptsS3Observation `json:"s3,omitempty" tf:"s3,omitempty"`

	Volumes []InitScriptsVolumesObservation `json:"volumes,omitempty" tf:"volumes,omitempty"`

	Workspace []InitScriptsWorkspaceObservation `json:"workspace,omitempty" tf:"workspace,omitempty"`
}

type NewClusterInitScriptsParameters struct {

	// +kubebuilder:validation:Optional
	Abfss []InitScriptsAbfssParameters `json:"abfss,omitempty" tf:"abfss,omitempty"`

	// +kubebuilder:validation:Optional
	Dbfs []NewClusterInitScriptsDbfsParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// block consisting of single string fields:
	// +kubebuilder:validation:Optional
	File []InitScriptsFileParameters `json:"file,omitempty" tf:"file,omitempty"`

	// +kubebuilder:validation:Optional
	Gcs []InitScriptsGcsParameters `json:"gcs,omitempty" tf:"gcs,omitempty"`

	// +kubebuilder:validation:Optional
	S3 []NewClusterInitScriptsS3Parameters `json:"s3,omitempty" tf:"s3,omitempty"`

	// +kubebuilder:validation:Optional
	Volumes []InitScriptsVolumesParameters `json:"volumes,omitempty" tf:"volumes,omitempty"`

	// +kubebuilder:validation:Optional
	Workspace []InitScriptsWorkspaceParameters `json:"workspace,omitempty" tf:"workspace,omitempty"`
}

type NewClusterInitScriptsS3InitParameters struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type NewClusterInitScriptsS3Observation struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type NewClusterInitScriptsS3Parameters struct {

	// +kubebuilder:validation:Optional
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`

	// +kubebuilder:validation:Optional
	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	// +kubebuilder:validation:Optional
	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	// +kubebuilder:validation:Optional
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// +kubebuilder:validation:Optional
	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	// +kubebuilder:validation:Optional
	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type NewClusterInitScriptsVolumesInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type NewClusterInitScriptsVolumesObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type NewClusterInitScriptsVolumesParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type NewClusterInitScriptsWorkspaceInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type NewClusterInitScriptsWorkspaceObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type NewClusterInitScriptsWorkspaceParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type NewClusterObservation struct {
	ApplyPolicyDefaultValues *bool `json:"applyPolicyDefaultValues,omitempty" tf:"apply_policy_default_values,omitempty"`

	Autoscale []AutoscaleObservation `json:"autoscale,omitempty" tf:"autoscale,omitempty"`

	AutoterminationMinutes *float64 `json:"autoterminationMinutes,omitempty" tf:"autotermination_minutes,omitempty"`

	AwsAttributes []AwsAttributesObservation `json:"awsAttributes,omitempty" tf:"aws_attributes,omitempty"`

	AzureAttributes []AzureAttributesObservation `json:"azureAttributes,omitempty" tf:"azure_attributes,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	ClusterLogConf []ClusterLogConfObservation `json:"clusterLogConf,omitempty" tf:"cluster_log_conf,omitempty"`

	ClusterMountInfo []ClusterMountInfoObservation `json:"clusterMountInfo,omitempty" tf:"cluster_mount_info,omitempty"`

	// An optional name for the job. The default value is Untitled.
	ClusterName *string `json:"clusterName,omitempty" tf:"cluster_name,omitempty"`

	CustomTags map[string]*string `json:"customTags,omitempty" tf:"custom_tags,omitempty"`

	DataSecurityMode *string `json:"dataSecurityMode,omitempty" tf:"data_security_mode,omitempty"`

	DockerImage []DockerImageObservation `json:"dockerImage,omitempty" tf:"docker_image,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverInstancePoolID *string `json:"driverInstancePoolId,omitempty" tf:"driver_instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverNodeTypeID *string `json:"driverNodeTypeId,omitempty" tf:"driver_node_type_id,omitempty"`

	EnableElasticDisk *bool `json:"enableElasticDisk,omitempty" tf:"enable_elastic_disk,omitempty"`

	EnableLocalDiskEncryption *bool `json:"enableLocalDiskEncryption,omitempty" tf:"enable_local_disk_encryption,omitempty"`

	GCPAttributes []GCPAttributesObservation `json:"gcpAttributes,omitempty" tf:"gcp_attributes,omitempty"`

	IdempotencyToken *string `json:"idempotencyToken,omitempty" tf:"idempotency_token,omitempty"`

	InitScripts []InitScriptsObservation `json:"initScripts,omitempty" tf:"init_scripts,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	InstancePoolID *string `json:"instancePoolId,omitempty" tf:"instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	NodeTypeID *string `json:"nodeTypeId,omitempty" tf:"node_type_id,omitempty"`

	NumWorkers *float64 `json:"numWorkers,omitempty" tf:"num_workers,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	PolicyID *string `json:"policyId,omitempty" tf:"policy_id,omitempty"`

	RuntimeEngine *string `json:"runtimeEngine,omitempty" tf:"runtime_engine,omitempty"`

	SSHPublicKeys []*string `json:"sshPublicKeys,omitempty" tf:"ssh_public_keys,omitempty"`

	// An optional name for the job. The default value is Untitled.
	SingleUserName *string `json:"singleUserName,omitempty" tf:"single_user_name,omitempty"`

	SparkConf map[string]*string `json:"sparkConf,omitempty" tf:"spark_conf,omitempty"`

	SparkEnvVars map[string]*string `json:"sparkEnvVars,omitempty" tf:"spark_env_vars,omitempty"`

	// parameter in databricks_cluster and other resources.
	SparkVersion *string `json:"sparkVersion,omitempty" tf:"spark_version,omitempty"`

	WorkloadType []WorkloadTypeObservation `json:"workloadType,omitempty" tf:"workload_type,omitempty"`
}

type NewClusterParameters struct {

	// +kubebuilder:validation:Optional
	ApplyPolicyDefaultValues *bool `json:"applyPolicyDefaultValues,omitempty" tf:"apply_policy_default_values,omitempty"`

	// +kubebuilder:validation:Optional
	Autoscale []AutoscaleParameters `json:"autoscale,omitempty" tf:"autoscale,omitempty"`

	// +kubebuilder:validation:Optional
	AutoterminationMinutes *float64 `json:"autoterminationMinutes,omitempty" tf:"autotermination_minutes,omitempty"`

	// +kubebuilder:validation:Optional
	AwsAttributes []AwsAttributesParameters `json:"awsAttributes,omitempty" tf:"aws_attributes,omitempty"`

	// +kubebuilder:validation:Optional
	AzureAttributes []AzureAttributesParameters `json:"azureAttributes,omitempty" tf:"azure_attributes,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// +kubebuilder:validation:Optional
	ClusterLogConf []ClusterLogConfParameters `json:"clusterLogConf,omitempty" tf:"cluster_log_conf,omitempty"`

	// +kubebuilder:validation:Optional
	ClusterMountInfo []ClusterMountInfoParameters `json:"clusterMountInfo,omitempty" tf:"cluster_mount_info,omitempty"`

	// An optional name for the job. The default value is Untitled.
	// +kubebuilder:validation:Optional
	ClusterName *string `json:"clusterName,omitempty" tf:"cluster_name,omitempty"`

	// +kubebuilder:validation:Optional
	CustomTags map[string]*string `json:"customTags,omitempty" tf:"custom_tags,omitempty"`

	// +kubebuilder:validation:Optional
	DataSecurityMode *string `json:"dataSecurityMode,omitempty" tf:"data_security_mode,omitempty"`

	// +kubebuilder:validation:Optional
	DockerImage []DockerImageParameters `json:"dockerImage,omitempty" tf:"docker_image,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	DriverInstancePoolID *string `json:"driverInstancePoolId,omitempty" tf:"driver_instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	DriverNodeTypeID *string `json:"driverNodeTypeId,omitempty" tf:"driver_node_type_id,omitempty"`

	// +kubebuilder:validation:Optional
	EnableElasticDisk *bool `json:"enableElasticDisk,omitempty" tf:"enable_elastic_disk,omitempty"`

	// +kubebuilder:validation:Optional
	EnableLocalDiskEncryption *bool `json:"enableLocalDiskEncryption,omitempty" tf:"enable_local_disk_encryption,omitempty"`

	// +kubebuilder:validation:Optional
	GCPAttributes []GCPAttributesParameters `json:"gcpAttributes,omitempty" tf:"gcp_attributes,omitempty"`

	// +kubebuilder:validation:Optional
	IdempotencyToken *string `json:"idempotencyToken,omitempty" tf:"idempotency_token,omitempty"`

	// +kubebuilder:validation:Optional
	InitScripts []InitScriptsParameters `json:"initScripts,omitempty" tf:"init_scripts,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	InstancePoolID *string `json:"instancePoolId,omitempty" tf:"instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	NodeTypeID *string `json:"nodeTypeId,omitempty" tf:"node_type_id,omitempty"`

	// +kubebuilder:validation:Optional
	NumWorkers *float64 `json:"numWorkers,omitempty" tf:"num_workers,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	PolicyID *string `json:"policyId,omitempty" tf:"policy_id,omitempty"`

	// +kubebuilder:validation:Optional
	RuntimeEngine *string `json:"runtimeEngine,omitempty" tf:"runtime_engine,omitempty"`

	// +kubebuilder:validation:Optional
	SSHPublicKeys []*string `json:"sshPublicKeys,omitempty" tf:"ssh_public_keys,omitempty"`

	// An optional name for the job. The default value is Untitled.
	// +kubebuilder:validation:Optional
	SingleUserName *string `json:"singleUserName,omitempty" tf:"single_user_name,omitempty"`

	// +kubebuilder:validation:Optional
	SparkConf map[string]*string `json:"sparkConf,omitempty" tf:"spark_conf,omitempty"`

	// +kubebuilder:validation:Optional
	SparkEnvVars map[string]*string `json:"sparkEnvVars,omitempty" tf:"spark_env_vars,omitempty"`

	// parameter in databricks_cluster and other resources.
	// +kubebuilder:validation:Optional
	SparkVersion *string `json:"sparkVersion" tf:"spark_version,omitempty"`

	// +kubebuilder:validation:Optional
	WorkloadType []WorkloadTypeParameters `json:"workloadType,omitempty" tf:"workload_type,omitempty"`
}

type NewClusterWorkloadTypeClientsInitParameters struct {
	Jobs *bool `json:"jobs,omitempty" tf:"jobs,omitempty"`

	Notebooks *bool `json:"notebooks,omitempty" tf:"notebooks,omitempty"`
}

type NewClusterWorkloadTypeClientsObservation struct {
	Jobs *bool `json:"jobs,omitempty" tf:"jobs,omitempty"`

	Notebooks *bool `json:"notebooks,omitempty" tf:"notebooks,omitempty"`
}

type NewClusterWorkloadTypeClientsParameters struct {

	// +kubebuilder:validation:Optional
	Jobs *bool `json:"jobs,omitempty" tf:"jobs,omitempty"`

	// +kubebuilder:validation:Optional
	Notebooks *bool `json:"notebooks,omitempty" tf:"notebooks,omitempty"`
}

type NewClusterWorkloadTypeInitParameters struct {
	Clients []WorkloadTypeClientsInitParameters `json:"clients,omitempty" tf:"clients,omitempty"`
}

type NewClusterWorkloadTypeObservation struct {
	Clients []WorkloadTypeClientsObservation `json:"clients,omitempty" tf:"clients,omitempty"`
}

type NewClusterWorkloadTypeParameters struct {

	// +kubebuilder:validation:Optional
	Clients []WorkloadTypeClientsParameters `json:"clients" tf:"clients,omitempty"`
}

type NotebookTaskInitParameters struct {

	// (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the jobs base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using dbutils.widgets.get.
	BaseParameters map[string]*string `json:"baseParameters,omitempty" tf:"base_parameters,omitempty"`

	// The path of the databricks_notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
	NotebookPath *string `json:"notebookPath,omitempty" tf:"notebook_path,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type NotebookTaskObservation struct {

	// (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the jobs base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using dbutils.widgets.get.
	BaseParameters map[string]*string `json:"baseParameters,omitempty" tf:"base_parameters,omitempty"`

	// The path of the databricks_notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
	NotebookPath *string `json:"notebookPath,omitempty" tf:"notebook_path,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type NotebookTaskParameters struct {

	// (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the jobs base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using dbutils.widgets.get.
	// +kubebuilder:validation:Optional
	BaseParameters map[string]*string `json:"baseParameters,omitempty" tf:"base_parameters,omitempty"`

	// The path of the databricks_notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
	// +kubebuilder:validation:Optional
	NotebookPath *string `json:"notebookPath" tf:"notebook_path,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	// +kubebuilder:validation:Optional
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type NotificationSettingsInitParameters struct {

	// (Bool) don't send alert for cancelled runs.
	NoAlertForCanceledRuns *bool `json:"noAlertForCanceledRuns,omitempty" tf:"no_alert_for_canceled_runs,omitempty"`

	// (Bool) don't send alert for skipped runs.
	NoAlertForSkippedRuns *bool `json:"noAlertForSkippedRuns,omitempty" tf:"no_alert_for_skipped_runs,omitempty"`
}

type NotificationSettingsObservation struct {

	// (Bool) don't send alert for cancelled runs.
	NoAlertForCanceledRuns *bool `json:"noAlertForCanceledRuns,omitempty" tf:"no_alert_for_canceled_runs,omitempty"`

	// (Bool) don't send alert for skipped runs.
	NoAlertForSkippedRuns *bool `json:"noAlertForSkippedRuns,omitempty" tf:"no_alert_for_skipped_runs,omitempty"`
}

type NotificationSettingsParameters struct {

	// (Bool) don't send alert for cancelled runs.
	// +kubebuilder:validation:Optional
	NoAlertForCanceledRuns *bool `json:"noAlertForCanceledRuns,omitempty" tf:"no_alert_for_canceled_runs,omitempty"`

	// (Bool) don't send alert for skipped runs.
	// +kubebuilder:validation:Optional
	NoAlertForSkippedRuns *bool `json:"noAlertForSkippedRuns,omitempty" tf:"no_alert_for_skipped_runs,omitempty"`
}

type OnDurationWarningThresholdExceededInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type OnDurationWarningThresholdExceededObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type OnDurationWarningThresholdExceededParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type OnFailureInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type OnFailureObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type OnFailureParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type OnStartInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type OnStartObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type OnStartParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type OnSuccessInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type OnSuccessObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type OnSuccessParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type ParameterInitParameters struct {

	// Default value of the parameter.
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// An optional name for the job. The default value is Untitled.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`
}

type ParameterObservation struct {

	// Default value of the parameter.
	Default *string `json:"default,omitempty" tf:"default,omitempty"`

	// An optional name for the job. The default value is Untitled.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`
}

type ParameterParameters struct {

	// Default value of the parameter.
	// +kubebuilder:validation:Optional
	Default *string `json:"default" tf:"default,omitempty"`

	// An optional name for the job. The default value is Untitled.
	// +kubebuilder:validation:Optional
	Name *string `json:"name" tf:"name,omitempty"`
}

type PipelineTaskInitParameters struct {

	// (Bool) Specifies if there should be full refresh of the pipeline.
	FullRefresh *bool `json:"fullRefresh,omitempty" tf:"full_refresh,omitempty"`

	// The pipeline's unique ID.
	PipelineID *string `json:"pipelineId,omitempty" tf:"pipeline_id,omitempty"`
}

type PipelineTaskObservation struct {

	// (Bool) Specifies if there should be full refresh of the pipeline.
	FullRefresh *bool `json:"fullRefresh,omitempty" tf:"full_refresh,omitempty"`

	// The pipeline's unique ID.
	PipelineID *string `json:"pipelineId,omitempty" tf:"pipeline_id,omitempty"`
}

type PipelineTaskParameters struct {

	// (Bool) Specifies if there should be full refresh of the pipeline.
	// +kubebuilder:validation:Optional
	FullRefresh *bool `json:"fullRefresh,omitempty" tf:"full_refresh,omitempty"`

	// The pipeline's unique ID.
	// +kubebuilder:validation:Optional
	PipelineID *string `json:"pipelineId" tf:"pipeline_id,omitempty"`
}

type PypiInitParameters struct {
	Package *string `json:"package,omitempty" tf:"package,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type PypiObservation struct {
	Package *string `json:"package,omitempty" tf:"package,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type PypiParameters struct {

	// +kubebuilder:validation:Optional
	Package *string `json:"package" tf:"package,omitempty"`

	// +kubebuilder:validation:Optional
	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type PythonWheelTaskInitParameters struct {

	// Python function as entry point for the task
	EntryPoint *string `json:"entryPoint,omitempty" tf:"entry_point,omitempty"`

	// Named parameters for the task
	NamedParameters map[string]*string `json:"namedParameters,omitempty" tf:"named_parameters,omitempty"`

	// Name of Python package
	PackageName *string `json:"packageName,omitempty" tf:"package_name,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type PythonWheelTaskObservation struct {

	// Python function as entry point for the task
	EntryPoint *string `json:"entryPoint,omitempty" tf:"entry_point,omitempty"`

	// Named parameters for the task
	NamedParameters map[string]*string `json:"namedParameters,omitempty" tf:"named_parameters,omitempty"`

	// Name of Python package
	PackageName *string `json:"packageName,omitempty" tf:"package_name,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type PythonWheelTaskParameters struct {

	// Python function as entry point for the task
	// +kubebuilder:validation:Optional
	EntryPoint *string `json:"entryPoint,omitempty" tf:"entry_point,omitempty"`

	// Named parameters for the task
	// +kubebuilder:validation:Optional
	NamedParameters map[string]*string `json:"namedParameters,omitempty" tf:"named_parameters,omitempty"`

	// Name of Python package
	// +kubebuilder:validation:Optional
	PackageName *string `json:"packageName,omitempty" tf:"package_name,omitempty"`

	// (List) Parameters passed to the main method.
	// +kubebuilder:validation:Optional
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type QueryInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	QueryID *string `json:"queryId,omitempty" tf:"query_id,omitempty"`
}

type QueryObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	QueryID *string `json:"queryId,omitempty" tf:"query_id,omitempty"`
}

type QueryParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	QueryID *string `json:"queryId" tf:"query_id,omitempty"`
}

type QueueInitParameters struct {

	// If true, enable queueing for the job.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type QueueObservation struct {

	// If true, enable queueing for the job.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type QueueParameters struct {

	// If true, enable queueing for the job.
	// +kubebuilder:validation:Optional
	Enabled *bool `json:"enabled" tf:"enabled,omitempty"`
}

type RulesInitParameters struct {

	// string specifying the metric to check.  The only supported metric is RUN_DURATION_SECONDS (check Jobs REST API documentation for the latest information).
	Metric *string `json:"metric,omitempty" tf:"metric,omitempty"`

	// string specifying the operation used to evaluate the given metric. The only supported operation is GREATER_THAN.
	Op *string `json:"op,omitempty" tf:"op,omitempty"`

	// integer value used to compare to the given metric.
	Value *float64 `json:"value,omitempty" tf:"value,omitempty"`
}

type RulesObservation struct {

	// string specifying the metric to check.  The only supported metric is RUN_DURATION_SECONDS (check Jobs REST API documentation for the latest information).
	Metric *string `json:"metric,omitempty" tf:"metric,omitempty"`

	// string specifying the operation used to evaluate the given metric. The only supported operation is GREATER_THAN.
	Op *string `json:"op,omitempty" tf:"op,omitempty"`

	// integer value used to compare to the given metric.
	Value *float64 `json:"value,omitempty" tf:"value,omitempty"`
}

type RulesParameters struct {

	// string specifying the metric to check.  The only supported metric is RUN_DURATION_SECONDS (check Jobs REST API documentation for the latest information).
	// +kubebuilder:validation:Optional
	Metric *string `json:"metric,omitempty" tf:"metric,omitempty"`

	// string specifying the operation used to evaluate the given metric. The only supported operation is GREATER_THAN.
	// +kubebuilder:validation:Optional
	Op *string `json:"op,omitempty" tf:"op,omitempty"`

	// integer value used to compare to the given metric.
	// +kubebuilder:validation:Optional
	Value *float64 `json:"value,omitempty" tf:"value,omitempty"`
}

type RunAsInitParameters struct {

	// The application ID of an active service principal. Setting this field requires the servicePrincipal/user role.
	ServicePrincipalName *string `json:"servicePrincipalName,omitempty" tf:"service_principal_name,omitempty"`

	// The email of an active workspace user. Non-admin users can only set this field to their own email.
	UserName *string `json:"userName,omitempty" tf:"user_name,omitempty"`
}

type RunAsObservation struct {

	// The application ID of an active service principal. Setting this field requires the servicePrincipal/user role.
	ServicePrincipalName *string `json:"servicePrincipalName,omitempty" tf:"service_principal_name,omitempty"`

	// The email of an active workspace user. Non-admin users can only set this field to their own email.
	UserName *string `json:"userName,omitempty" tf:"user_name,omitempty"`
}

type RunAsParameters struct {

	// The application ID of an active service principal. Setting this field requires the servicePrincipal/user role.
	// +kubebuilder:validation:Optional
	ServicePrincipalName *string `json:"servicePrincipalName,omitempty" tf:"service_principal_name,omitempty"`

	// The email of an active workspace user. Non-admin users can only set this field to their own email.
	// +kubebuilder:validation:Optional
	UserName *string `json:"userName,omitempty" tf:"user_name,omitempty"`
}

type RunJobTaskInitParameters struct {

	// (String) ID of the job
	JobID *float64 `json:"jobId,omitempty" tf:"job_id,omitempty"`

	// (Map) Job parameters for the task
	JobParameters map[string]*string `json:"jobParameters,omitempty" tf:"job_parameters,omitempty"`
}

type RunJobTaskObservation struct {

	// (String) ID of the job
	JobID *float64 `json:"jobId,omitempty" tf:"job_id,omitempty"`

	// (Map) Job parameters for the task
	JobParameters map[string]*string `json:"jobParameters,omitempty" tf:"job_parameters,omitempty"`
}

type RunJobTaskParameters struct {

	// (String) ID of the job
	// +kubebuilder:validation:Optional
	JobID *float64 `json:"jobId" tf:"job_id,omitempty"`

	// (Map) Job parameters for the task
	// +kubebuilder:validation:Optional
	JobParameters map[string]*string `json:"jobParameters,omitempty" tf:"job_parameters,omitempty"`
}

type S3InitParameters struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type S3Observation struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type S3Parameters struct {

	// +kubebuilder:validation:Optional
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`

	// +kubebuilder:validation:Optional
	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	// +kubebuilder:validation:Optional
	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	// +kubebuilder:validation:Optional
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// +kubebuilder:validation:Optional
	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	// +kubebuilder:validation:Optional
	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type SQLTaskAlertInitParameters struct {

	// (String) identifier of the Databricks SQL Alert.
	AlertID *string `json:"alertId,omitempty" tf:"alert_id,omitempty"`

	// flag that specifies if subscriptions are paused or not.
	PauseSubscriptions *bool `json:"pauseSubscriptions,omitempty" tf:"pause_subscriptions,omitempty"`

	// a list of subscription blocks consisting out of one of the required fields: user_name for user emails or destination_id - for Alert destination's identifier.
	Subscriptions []AlertSubscriptionsInitParameters `json:"subscriptions,omitempty" tf:"subscriptions,omitempty"`
}

type SQLTaskAlertObservation struct {

	// (String) identifier of the Databricks SQL Alert.
	AlertID *string `json:"alertId,omitempty" tf:"alert_id,omitempty"`

	// flag that specifies if subscriptions are paused or not.
	PauseSubscriptions *bool `json:"pauseSubscriptions,omitempty" tf:"pause_subscriptions,omitempty"`

	// a list of subscription blocks consisting out of one of the required fields: user_name for user emails or destination_id - for Alert destination's identifier.
	Subscriptions []AlertSubscriptionsObservation `json:"subscriptions,omitempty" tf:"subscriptions,omitempty"`
}

type SQLTaskAlertParameters struct {

	// (String) identifier of the Databricks SQL Alert.
	// +kubebuilder:validation:Optional
	AlertID *string `json:"alertId" tf:"alert_id,omitempty"`

	// flag that specifies if subscriptions are paused or not.
	// +kubebuilder:validation:Optional
	PauseSubscriptions *bool `json:"pauseSubscriptions,omitempty" tf:"pause_subscriptions,omitempty"`

	// a list of subscription blocks consisting out of one of the required fields: user_name for user emails or destination_id - for Alert destination's identifier.
	// +kubebuilder:validation:Optional
	Subscriptions []AlertSubscriptionsParameters `json:"subscriptions" tf:"subscriptions,omitempty"`
}

type SQLTaskDashboardInitParameters struct {

	// string specifying a custom subject of email sent.
	CustomSubject *string `json:"customSubject,omitempty" tf:"custom_subject,omitempty"`

	// (String) identifier of the Databricks SQL Dashboard databricks_sql_dashboard.
	DashboardID *string `json:"dashboardId,omitempty" tf:"dashboard_id,omitempty"`

	// flag that specifies if subscriptions are paused or not.
	PauseSubscriptions *bool `json:"pauseSubscriptions,omitempty" tf:"pause_subscriptions,omitempty"`

	// a list of subscription blocks consisting out of one of the required fields: user_name for user emails or destination_id - for Alert destination's identifier.
	Subscriptions []SQLTaskDashboardSubscriptionsInitParameters `json:"subscriptions,omitempty" tf:"subscriptions,omitempty"`
}

type SQLTaskDashboardObservation struct {

	// string specifying a custom subject of email sent.
	CustomSubject *string `json:"customSubject,omitempty" tf:"custom_subject,omitempty"`

	// (String) identifier of the Databricks SQL Dashboard databricks_sql_dashboard.
	DashboardID *string `json:"dashboardId,omitempty" tf:"dashboard_id,omitempty"`

	// flag that specifies if subscriptions are paused or not.
	PauseSubscriptions *bool `json:"pauseSubscriptions,omitempty" tf:"pause_subscriptions,omitempty"`

	// a list of subscription blocks consisting out of one of the required fields: user_name for user emails or destination_id - for Alert destination's identifier.
	Subscriptions []SQLTaskDashboardSubscriptionsObservation `json:"subscriptions,omitempty" tf:"subscriptions,omitempty"`
}

type SQLTaskDashboardParameters struct {

	// string specifying a custom subject of email sent.
	// +kubebuilder:validation:Optional
	CustomSubject *string `json:"customSubject,omitempty" tf:"custom_subject,omitempty"`

	// (String) identifier of the Databricks SQL Dashboard databricks_sql_dashboard.
	// +kubebuilder:validation:Optional
	DashboardID *string `json:"dashboardId" tf:"dashboard_id,omitempty"`

	// flag that specifies if subscriptions are paused or not.
	// +kubebuilder:validation:Optional
	PauseSubscriptions *bool `json:"pauseSubscriptions,omitempty" tf:"pause_subscriptions,omitempty"`

	// a list of subscription blocks consisting out of one of the required fields: user_name for user emails or destination_id - for Alert destination's identifier.
	// +kubebuilder:validation:Optional
	Subscriptions []SQLTaskDashboardSubscriptionsParameters `json:"subscriptions,omitempty" tf:"subscriptions,omitempty"`
}

type SQLTaskDashboardSubscriptionsInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DestinationID *string `json:"destinationId,omitempty" tf:"destination_id,omitempty"`

	// The email of an active workspace user. Non-admin users can only set this field to their own email.
	UserName *string `json:"userName,omitempty" tf:"user_name,omitempty"`
}

type SQLTaskDashboardSubscriptionsObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DestinationID *string `json:"destinationId,omitempty" tf:"destination_id,omitempty"`

	// The email of an active workspace user. Non-admin users can only set this field to their own email.
	UserName *string `json:"userName,omitempty" tf:"user_name,omitempty"`
}

type SQLTaskDashboardSubscriptionsParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	DestinationID *string `json:"destinationId,omitempty" tf:"destination_id,omitempty"`

	// The email of an active workspace user. Non-admin users can only set this field to their own email.
	// +kubebuilder:validation:Optional
	UserName *string `json:"userName,omitempty" tf:"user_name,omitempty"`
}

type SQLTaskFileInitParameters struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type SQLTaskFileObservation struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type SQLTaskFileParameters struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	// +kubebuilder:validation:Optional
	Path *string `json:"path" tf:"path,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	// +kubebuilder:validation:Optional
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type SQLTaskInitParameters struct {

	// block consisting of following fields:
	Alert []AlertInitParameters `json:"alert,omitempty" tf:"alert,omitempty"`

	// block consisting of following fields:
	Dashboard []DashboardInitParameters `json:"dashboard,omitempty" tf:"dashboard,omitempty"`

	// block consisting of single string fields:
	File []SQLTaskFileInitParameters `json:"file,omitempty" tf:"file,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters map[string]*string `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// block consisting of single string field: query_id - identifier of the Databricks SQL Query (databricks_sql_query).
	Query []QueryInitParameters `json:"query,omitempty" tf:"query,omitempty"`

	// The ID of the SQL warehouse that dbt should execute against.
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type SQLTaskObservation struct {

	// block consisting of following fields:
	Alert []AlertObservation `json:"alert,omitempty" tf:"alert,omitempty"`

	// block consisting of following fields:
	Dashboard []DashboardObservation `json:"dashboard,omitempty" tf:"dashboard,omitempty"`

	// block consisting of single string fields:
	File []SQLTaskFileObservation `json:"file,omitempty" tf:"file,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters map[string]*string `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// block consisting of single string field: query_id - identifier of the Databricks SQL Query (databricks_sql_query).
	Query []QueryObservation `json:"query,omitempty" tf:"query,omitempty"`

	// The ID of the SQL warehouse that dbt should execute against.
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type SQLTaskParameters struct {

	// block consisting of following fields:
	// +kubebuilder:validation:Optional
	Alert []AlertParameters `json:"alert,omitempty" tf:"alert,omitempty"`

	// block consisting of following fields:
	// +kubebuilder:validation:Optional
	Dashboard []DashboardParameters `json:"dashboard,omitempty" tf:"dashboard,omitempty"`

	// block consisting of single string fields:
	// +kubebuilder:validation:Optional
	File []SQLTaskFileParameters `json:"file,omitempty" tf:"file,omitempty"`

	// (List) Parameters passed to the main method.
	// +kubebuilder:validation:Optional
	Parameters map[string]*string `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// block consisting of single string field: query_id - identifier of the Databricks SQL Query (databricks_sql_query).
	// +kubebuilder:validation:Optional
	Query []QueryParameters `json:"query,omitempty" tf:"query,omitempty"`

	// The ID of the SQL warehouse that dbt should execute against.
	// +kubebuilder:validation:Optional
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type SQLTaskQueryInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	QueryID *string `json:"queryId,omitempty" tf:"query_id,omitempty"`
}

type SQLTaskQueryObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	QueryID *string `json:"queryId,omitempty" tf:"query_id,omitempty"`
}

type SQLTaskQueryParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	QueryID *string `json:"queryId" tf:"query_id,omitempty"`
}

type ScheduleInitParameters struct {

	// Indicate whether this schedule is paused or not. Either PAUSED or UNPAUSED. When the pause_status field is omitted and a schedule is provided, the server will default to using UNPAUSED as a value for pause_status.
	PauseStatus *string `json:"pauseStatus,omitempty" tf:"pause_status,omitempty"`

	// A Cron expression using Quartz syntax that describes the schedule for a job. This field is required.
	QuartzCronExpression *string `json:"quartzCronExpression,omitempty" tf:"quartz_cron_expression,omitempty"`

	// A Java timezone ID. The schedule for a job will be resolved with respect to this timezone. See Java TimeZone for details. This field is required.
	TimezoneID *string `json:"timezoneId,omitempty" tf:"timezone_id,omitempty"`
}

type ScheduleObservation struct {

	// Indicate whether this schedule is paused or not. Either PAUSED or UNPAUSED. When the pause_status field is omitted and a schedule is provided, the server will default to using UNPAUSED as a value for pause_status.
	PauseStatus *string `json:"pauseStatus,omitempty" tf:"pause_status,omitempty"`

	// A Cron expression using Quartz syntax that describes the schedule for a job. This field is required.
	QuartzCronExpression *string `json:"quartzCronExpression,omitempty" tf:"quartz_cron_expression,omitempty"`

	// A Java timezone ID. The schedule for a job will be resolved with respect to this timezone. See Java TimeZone for details. This field is required.
	TimezoneID *string `json:"timezoneId,omitempty" tf:"timezone_id,omitempty"`
}

type ScheduleParameters struct {

	// Indicate whether this schedule is paused or not. Either PAUSED or UNPAUSED. When the pause_status field is omitted and a schedule is provided, the server will default to using UNPAUSED as a value for pause_status.
	// +kubebuilder:validation:Optional
	PauseStatus *string `json:"pauseStatus,omitempty" tf:"pause_status,omitempty"`

	// A Cron expression using Quartz syntax that describes the schedule for a job. This field is required.
	// +kubebuilder:validation:Optional
	QuartzCronExpression *string `json:"quartzCronExpression" tf:"quartz_cron_expression,omitempty"`

	// A Java timezone ID. The schedule for a job will be resolved with respect to this timezone. See Java TimeZone for details. This field is required.
	// +kubebuilder:validation:Optional
	TimezoneID *string `json:"timezoneId" tf:"timezone_id,omitempty"`
}

type SparkJarTaskInitParameters struct {
	JarURI *string `json:"jarUri,omitempty" tf:"jar_uri,omitempty"`

	// The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use SparkContext.getOrCreate to obtain a Spark context; otherwise, runs of the job will fail.
	MainClassName *string `json:"mainClassName,omitempty" tf:"main_class_name,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type SparkJarTaskObservation struct {
	JarURI *string `json:"jarUri,omitempty" tf:"jar_uri,omitempty"`

	// The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use SparkContext.getOrCreate to obtain a Spark context; otherwise, runs of the job will fail.
	MainClassName *string `json:"mainClassName,omitempty" tf:"main_class_name,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type SparkJarTaskParameters struct {

	// +kubebuilder:validation:Optional
	JarURI *string `json:"jarUri,omitempty" tf:"jar_uri,omitempty"`

	// The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use SparkContext.getOrCreate to obtain a Spark context; otherwise, runs of the job will fail.
	// +kubebuilder:validation:Optional
	MainClassName *string `json:"mainClassName,omitempty" tf:"main_class_name,omitempty"`

	// (List) Parameters passed to the main method.
	// +kubebuilder:validation:Optional
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type SparkPythonTaskInitParameters struct {

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. s3:/, abfss:/, gs:/), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with /Repos. For files stored in a remote repository, the path must be relative. This field is required.
	PythonFile *string `json:"pythonFile,omitempty" tf:"python_file,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type SparkPythonTaskObservation struct {

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. s3:/, abfss:/, gs:/), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with /Repos. For files stored in a remote repository, the path must be relative. This field is required.
	PythonFile *string `json:"pythonFile,omitempty" tf:"python_file,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type SparkPythonTaskParameters struct {

	// (List) Parameters passed to the main method.
	// +kubebuilder:validation:Optional
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. s3:/, abfss:/, gs:/), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with /Repos. For files stored in a remote repository, the path must be relative. This field is required.
	// +kubebuilder:validation:Optional
	PythonFile *string `json:"pythonFile" tf:"python_file,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	// +kubebuilder:validation:Optional
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type SparkSubmitTaskInitParameters struct {

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type SparkSubmitTaskObservation struct {

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type SparkSubmitTaskParameters struct {

	// (List) Parameters passed to the main method.
	// +kubebuilder:validation:Optional
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type SpecInitParameters struct {
	Kind *string `json:"kind,omitempty" tf:"kind,omitempty"`
}

type SpecObservation struct {
	Kind *string `json:"kind,omitempty" tf:"kind,omitempty"`
}

type SpecParameters struct {

	// +kubebuilder:validation:Optional
	Kind *string `json:"kind,omitempty" tf:"kind,omitempty"`
}

type SubscriptionsInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DestinationID *string `json:"destinationId,omitempty" tf:"destination_id,omitempty"`

	// The email of an active workspace user. Non-admin users can only set this field to their own email.
	UserName *string `json:"userName,omitempty" tf:"user_name,omitempty"`
}

type SubscriptionsObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DestinationID *string `json:"destinationId,omitempty" tf:"destination_id,omitempty"`

	// The email of an active workspace user. Non-admin users can only set this field to their own email.
	UserName *string `json:"userName,omitempty" tf:"user_name,omitempty"`
}

type SubscriptionsParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	DestinationID *string `json:"destinationId,omitempty" tf:"destination_id,omitempty"`

	// The email of an active workspace user. Non-admin users can only set this field to their own email.
	// +kubebuilder:validation:Optional
	UserName *string `json:"userName,omitempty" tf:"user_name,omitempty"`
}

type TaskConditionTaskInitParameters struct {

	// The left operand of the condition task. It could be a string value, job state, or a parameter reference.
	Left *string `json:"left,omitempty" tf:"left,omitempty"`

	// string specifying the operation used to evaluate the given metric. The only supported operation is GREATER_THAN.
	Op *string `json:"op,omitempty" tf:"op,omitempty"`

	// The right operand of the condition task. It could be a string value, job state, or parameter reference.
	Right *string `json:"right,omitempty" tf:"right,omitempty"`
}

type TaskConditionTaskObservation struct {

	// The left operand of the condition task. It could be a string value, job state, or a parameter reference.
	Left *string `json:"left,omitempty" tf:"left,omitempty"`

	// string specifying the operation used to evaluate the given metric. The only supported operation is GREATER_THAN.
	Op *string `json:"op,omitempty" tf:"op,omitempty"`

	// The right operand of the condition task. It could be a string value, job state, or parameter reference.
	Right *string `json:"right,omitempty" tf:"right,omitempty"`
}

type TaskConditionTaskParameters struct {

	// The left operand of the condition task. It could be a string value, job state, or a parameter reference.
	// +kubebuilder:validation:Optional
	Left *string `json:"left,omitempty" tf:"left,omitempty"`

	// string specifying the operation used to evaluate the given metric. The only supported operation is GREATER_THAN.
	// +kubebuilder:validation:Optional
	Op *string `json:"op,omitempty" tf:"op,omitempty"`

	// The right operand of the condition task. It could be a string value, job state, or parameter reference.
	// +kubebuilder:validation:Optional
	Right *string `json:"right,omitempty" tf:"right,omitempty"`
}

type TaskDbtTaskInitParameters struct {

	// The name of the catalog to use inside Unity Catalog.
	Catalog *string `json:"catalog,omitempty" tf:"catalog,omitempty"`

	// (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
	Commands []*string `json:"commands,omitempty" tf:"commands,omitempty"`

	// The relative path to the directory in the repository specified by git_source where dbt should look in for the profiles.yml file. If not specified, defaults to the repository's root directory. Equivalent to passing --profile-dir to a dbt command.
	ProfilesDirectory *string `json:"profilesDirectory,omitempty" tf:"profiles_directory,omitempty"`

	// The path where dbt should look for dbt_project.yml. Equivalent to passing --project-dir to the dbt CLI.
	ProjectDirectory *string `json:"projectDirectory,omitempty" tf:"project_directory,omitempty"`

	// The name of the schema dbt should run in. Defaults to default.
	Schema *string `json:"schema,omitempty" tf:"schema,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`

	// The ID of the SQL warehouse that dbt should execute against.
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type TaskDbtTaskObservation struct {

	// The name of the catalog to use inside Unity Catalog.
	Catalog *string `json:"catalog,omitempty" tf:"catalog,omitempty"`

	// (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
	Commands []*string `json:"commands,omitempty" tf:"commands,omitempty"`

	// The relative path to the directory in the repository specified by git_source where dbt should look in for the profiles.yml file. If not specified, defaults to the repository's root directory. Equivalent to passing --profile-dir to a dbt command.
	ProfilesDirectory *string `json:"profilesDirectory,omitempty" tf:"profiles_directory,omitempty"`

	// The path where dbt should look for dbt_project.yml. Equivalent to passing --project-dir to the dbt CLI.
	ProjectDirectory *string `json:"projectDirectory,omitempty" tf:"project_directory,omitempty"`

	// The name of the schema dbt should run in. Defaults to default.
	Schema *string `json:"schema,omitempty" tf:"schema,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`

	// The ID of the SQL warehouse that dbt should execute against.
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type TaskDbtTaskParameters struct {

	// The name of the catalog to use inside Unity Catalog.
	// +kubebuilder:validation:Optional
	Catalog *string `json:"catalog,omitempty" tf:"catalog,omitempty"`

	// (Array) Series of dbt commands to execute in sequence. Every command must start with "dbt".
	// +kubebuilder:validation:Optional
	Commands []*string `json:"commands" tf:"commands,omitempty"`

	// The relative path to the directory in the repository specified by git_source where dbt should look in for the profiles.yml file. If not specified, defaults to the repository's root directory. Equivalent to passing --profile-dir to a dbt command.
	// +kubebuilder:validation:Optional
	ProfilesDirectory *string `json:"profilesDirectory,omitempty" tf:"profiles_directory,omitempty"`

	// The path where dbt should look for dbt_project.yml. Equivalent to passing --project-dir to the dbt CLI.
	// +kubebuilder:validation:Optional
	ProjectDirectory *string `json:"projectDirectory,omitempty" tf:"project_directory,omitempty"`

	// The name of the schema dbt should run in. Defaults to default.
	// +kubebuilder:validation:Optional
	Schema *string `json:"schema,omitempty" tf:"schema,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	// +kubebuilder:validation:Optional
	Source *string `json:"source,omitempty" tf:"source,omitempty"`

	// The ID of the SQL warehouse that dbt should execute against.
	// +kubebuilder:validation:Optional
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type TaskDependsOnInitParameters struct {

	// Can only be specified on condition task dependencies. The outcome of the dependent task that must be met for this task to run. Possible values are "true" or "false".
	Outcome *string `json:"outcome,omitempty" tf:"outcome,omitempty"`

	// string specifying an unique key for a given task.
	TaskKey *string `json:"taskKey,omitempty" tf:"task_key,omitempty"`
}

type TaskDependsOnObservation struct {

	// Can only be specified on condition task dependencies. The outcome of the dependent task that must be met for this task to run. Possible values are "true" or "false".
	Outcome *string `json:"outcome,omitempty" tf:"outcome,omitempty"`

	// string specifying an unique key for a given task.
	TaskKey *string `json:"taskKey,omitempty" tf:"task_key,omitempty"`
}

type TaskDependsOnParameters struct {

	// Can only be specified on condition task dependencies. The outcome of the dependent task that must be met for this task to run. Possible values are "true" or "false".
	// +kubebuilder:validation:Optional
	Outcome *string `json:"outcome,omitempty" tf:"outcome,omitempty"`

	// string specifying an unique key for a given task.
	// +kubebuilder:validation:Optional
	TaskKey *string `json:"taskKey" tf:"task_key,omitempty"`
}

type TaskEmailNotificationsInitParameters struct {

	// (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	OnDurationWarningThresholdExceeded []*string `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
	OnFailure []*string `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
	OnStart []*string `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
	OnSuccess []*string `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type TaskEmailNotificationsObservation struct {

	// (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	OnDurationWarningThresholdExceeded []*string `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
	OnFailure []*string `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
	OnStart []*string `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
	OnSuccess []*string `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type TaskEmailNotificationsParameters struct {

	// (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	// +kubebuilder:validation:Optional
	OnDurationWarningThresholdExceeded []*string `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
	// +kubebuilder:validation:Optional
	OnFailure []*string `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
	// +kubebuilder:validation:Optional
	OnStart []*string `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
	// +kubebuilder:validation:Optional
	OnSuccess []*string `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type TaskHealthInitParameters struct {

	// (List) list of rules that are represented as objects with the following attributes:
	Rules []HealthRulesInitParameters `json:"rules,omitempty" tf:"rules,omitempty"`
}

type TaskHealthObservation struct {

	// (List) list of rules that are represented as objects with the following attributes:
	Rules []HealthRulesObservation `json:"rules,omitempty" tf:"rules,omitempty"`
}

type TaskHealthParameters struct {

	// (List) list of rules that are represented as objects with the following attributes:
	// +kubebuilder:validation:Optional
	Rules []HealthRulesParameters `json:"rules" tf:"rules,omitempty"`
}

type TaskHealthRulesInitParameters struct {

	// string specifying the metric to check.  The only supported metric is RUN_DURATION_SECONDS (check Jobs REST API documentation for the latest information).
	Metric *string `json:"metric,omitempty" tf:"metric,omitempty"`

	// string specifying the operation used to evaluate the given metric. The only supported operation is GREATER_THAN.
	Op *string `json:"op,omitempty" tf:"op,omitempty"`

	// integer value used to compare to the given metric.
	Value *float64 `json:"value,omitempty" tf:"value,omitempty"`
}

type TaskHealthRulesObservation struct {

	// string specifying the metric to check.  The only supported metric is RUN_DURATION_SECONDS (check Jobs REST API documentation for the latest information).
	Metric *string `json:"metric,omitempty" tf:"metric,omitempty"`

	// string specifying the operation used to evaluate the given metric. The only supported operation is GREATER_THAN.
	Op *string `json:"op,omitempty" tf:"op,omitempty"`

	// integer value used to compare to the given metric.
	Value *float64 `json:"value,omitempty" tf:"value,omitempty"`
}

type TaskHealthRulesParameters struct {

	// string specifying the metric to check.  The only supported metric is RUN_DURATION_SECONDS (check Jobs REST API documentation for the latest information).
	// +kubebuilder:validation:Optional
	Metric *string `json:"metric,omitempty" tf:"metric,omitempty"`

	// string specifying the operation used to evaluate the given metric. The only supported operation is GREATER_THAN.
	// +kubebuilder:validation:Optional
	Op *string `json:"op,omitempty" tf:"op,omitempty"`

	// integer value used to compare to the given metric.
	// +kubebuilder:validation:Optional
	Value *float64 `json:"value,omitempty" tf:"value,omitempty"`
}

type TaskInitParameters struct {
	ComputeKey *string `json:"computeKey,omitempty" tf:"compute_key,omitempty"`

	// Task to run against the inputs list.
	ConditionTask []ConditionTaskInitParameters `json:"conditionTask,omitempty" tf:"condition_task,omitempty"`

	// Task to run against the inputs list.
	DbtTask []TaskDbtTaskInitParameters `json:"dbtTask,omitempty" tf:"dbt_task,omitempty"`

	// block specifying dependency(-ies) for a given task.
	DependsOn []DependsOnInitParameters `json:"dependsOn,omitempty" tf:"depends_on,omitempty"`

	// An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (List) An optional set of email addresses notified when runs of this job begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
	EmailNotifications []TaskEmailNotificationsInitParameters `json:"emailNotifications,omitempty" tf:"email_notifications,omitempty"`

	// If existing_cluster_id, the ID of an existing cluster that will be used for all runs of this job. When running jobs on an existing cluster, you may need to manually restart the cluster if it stops responding. We strongly suggest to use new_cluster for greater reliability.
	ExistingClusterID *string `json:"existingClusterId,omitempty" tf:"existing_cluster_id,omitempty"`

	// Task to run against the inputs list.
	ForEachTask []ForEachTaskInitParameters `json:"forEachTask,omitempty" tf:"for_each_task,omitempty"`

	// An optional block that specifies the health conditions for the job (described below).
	Health []JobTaskHealthInitParameters `json:"health,omitempty" tf:"health,omitempty"`

	// Identifier that can be referenced in task block, so that cluster is shared between tasks
	JobClusterKey *string `json:"jobClusterKey,omitempty" tf:"job_cluster_key,omitempty"`

	// (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for databricks_cluster resource.
	Library []JobTaskLibraryInitParameters `json:"library,omitempty" tf:"library,omitempty"`

	// (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a FAILED or INTERNAL_ERROR lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: PENDING, RUNNING, TERMINATING, TERMINATED, SKIPPED or INTERNAL_ERROR.
	MaxRetries *float64 `json:"maxRetries,omitempty" tf:"max_retries,omitempty"`

	// (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
	MinRetryIntervalMillis *float64 `json:"minRetryIntervalMillis,omitempty" tf:"min_retry_interval_millis,omitempty"`

	// Same set of parameters as for databricks_cluster resource.
	NewCluster []JobTaskNewClusterInitParameters `json:"newCluster,omitempty" tf:"new_cluster,omitempty"`

	// Task to run against the inputs list.
	NotebookTask []JobTaskNotebookTaskInitParameters `json:"notebookTask,omitempty" tf:"notebook_task,omitempty"`

	// An optional block controlling the notification settings on the job level (described below).
	NotificationSettings []JobTaskNotificationSettingsInitParameters `json:"notificationSettings,omitempty" tf:"notification_settings,omitempty"`

	// Task to run against the inputs list.
	PipelineTask []JobTaskPipelineTaskInitParameters `json:"pipelineTask,omitempty" tf:"pipeline_task,omitempty"`

	// Task to run against the inputs list.
	PythonWheelTask []JobTaskPythonWheelTaskInitParameters `json:"pythonWheelTask,omitempty" tf:"python_wheel_task,omitempty"`

	// (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
	RetryOnTimeout *bool `json:"retryOnTimeout,omitempty" tf:"retry_on_timeout,omitempty"`

	// An optional value indicating the condition that determines whether the task should be run once its dependencies have been completed. When omitted, defaults to ALL_SUCCESS.
	RunIf *string `json:"runIf,omitempty" tf:"run_if,omitempty"`

	// Task to run against the inputs list.
	RunJobTask []JobTaskRunJobTaskInitParameters `json:"runJobTask,omitempty" tf:"run_job_task,omitempty"`

	// Task to run against the inputs list.
	SQLTask []TaskSQLTaskInitParameters `json:"sqlTask,omitempty" tf:"sql_task,omitempty"`

	// Task to run against the inputs list.
	SparkJarTask []JobTaskSparkJarTaskInitParameters `json:"sparkJarTask,omitempty" tf:"spark_jar_task,omitempty"`

	// Task to run against the inputs list.
	SparkPythonTask []JobTaskSparkPythonTaskInitParameters `json:"sparkPythonTask,omitempty" tf:"spark_python_task,omitempty"`

	// Task to run against the inputs list.
	SparkSubmitTask []JobTaskSparkSubmitTaskInitParameters `json:"sparkSubmitTask,omitempty" tf:"spark_submit_task,omitempty"`

	// string specifying an unique key for a given task.
	TaskKey *string `json:"taskKey,omitempty" tf:"task_key,omitempty"`

	// (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
	TimeoutSeconds *float64 `json:"timeoutSeconds,omitempty" tf:"timeout_seconds,omitempty"`

	// (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this job begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
	WebhookNotifications []TaskWebhookNotificationsInitParameters `json:"webhookNotifications,omitempty" tf:"webhook_notifications,omitempty"`
}

type TaskLibraryCranInitParameters struct {
	Package *string `json:"package,omitempty" tf:"package,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type TaskLibraryCranObservation struct {
	Package *string `json:"package,omitempty" tf:"package,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type TaskLibraryCranParameters struct {

	// +kubebuilder:validation:Optional
	Package *string `json:"package" tf:"package,omitempty"`

	// +kubebuilder:validation:Optional
	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type TaskLibraryInitParameters struct {
	Cran []LibraryCranInitParameters `json:"cran,omitempty" tf:"cran,omitempty"`

	Egg *string `json:"egg,omitempty" tf:"egg,omitempty"`

	Jar *string `json:"jar,omitempty" tf:"jar,omitempty"`

	Maven []LibraryMavenInitParameters `json:"maven,omitempty" tf:"maven,omitempty"`

	Pypi []LibraryPypiInitParameters `json:"pypi,omitempty" tf:"pypi,omitempty"`

	Whl *string `json:"whl,omitempty" tf:"whl,omitempty"`
}

type TaskLibraryMavenInitParameters struct {
	Coordinates *string `json:"coordinates,omitempty" tf:"coordinates,omitempty"`

	Exclusions []*string `json:"exclusions,omitempty" tf:"exclusions,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type TaskLibraryMavenObservation struct {
	Coordinates *string `json:"coordinates,omitempty" tf:"coordinates,omitempty"`

	Exclusions []*string `json:"exclusions,omitempty" tf:"exclusions,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type TaskLibraryMavenParameters struct {

	// +kubebuilder:validation:Optional
	Coordinates *string `json:"coordinates" tf:"coordinates,omitempty"`

	// +kubebuilder:validation:Optional
	Exclusions []*string `json:"exclusions,omitempty" tf:"exclusions,omitempty"`

	// +kubebuilder:validation:Optional
	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type TaskLibraryObservation struct {
	Cran []LibraryCranObservation `json:"cran,omitempty" tf:"cran,omitempty"`

	Egg *string `json:"egg,omitempty" tf:"egg,omitempty"`

	Jar *string `json:"jar,omitempty" tf:"jar,omitempty"`

	Maven []LibraryMavenObservation `json:"maven,omitempty" tf:"maven,omitempty"`

	Pypi []LibraryPypiObservation `json:"pypi,omitempty" tf:"pypi,omitempty"`

	Whl *string `json:"whl,omitempty" tf:"whl,omitempty"`
}

type TaskLibraryParameters struct {

	// +kubebuilder:validation:Optional
	Cran []LibraryCranParameters `json:"cran,omitempty" tf:"cran,omitempty"`

	// +kubebuilder:validation:Optional
	Egg *string `json:"egg,omitempty" tf:"egg,omitempty"`

	// +kubebuilder:validation:Optional
	Jar *string `json:"jar,omitempty" tf:"jar,omitempty"`

	// +kubebuilder:validation:Optional
	Maven []LibraryMavenParameters `json:"maven,omitempty" tf:"maven,omitempty"`

	// +kubebuilder:validation:Optional
	Pypi []LibraryPypiParameters `json:"pypi,omitempty" tf:"pypi,omitempty"`

	// +kubebuilder:validation:Optional
	Whl *string `json:"whl,omitempty" tf:"whl,omitempty"`
}

type TaskLibraryPypiInitParameters struct {
	Package *string `json:"package,omitempty" tf:"package,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type TaskLibraryPypiObservation struct {
	Package *string `json:"package,omitempty" tf:"package,omitempty"`

	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type TaskLibraryPypiParameters struct {

	// +kubebuilder:validation:Optional
	Package *string `json:"package" tf:"package,omitempty"`

	// +kubebuilder:validation:Optional
	Repo *string `json:"repo,omitempty" tf:"repo,omitempty"`
}

type TaskNewClusterAutoscaleInitParameters struct {
	MaxWorkers *float64 `json:"maxWorkers,omitempty" tf:"max_workers,omitempty"`

	MinWorkers *float64 `json:"minWorkers,omitempty" tf:"min_workers,omitempty"`
}

type TaskNewClusterAutoscaleObservation struct {
	MaxWorkers *float64 `json:"maxWorkers,omitempty" tf:"max_workers,omitempty"`

	MinWorkers *float64 `json:"minWorkers,omitempty" tf:"min_workers,omitempty"`
}

type TaskNewClusterAutoscaleParameters struct {

	// +kubebuilder:validation:Optional
	MaxWorkers *float64 `json:"maxWorkers,omitempty" tf:"max_workers,omitempty"`

	// +kubebuilder:validation:Optional
	MinWorkers *float64 `json:"minWorkers,omitempty" tf:"min_workers,omitempty"`
}

type TaskNewClusterAwsAttributesInitParameters struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	EBSVolumeCount *float64 `json:"ebsVolumeCount,omitempty" tf:"ebs_volume_count,omitempty"`

	EBSVolumeSize *float64 `json:"ebsVolumeSize,omitempty" tf:"ebs_volume_size,omitempty"`

	EBSVolumeType *string `json:"ebsVolumeType,omitempty" tf:"ebs_volume_type,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	InstanceProfileArn *string `json:"instanceProfileArn,omitempty" tf:"instance_profile_arn,omitempty"`

	SpotBidPricePercent *float64 `json:"spotBidPricePercent,omitempty" tf:"spot_bid_price_percent,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type TaskNewClusterAwsAttributesObservation struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	EBSVolumeCount *float64 `json:"ebsVolumeCount,omitempty" tf:"ebs_volume_count,omitempty"`

	EBSVolumeSize *float64 `json:"ebsVolumeSize,omitempty" tf:"ebs_volume_size,omitempty"`

	EBSVolumeType *string `json:"ebsVolumeType,omitempty" tf:"ebs_volume_type,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	InstanceProfileArn *string `json:"instanceProfileArn,omitempty" tf:"instance_profile_arn,omitempty"`

	SpotBidPricePercent *float64 `json:"spotBidPricePercent,omitempty" tf:"spot_bid_price_percent,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type TaskNewClusterAwsAttributesParameters struct {

	// +kubebuilder:validation:Optional
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	// +kubebuilder:validation:Optional
	EBSVolumeCount *float64 `json:"ebsVolumeCount,omitempty" tf:"ebs_volume_count,omitempty"`

	// +kubebuilder:validation:Optional
	EBSVolumeSize *float64 `json:"ebsVolumeSize,omitempty" tf:"ebs_volume_size,omitempty"`

	// +kubebuilder:validation:Optional
	EBSVolumeType *string `json:"ebsVolumeType,omitempty" tf:"ebs_volume_type,omitempty"`

	// +kubebuilder:validation:Optional
	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	// +kubebuilder:validation:Optional
	InstanceProfileArn *string `json:"instanceProfileArn,omitempty" tf:"instance_profile_arn,omitempty"`

	// +kubebuilder:validation:Optional
	SpotBidPricePercent *float64 `json:"spotBidPricePercent,omitempty" tf:"spot_bid_price_percent,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type TaskNewClusterAzureAttributesInitParameters struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	SpotBidMaxPrice *float64 `json:"spotBidMaxPrice,omitempty" tf:"spot_bid_max_price,omitempty"`
}

type TaskNewClusterAzureAttributesObservation struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	SpotBidMaxPrice *float64 `json:"spotBidMaxPrice,omitempty" tf:"spot_bid_max_price,omitempty"`
}

type TaskNewClusterAzureAttributesParameters struct {

	// +kubebuilder:validation:Optional
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	// +kubebuilder:validation:Optional
	FirstOnDemand *float64 `json:"firstOnDemand,omitempty" tf:"first_on_demand,omitempty"`

	// +kubebuilder:validation:Optional
	SpotBidMaxPrice *float64 `json:"spotBidMaxPrice,omitempty" tf:"spot_bid_max_price,omitempty"`
}

type TaskNewClusterClusterLogConfDbfsInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type TaskNewClusterClusterLogConfDbfsObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type TaskNewClusterClusterLogConfDbfsParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type TaskNewClusterClusterLogConfInitParameters struct {
	Dbfs []NewClusterClusterLogConfDbfsInitParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	S3 []NewClusterClusterLogConfS3InitParameters `json:"s3,omitempty" tf:"s3,omitempty"`
}

type TaskNewClusterClusterLogConfObservation struct {
	Dbfs []NewClusterClusterLogConfDbfsObservation `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	S3 []NewClusterClusterLogConfS3Observation `json:"s3,omitempty" tf:"s3,omitempty"`
}

type TaskNewClusterClusterLogConfParameters struct {

	// +kubebuilder:validation:Optional
	Dbfs []NewClusterClusterLogConfDbfsParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// +kubebuilder:validation:Optional
	S3 []NewClusterClusterLogConfS3Parameters `json:"s3,omitempty" tf:"s3,omitempty"`
}

type TaskNewClusterClusterLogConfS3InitParameters struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type TaskNewClusterClusterLogConfS3Observation struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type TaskNewClusterClusterLogConfS3Parameters struct {

	// +kubebuilder:validation:Optional
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`

	// +kubebuilder:validation:Optional
	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	// +kubebuilder:validation:Optional
	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	// +kubebuilder:validation:Optional
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// +kubebuilder:validation:Optional
	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	// +kubebuilder:validation:Optional
	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type TaskNewClusterClusterMountInfoInitParameters struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	LocalMountDirPath *string `json:"localMountDirPath,omitempty" tf:"local_mount_dir_path,omitempty"`

	NetworkFilesystemInfo []NewClusterClusterMountInfoNetworkFilesystemInfoInitParameters `json:"networkFilesystemInfo,omitempty" tf:"network_filesystem_info,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	RemoteMountDirPath *string `json:"remoteMountDirPath,omitempty" tf:"remote_mount_dir_path,omitempty"`
}

type TaskNewClusterClusterMountInfoNetworkFilesystemInfoInitParameters struct {
	MountOptions *string `json:"mountOptions,omitempty" tf:"mount_options,omitempty"`

	ServerAddress *string `json:"serverAddress,omitempty" tf:"server_address,omitempty"`
}

type TaskNewClusterClusterMountInfoNetworkFilesystemInfoObservation struct {
	MountOptions *string `json:"mountOptions,omitempty" tf:"mount_options,omitempty"`

	ServerAddress *string `json:"serverAddress,omitempty" tf:"server_address,omitempty"`
}

type TaskNewClusterClusterMountInfoNetworkFilesystemInfoParameters struct {

	// +kubebuilder:validation:Optional
	MountOptions *string `json:"mountOptions,omitempty" tf:"mount_options,omitempty"`

	// +kubebuilder:validation:Optional
	ServerAddress *string `json:"serverAddress" tf:"server_address,omitempty"`
}

type TaskNewClusterClusterMountInfoObservation struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	LocalMountDirPath *string `json:"localMountDirPath,omitempty" tf:"local_mount_dir_path,omitempty"`

	NetworkFilesystemInfo []NewClusterClusterMountInfoNetworkFilesystemInfoObservation `json:"networkFilesystemInfo,omitempty" tf:"network_filesystem_info,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	RemoteMountDirPath *string `json:"remoteMountDirPath,omitempty" tf:"remote_mount_dir_path,omitempty"`
}

type TaskNewClusterClusterMountInfoParameters struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	// +kubebuilder:validation:Optional
	LocalMountDirPath *string `json:"localMountDirPath" tf:"local_mount_dir_path,omitempty"`

	// +kubebuilder:validation:Optional
	NetworkFilesystemInfo []NewClusterClusterMountInfoNetworkFilesystemInfoParameters `json:"networkFilesystemInfo" tf:"network_filesystem_info,omitempty"`

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	// +kubebuilder:validation:Optional
	RemoteMountDirPath *string `json:"remoteMountDirPath,omitempty" tf:"remote_mount_dir_path,omitempty"`
}

type TaskNewClusterDockerImageBasicAuthInitParameters struct {

	// An optional name for the job. The default value is Untitled.
	Username *string `json:"username,omitempty" tf:"username,omitempty"`
}

type TaskNewClusterDockerImageBasicAuthObservation struct {

	// An optional name for the job. The default value is Untitled.
	Username *string `json:"username,omitempty" tf:"username,omitempty"`
}

type TaskNewClusterDockerImageBasicAuthParameters struct {

	// +kubebuilder:validation:Required
	PasswordSecretRef v1.SecretKeySelector `json:"passwordSecretRef" tf:"-"`

	// An optional name for the job. The default value is Untitled.
	// +kubebuilder:validation:Optional
	Username *string `json:"username" tf:"username,omitempty"`
}

type TaskNewClusterDockerImageInitParameters struct {
	BasicAuth []NewClusterDockerImageBasicAuthInitParameters `json:"basicAuth,omitempty" tf:"basic_auth,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	URL *string `json:"url,omitempty" tf:"url,omitempty"`
}

type TaskNewClusterDockerImageObservation struct {
	BasicAuth []NewClusterDockerImageBasicAuthObservation `json:"basicAuth,omitempty" tf:"basic_auth,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	URL *string `json:"url,omitempty" tf:"url,omitempty"`
}

type TaskNewClusterDockerImageParameters struct {

	// +kubebuilder:validation:Optional
	BasicAuth []NewClusterDockerImageBasicAuthParameters `json:"basicAuth,omitempty" tf:"basic_auth,omitempty"`

	// string with URL under the Unity Catalog external location that will be monitored for new files. Please note that have a trailing slash character (/).
	// +kubebuilder:validation:Optional
	URL *string `json:"url" tf:"url,omitempty"`
}

type TaskNewClusterGCPAttributesInitParameters struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	BootDiskSize *float64 `json:"bootDiskSize,omitempty" tf:"boot_disk_size,omitempty"`

	GoogleServiceAccount *string `json:"googleServiceAccount,omitempty" tf:"google_service_account,omitempty"`

	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`

	UsePreemptibleExecutors *bool `json:"usePreemptibleExecutors,omitempty" tf:"use_preemptible_executors,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type TaskNewClusterGCPAttributesObservation struct {
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	BootDiskSize *float64 `json:"bootDiskSize,omitempty" tf:"boot_disk_size,omitempty"`

	GoogleServiceAccount *string `json:"googleServiceAccount,omitempty" tf:"google_service_account,omitempty"`

	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`

	UsePreemptibleExecutors *bool `json:"usePreemptibleExecutors,omitempty" tf:"use_preemptible_executors,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type TaskNewClusterGCPAttributesParameters struct {

	// +kubebuilder:validation:Optional
	Availability *string `json:"availability,omitempty" tf:"availability,omitempty"`

	// +kubebuilder:validation:Optional
	BootDiskSize *float64 `json:"bootDiskSize,omitempty" tf:"boot_disk_size,omitempty"`

	// +kubebuilder:validation:Optional
	GoogleServiceAccount *string `json:"googleServiceAccount,omitempty" tf:"google_service_account,omitempty"`

	// +kubebuilder:validation:Optional
	LocalSsdCount *float64 `json:"localSsdCount,omitempty" tf:"local_ssd_count,omitempty"`

	// +kubebuilder:validation:Optional
	UsePreemptibleExecutors *bool `json:"usePreemptibleExecutors,omitempty" tf:"use_preemptible_executors,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type TaskNewClusterInitParameters struct {
	ApplyPolicyDefaultValues *bool `json:"applyPolicyDefaultValues,omitempty" tf:"apply_policy_default_values,omitempty"`

	Autoscale []TaskNewClusterAutoscaleInitParameters `json:"autoscale,omitempty" tf:"autoscale,omitempty"`

	AutoterminationMinutes *float64 `json:"autoterminationMinutes,omitempty" tf:"autotermination_minutes,omitempty"`

	AwsAttributes []TaskNewClusterAwsAttributesInitParameters `json:"awsAttributes,omitempty" tf:"aws_attributes,omitempty"`

	AzureAttributes []TaskNewClusterAzureAttributesInitParameters `json:"azureAttributes,omitempty" tf:"azure_attributes,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	ClusterLogConf []TaskNewClusterClusterLogConfInitParameters `json:"clusterLogConf,omitempty" tf:"cluster_log_conf,omitempty"`

	ClusterMountInfo []TaskNewClusterClusterMountInfoInitParameters `json:"clusterMountInfo,omitempty" tf:"cluster_mount_info,omitempty"`

	// An optional name for the job. The default value is Untitled.
	ClusterName *string `json:"clusterName,omitempty" tf:"cluster_name,omitempty"`

	CustomTags map[string]*string `json:"customTags,omitempty" tf:"custom_tags,omitempty"`

	DataSecurityMode *string `json:"dataSecurityMode,omitempty" tf:"data_security_mode,omitempty"`

	DockerImage []TaskNewClusterDockerImageInitParameters `json:"dockerImage,omitempty" tf:"docker_image,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverInstancePoolID *string `json:"driverInstancePoolId,omitempty" tf:"driver_instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverNodeTypeID *string `json:"driverNodeTypeId,omitempty" tf:"driver_node_type_id,omitempty"`

	EnableElasticDisk *bool `json:"enableElasticDisk,omitempty" tf:"enable_elastic_disk,omitempty"`

	EnableLocalDiskEncryption *bool `json:"enableLocalDiskEncryption,omitempty" tf:"enable_local_disk_encryption,omitempty"`

	GCPAttributes []TaskNewClusterGCPAttributesInitParameters `json:"gcpAttributes,omitempty" tf:"gcp_attributes,omitempty"`

	IdempotencyToken *string `json:"idempotencyToken,omitempty" tf:"idempotency_token,omitempty"`

	InitScripts []TaskNewClusterInitScriptsInitParameters `json:"initScripts,omitempty" tf:"init_scripts,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	InstancePoolID *string `json:"instancePoolId,omitempty" tf:"instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	NodeTypeID *string `json:"nodeTypeId,omitempty" tf:"node_type_id,omitempty"`

	NumWorkers *float64 `json:"numWorkers,omitempty" tf:"num_workers,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	PolicyID *string `json:"policyId,omitempty" tf:"policy_id,omitempty"`

	RuntimeEngine *string `json:"runtimeEngine,omitempty" tf:"runtime_engine,omitempty"`

	SSHPublicKeys []*string `json:"sshPublicKeys,omitempty" tf:"ssh_public_keys,omitempty"`

	// An optional name for the job. The default value is Untitled.
	SingleUserName *string `json:"singleUserName,omitempty" tf:"single_user_name,omitempty"`

	SparkConf map[string]*string `json:"sparkConf,omitempty" tf:"spark_conf,omitempty"`

	SparkEnvVars map[string]*string `json:"sparkEnvVars,omitempty" tf:"spark_env_vars,omitempty"`

	// parameter in databricks_cluster and other resources.
	SparkVersion *string `json:"sparkVersion,omitempty" tf:"spark_version,omitempty"`

	WorkloadType []TaskNewClusterWorkloadTypeInitParameters `json:"workloadType,omitempty" tf:"workload_type,omitempty"`
}

type TaskNewClusterInitScriptsAbfssInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsAbfssObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsAbfssParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsDbfsInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsDbfsObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsDbfsParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsFileInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsFileObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsFileParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsGcsInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsGcsObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsGcsParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsInitParameters struct {
	Abfss []NewClusterInitScriptsAbfssInitParameters `json:"abfss,omitempty" tf:"abfss,omitempty"`

	Dbfs []TaskNewClusterInitScriptsDbfsInitParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// block consisting of single string fields:
	File []NewClusterInitScriptsFileInitParameters `json:"file,omitempty" tf:"file,omitempty"`

	Gcs []NewClusterInitScriptsGcsInitParameters `json:"gcs,omitempty" tf:"gcs,omitempty"`

	S3 []TaskNewClusterInitScriptsS3InitParameters `json:"s3,omitempty" tf:"s3,omitempty"`

	Volumes []NewClusterInitScriptsVolumesInitParameters `json:"volumes,omitempty" tf:"volumes,omitempty"`

	Workspace []NewClusterInitScriptsWorkspaceInitParameters `json:"workspace,omitempty" tf:"workspace,omitempty"`
}

type TaskNewClusterInitScriptsObservation struct {
	Abfss []NewClusterInitScriptsAbfssObservation `json:"abfss,omitempty" tf:"abfss,omitempty"`

	Dbfs []TaskNewClusterInitScriptsDbfsObservation `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// block consisting of single string fields:
	File []NewClusterInitScriptsFileObservation `json:"file,omitempty" tf:"file,omitempty"`

	Gcs []NewClusterInitScriptsGcsObservation `json:"gcs,omitempty" tf:"gcs,omitempty"`

	S3 []TaskNewClusterInitScriptsS3Observation `json:"s3,omitempty" tf:"s3,omitempty"`

	Volumes []NewClusterInitScriptsVolumesObservation `json:"volumes,omitempty" tf:"volumes,omitempty"`

	Workspace []NewClusterInitScriptsWorkspaceObservation `json:"workspace,omitempty" tf:"workspace,omitempty"`
}

type TaskNewClusterInitScriptsParameters struct {

	// +kubebuilder:validation:Optional
	Abfss []NewClusterInitScriptsAbfssParameters `json:"abfss,omitempty" tf:"abfss,omitempty"`

	// +kubebuilder:validation:Optional
	Dbfs []TaskNewClusterInitScriptsDbfsParameters `json:"dbfs,omitempty" tf:"dbfs,omitempty"`

	// block consisting of single string fields:
	// +kubebuilder:validation:Optional
	File []NewClusterInitScriptsFileParameters `json:"file,omitempty" tf:"file,omitempty"`

	// +kubebuilder:validation:Optional
	Gcs []NewClusterInitScriptsGcsParameters `json:"gcs,omitempty" tf:"gcs,omitempty"`

	// +kubebuilder:validation:Optional
	S3 []TaskNewClusterInitScriptsS3Parameters `json:"s3,omitempty" tf:"s3,omitempty"`

	// +kubebuilder:validation:Optional
	Volumes []NewClusterInitScriptsVolumesParameters `json:"volumes,omitempty" tf:"volumes,omitempty"`

	// +kubebuilder:validation:Optional
	Workspace []NewClusterInitScriptsWorkspaceParameters `json:"workspace,omitempty" tf:"workspace,omitempty"`
}

type TaskNewClusterInitScriptsS3InitParameters struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type TaskNewClusterInitScriptsS3Observation struct {
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`

	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type TaskNewClusterInitScriptsS3Parameters struct {

	// +kubebuilder:validation:Optional
	CannedACL *string `json:"cannedAcl,omitempty" tf:"canned_acl,omitempty"`

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`

	// +kubebuilder:validation:Optional
	EnableEncryption *bool `json:"enableEncryption,omitempty" tf:"enable_encryption,omitempty"`

	// +kubebuilder:validation:Optional
	EncryptionType *string `json:"encryptionType,omitempty" tf:"encryption_type,omitempty"`

	// +kubebuilder:validation:Optional
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// +kubebuilder:validation:Optional
	KMSKey *string `json:"kmsKey,omitempty" tf:"kms_key,omitempty"`

	// +kubebuilder:validation:Optional
	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type TaskNewClusterInitScriptsVolumesInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsVolumesObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsVolumesParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsWorkspaceInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsWorkspaceObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type TaskNewClusterInitScriptsWorkspaceParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type TaskNewClusterObservation struct {
	ApplyPolicyDefaultValues *bool `json:"applyPolicyDefaultValues,omitempty" tf:"apply_policy_default_values,omitempty"`

	Autoscale []TaskNewClusterAutoscaleObservation `json:"autoscale,omitempty" tf:"autoscale,omitempty"`

	AutoterminationMinutes *float64 `json:"autoterminationMinutes,omitempty" tf:"autotermination_minutes,omitempty"`

	AwsAttributes []TaskNewClusterAwsAttributesObservation `json:"awsAttributes,omitempty" tf:"aws_attributes,omitempty"`

	AzureAttributes []TaskNewClusterAzureAttributesObservation `json:"azureAttributes,omitempty" tf:"azure_attributes,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	ClusterLogConf []TaskNewClusterClusterLogConfObservation `json:"clusterLogConf,omitempty" tf:"cluster_log_conf,omitempty"`

	ClusterMountInfo []TaskNewClusterClusterMountInfoObservation `json:"clusterMountInfo,omitempty" tf:"cluster_mount_info,omitempty"`

	// An optional name for the job. The default value is Untitled.
	ClusterName *string `json:"clusterName,omitempty" tf:"cluster_name,omitempty"`

	CustomTags map[string]*string `json:"customTags,omitempty" tf:"custom_tags,omitempty"`

	DataSecurityMode *string `json:"dataSecurityMode,omitempty" tf:"data_security_mode,omitempty"`

	DockerImage []TaskNewClusterDockerImageObservation `json:"dockerImage,omitempty" tf:"docker_image,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverInstancePoolID *string `json:"driverInstancePoolId,omitempty" tf:"driver_instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	DriverNodeTypeID *string `json:"driverNodeTypeId,omitempty" tf:"driver_node_type_id,omitempty"`

	EnableElasticDisk *bool `json:"enableElasticDisk,omitempty" tf:"enable_elastic_disk,omitempty"`

	EnableLocalDiskEncryption *bool `json:"enableLocalDiskEncryption,omitempty" tf:"enable_local_disk_encryption,omitempty"`

	GCPAttributes []TaskNewClusterGCPAttributesObservation `json:"gcpAttributes,omitempty" tf:"gcp_attributes,omitempty"`

	IdempotencyToken *string `json:"idempotencyToken,omitempty" tf:"idempotency_token,omitempty"`

	InitScripts []TaskNewClusterInitScriptsObservation `json:"initScripts,omitempty" tf:"init_scripts,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	InstancePoolID *string `json:"instancePoolId,omitempty" tf:"instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	NodeTypeID *string `json:"nodeTypeId,omitempty" tf:"node_type_id,omitempty"`

	NumWorkers *float64 `json:"numWorkers,omitempty" tf:"num_workers,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	PolicyID *string `json:"policyId,omitempty" tf:"policy_id,omitempty"`

	RuntimeEngine *string `json:"runtimeEngine,omitempty" tf:"runtime_engine,omitempty"`

	SSHPublicKeys []*string `json:"sshPublicKeys,omitempty" tf:"ssh_public_keys,omitempty"`

	// An optional name for the job. The default value is Untitled.
	SingleUserName *string `json:"singleUserName,omitempty" tf:"single_user_name,omitempty"`

	SparkConf map[string]*string `json:"sparkConf,omitempty" tf:"spark_conf,omitempty"`

	SparkEnvVars map[string]*string `json:"sparkEnvVars,omitempty" tf:"spark_env_vars,omitempty"`

	// parameter in databricks_cluster and other resources.
	SparkVersion *string `json:"sparkVersion,omitempty" tf:"spark_version,omitempty"`

	WorkloadType []TaskNewClusterWorkloadTypeObservation `json:"workloadType,omitempty" tf:"workload_type,omitempty"`
}

type TaskNewClusterParameters struct {

	// +kubebuilder:validation:Optional
	ApplyPolicyDefaultValues *bool `json:"applyPolicyDefaultValues,omitempty" tf:"apply_policy_default_values,omitempty"`

	// +kubebuilder:validation:Optional
	Autoscale []TaskNewClusterAutoscaleParameters `json:"autoscale,omitempty" tf:"autoscale,omitempty"`

	// +kubebuilder:validation:Optional
	AutoterminationMinutes *float64 `json:"autoterminationMinutes,omitempty" tf:"autotermination_minutes,omitempty"`

	// +kubebuilder:validation:Optional
	AwsAttributes []TaskNewClusterAwsAttributesParameters `json:"awsAttributes,omitempty" tf:"aws_attributes,omitempty"`

	// +kubebuilder:validation:Optional
	AzureAttributes []TaskNewClusterAzureAttributesParameters `json:"azureAttributes,omitempty" tf:"azure_attributes,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// +kubebuilder:validation:Optional
	ClusterLogConf []TaskNewClusterClusterLogConfParameters `json:"clusterLogConf,omitempty" tf:"cluster_log_conf,omitempty"`

	// +kubebuilder:validation:Optional
	ClusterMountInfo []TaskNewClusterClusterMountInfoParameters `json:"clusterMountInfo,omitempty" tf:"cluster_mount_info,omitempty"`

	// An optional name for the job. The default value is Untitled.
	// +kubebuilder:validation:Optional
	ClusterName *string `json:"clusterName,omitempty" tf:"cluster_name,omitempty"`

	// +kubebuilder:validation:Optional
	CustomTags map[string]*string `json:"customTags,omitempty" tf:"custom_tags,omitempty"`

	// +kubebuilder:validation:Optional
	DataSecurityMode *string `json:"dataSecurityMode,omitempty" tf:"data_security_mode,omitempty"`

	// +kubebuilder:validation:Optional
	DockerImage []TaskNewClusterDockerImageParameters `json:"dockerImage,omitempty" tf:"docker_image,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	DriverInstancePoolID *string `json:"driverInstancePoolId,omitempty" tf:"driver_instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	DriverNodeTypeID *string `json:"driverNodeTypeId,omitempty" tf:"driver_node_type_id,omitempty"`

	// +kubebuilder:validation:Optional
	EnableElasticDisk *bool `json:"enableElasticDisk,omitempty" tf:"enable_elastic_disk,omitempty"`

	// +kubebuilder:validation:Optional
	EnableLocalDiskEncryption *bool `json:"enableLocalDiskEncryption,omitempty" tf:"enable_local_disk_encryption,omitempty"`

	// +kubebuilder:validation:Optional
	GCPAttributes []TaskNewClusterGCPAttributesParameters `json:"gcpAttributes,omitempty" tf:"gcp_attributes,omitempty"`

	// +kubebuilder:validation:Optional
	IdempotencyToken *string `json:"idempotencyToken,omitempty" tf:"idempotency_token,omitempty"`

	// +kubebuilder:validation:Optional
	InitScripts []TaskNewClusterInitScriptsParameters `json:"initScripts,omitempty" tf:"init_scripts,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	InstancePoolID *string `json:"instancePoolId,omitempty" tf:"instance_pool_id,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	NodeTypeID *string `json:"nodeTypeId,omitempty" tf:"node_type_id,omitempty"`

	// +kubebuilder:validation:Optional
	NumWorkers *float64 `json:"numWorkers" tf:"num_workers,omitempty"`

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	PolicyID *string `json:"policyId,omitempty" tf:"policy_id,omitempty"`

	// +kubebuilder:validation:Optional
	RuntimeEngine *string `json:"runtimeEngine,omitempty" tf:"runtime_engine,omitempty"`

	// +kubebuilder:validation:Optional
	SSHPublicKeys []*string `json:"sshPublicKeys,omitempty" tf:"ssh_public_keys,omitempty"`

	// An optional name for the job. The default value is Untitled.
	// +kubebuilder:validation:Optional
	SingleUserName *string `json:"singleUserName,omitempty" tf:"single_user_name,omitempty"`

	// +kubebuilder:validation:Optional
	SparkConf map[string]*string `json:"sparkConf,omitempty" tf:"spark_conf,omitempty"`

	// +kubebuilder:validation:Optional
	SparkEnvVars map[string]*string `json:"sparkEnvVars,omitempty" tf:"spark_env_vars,omitempty"`

	// parameter in databricks_cluster and other resources.
	// +kubebuilder:validation:Optional
	SparkVersion *string `json:"sparkVersion" tf:"spark_version,omitempty"`

	// +kubebuilder:validation:Optional
	WorkloadType []TaskNewClusterWorkloadTypeParameters `json:"workloadType,omitempty" tf:"workload_type,omitempty"`
}

type TaskNewClusterWorkloadTypeClientsInitParameters struct {
	Jobs *bool `json:"jobs,omitempty" tf:"jobs,omitempty"`

	Notebooks *bool `json:"notebooks,omitempty" tf:"notebooks,omitempty"`
}

type TaskNewClusterWorkloadTypeClientsObservation struct {
	Jobs *bool `json:"jobs,omitempty" tf:"jobs,omitempty"`

	Notebooks *bool `json:"notebooks,omitempty" tf:"notebooks,omitempty"`
}

type TaskNewClusterWorkloadTypeClientsParameters struct {

	// +kubebuilder:validation:Optional
	Jobs *bool `json:"jobs,omitempty" tf:"jobs,omitempty"`

	// +kubebuilder:validation:Optional
	Notebooks *bool `json:"notebooks,omitempty" tf:"notebooks,omitempty"`
}

type TaskNewClusterWorkloadTypeInitParameters struct {
	Clients []NewClusterWorkloadTypeClientsInitParameters `json:"clients,omitempty" tf:"clients,omitempty"`
}

type TaskNewClusterWorkloadTypeObservation struct {
	Clients []NewClusterWorkloadTypeClientsObservation `json:"clients,omitempty" tf:"clients,omitempty"`
}

type TaskNewClusterWorkloadTypeParameters struct {

	// +kubebuilder:validation:Optional
	Clients []NewClusterWorkloadTypeClientsParameters `json:"clients" tf:"clients,omitempty"`
}

type TaskNotebookTaskInitParameters struct {

	// (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the jobs base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using dbutils.widgets.get.
	BaseParameters map[string]*string `json:"baseParameters,omitempty" tf:"base_parameters,omitempty"`

	// The path of the databricks_notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
	NotebookPath *string `json:"notebookPath,omitempty" tf:"notebook_path,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type TaskNotebookTaskObservation struct {

	// (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the jobs base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using dbutils.widgets.get.
	BaseParameters map[string]*string `json:"baseParameters,omitempty" tf:"base_parameters,omitempty"`

	// The path of the databricks_notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
	NotebookPath *string `json:"notebookPath,omitempty" tf:"notebook_path,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type TaskNotebookTaskParameters struct {

	// (Map) Base parameters to be used for each run of this job. If the run is initiated by a call to run-now with parameters specified, the two parameters maps will be merged. If the same key is specified in base_parameters and in run-now, the value from run-now will be used. If the notebook takes a parameter that is not specified in the jobs base_parameters or the run-now override parameters, the default value from the notebook will be used. Retrieve these parameters in a notebook using dbutils.widgets.get.
	// +kubebuilder:validation:Optional
	BaseParameters map[string]*string `json:"baseParameters,omitempty" tf:"base_parameters,omitempty"`

	// The path of the databricks_notebook to be run in the Databricks workspace or remote repository. For notebooks stored in the Databricks workspace, the path must be absolute and begin with a slash. For notebooks stored in a remote repository, the path must be relative. This field is required.
	// +kubebuilder:validation:Optional
	NotebookPath *string `json:"notebookPath" tf:"notebook_path,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	// +kubebuilder:validation:Optional
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type TaskNotificationSettingsInitParameters struct {

	// (Bool) do not send notifications to recipients specified in on_start for the retried runs and do not send notifications to recipients specified in on_failure until the last retry of the run.
	AlertOnLastAttempt *bool `json:"alertOnLastAttempt,omitempty" tf:"alert_on_last_attempt,omitempty"`

	// (Bool) don't send alert for cancelled runs.
	NoAlertForCanceledRuns *bool `json:"noAlertForCanceledRuns,omitempty" tf:"no_alert_for_canceled_runs,omitempty"`

	// (Bool) don't send alert for skipped runs.
	NoAlertForSkippedRuns *bool `json:"noAlertForSkippedRuns,omitempty" tf:"no_alert_for_skipped_runs,omitempty"`
}

type TaskNotificationSettingsObservation struct {

	// (Bool) do not send notifications to recipients specified in on_start for the retried runs and do not send notifications to recipients specified in on_failure until the last retry of the run.
	AlertOnLastAttempt *bool `json:"alertOnLastAttempt,omitempty" tf:"alert_on_last_attempt,omitempty"`

	// (Bool) don't send alert for cancelled runs.
	NoAlertForCanceledRuns *bool `json:"noAlertForCanceledRuns,omitempty" tf:"no_alert_for_canceled_runs,omitempty"`

	// (Bool) don't send alert for skipped runs.
	NoAlertForSkippedRuns *bool `json:"noAlertForSkippedRuns,omitempty" tf:"no_alert_for_skipped_runs,omitempty"`
}

type TaskNotificationSettingsParameters struct {

	// (Bool) do not send notifications to recipients specified in on_start for the retried runs and do not send notifications to recipients specified in on_failure until the last retry of the run.
	// +kubebuilder:validation:Optional
	AlertOnLastAttempt *bool `json:"alertOnLastAttempt,omitempty" tf:"alert_on_last_attempt,omitempty"`

	// (Bool) don't send alert for cancelled runs.
	// +kubebuilder:validation:Optional
	NoAlertForCanceledRuns *bool `json:"noAlertForCanceledRuns,omitempty" tf:"no_alert_for_canceled_runs,omitempty"`

	// (Bool) don't send alert for skipped runs.
	// +kubebuilder:validation:Optional
	NoAlertForSkippedRuns *bool `json:"noAlertForSkippedRuns,omitempty" tf:"no_alert_for_skipped_runs,omitempty"`
}

type TaskObservation struct {
	ComputeKey *string `json:"computeKey,omitempty" tf:"compute_key,omitempty"`

	// Task to run against the inputs list.
	ConditionTask []ConditionTaskObservation `json:"conditionTask,omitempty" tf:"condition_task,omitempty"`

	// Task to run against the inputs list.
	DbtTask []TaskDbtTaskObservation `json:"dbtTask,omitempty" tf:"dbt_task,omitempty"`

	// block specifying dependency(-ies) for a given task.
	DependsOn []DependsOnObservation `json:"dependsOn,omitempty" tf:"depends_on,omitempty"`

	// An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (List) An optional set of email addresses notified when runs of this job begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
	EmailNotifications []TaskEmailNotificationsObservation `json:"emailNotifications,omitempty" tf:"email_notifications,omitempty"`

	// If existing_cluster_id, the ID of an existing cluster that will be used for all runs of this job. When running jobs on an existing cluster, you may need to manually restart the cluster if it stops responding. We strongly suggest to use new_cluster for greater reliability.
	ExistingClusterID *string `json:"existingClusterId,omitempty" tf:"existing_cluster_id,omitempty"`

	// Task to run against the inputs list.
	ForEachTask []ForEachTaskObservation `json:"forEachTask,omitempty" tf:"for_each_task,omitempty"`

	// An optional block that specifies the health conditions for the job (described below).
	Health []JobTaskHealthObservation `json:"health,omitempty" tf:"health,omitempty"`

	// Identifier that can be referenced in task block, so that cluster is shared between tasks
	JobClusterKey *string `json:"jobClusterKey,omitempty" tf:"job_cluster_key,omitempty"`

	// (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for databricks_cluster resource.
	Library []JobTaskLibraryObservation `json:"library,omitempty" tf:"library,omitempty"`

	// (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a FAILED or INTERNAL_ERROR lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: PENDING, RUNNING, TERMINATING, TERMINATED, SKIPPED or INTERNAL_ERROR.
	MaxRetries *float64 `json:"maxRetries,omitempty" tf:"max_retries,omitempty"`

	// (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
	MinRetryIntervalMillis *float64 `json:"minRetryIntervalMillis,omitempty" tf:"min_retry_interval_millis,omitempty"`

	// Same set of parameters as for databricks_cluster resource.
	NewCluster []JobTaskNewClusterObservation `json:"newCluster,omitempty" tf:"new_cluster,omitempty"`

	// Task to run against the inputs list.
	NotebookTask []JobTaskNotebookTaskObservation `json:"notebookTask,omitempty" tf:"notebook_task,omitempty"`

	// An optional block controlling the notification settings on the job level (described below).
	NotificationSettings []JobTaskNotificationSettingsObservation `json:"notificationSettings,omitempty" tf:"notification_settings,omitempty"`

	// Task to run against the inputs list.
	PipelineTask []JobTaskPipelineTaskObservation `json:"pipelineTask,omitempty" tf:"pipeline_task,omitempty"`

	// Task to run against the inputs list.
	PythonWheelTask []JobTaskPythonWheelTaskObservation `json:"pythonWheelTask,omitempty" tf:"python_wheel_task,omitempty"`

	// (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
	RetryOnTimeout *bool `json:"retryOnTimeout,omitempty" tf:"retry_on_timeout,omitempty"`

	// An optional value indicating the condition that determines whether the task should be run once its dependencies have been completed. When omitted, defaults to ALL_SUCCESS.
	RunIf *string `json:"runIf,omitempty" tf:"run_if,omitempty"`

	// Task to run against the inputs list.
	RunJobTask []JobTaskRunJobTaskObservation `json:"runJobTask,omitempty" tf:"run_job_task,omitempty"`

	// Task to run against the inputs list.
	SQLTask []TaskSQLTaskObservation `json:"sqlTask,omitempty" tf:"sql_task,omitempty"`

	// Task to run against the inputs list.
	SparkJarTask []JobTaskSparkJarTaskObservation `json:"sparkJarTask,omitempty" tf:"spark_jar_task,omitempty"`

	// Task to run against the inputs list.
	SparkPythonTask []JobTaskSparkPythonTaskObservation `json:"sparkPythonTask,omitempty" tf:"spark_python_task,omitempty"`

	// Task to run against the inputs list.
	SparkSubmitTask []JobTaskSparkSubmitTaskObservation `json:"sparkSubmitTask,omitempty" tf:"spark_submit_task,omitempty"`

	// string specifying an unique key for a given task.
	TaskKey *string `json:"taskKey,omitempty" tf:"task_key,omitempty"`

	// (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
	TimeoutSeconds *float64 `json:"timeoutSeconds,omitempty" tf:"timeout_seconds,omitempty"`

	// (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this job begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
	WebhookNotifications []TaskWebhookNotificationsObservation `json:"webhookNotifications,omitempty" tf:"webhook_notifications,omitempty"`
}

type TaskParameters struct {

	// +kubebuilder:validation:Optional
	ComputeKey *string `json:"computeKey,omitempty" tf:"compute_key,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	ConditionTask []ConditionTaskParameters `json:"conditionTask,omitempty" tf:"condition_task,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	DbtTask []TaskDbtTaskParameters `json:"dbtTask,omitempty" tf:"dbt_task,omitempty"`

	// block specifying dependency(-ies) for a given task.
	// +kubebuilder:validation:Optional
	DependsOn []DependsOnParameters `json:"dependsOn,omitempty" tf:"depends_on,omitempty"`

	// An optional description for the job. The maximum length is 1024 characters in UTF-8 encoding.
	// +kubebuilder:validation:Optional
	Description *string `json:"description,omitempty" tf:"description,omitempty"`

	// (List) An optional set of email addresses notified when runs of this job begins, completes or fails. The default behavior is to not send any emails. This field is a block and is documented below.
	// +kubebuilder:validation:Optional
	EmailNotifications []TaskEmailNotificationsParameters `json:"emailNotifications,omitempty" tf:"email_notifications,omitempty"`

	// If existing_cluster_id, the ID of an existing cluster that will be used for all runs of this job. When running jobs on an existing cluster, you may need to manually restart the cluster if it stops responding. We strongly suggest to use new_cluster for greater reliability.
	// +kubebuilder:validation:Optional
	ExistingClusterID *string `json:"existingClusterId,omitempty" tf:"existing_cluster_id,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	ForEachTask []ForEachTaskParameters `json:"forEachTask,omitempty" tf:"for_each_task,omitempty"`

	// An optional block that specifies the health conditions for the job (described below).
	// +kubebuilder:validation:Optional
	Health []JobTaskHealthParameters `json:"health,omitempty" tf:"health,omitempty"`

	// Identifier that can be referenced in task block, so that cluster is shared between tasks
	// +kubebuilder:validation:Optional
	JobClusterKey *string `json:"jobClusterKey,omitempty" tf:"job_cluster_key,omitempty"`

	// (Set) An optional list of libraries to be installed on the cluster that will execute the job. Please consult libraries section for databricks_cluster resource.
	// +kubebuilder:validation:Optional
	Library []JobTaskLibraryParameters `json:"library,omitempty" tf:"library,omitempty"`

	// (Integer) An optional maximum number of times to retry an unsuccessful run. A run is considered to be unsuccessful if it completes with a FAILED or INTERNAL_ERROR lifecycle state. The value -1 means to retry indefinitely and the value 0 means to never retry. The default behavior is to never retry. A run can have the following lifecycle state: PENDING, RUNNING, TERMINATING, TERMINATED, SKIPPED or INTERNAL_ERROR.
	// +kubebuilder:validation:Optional
	MaxRetries *float64 `json:"maxRetries,omitempty" tf:"max_retries,omitempty"`

	// (Integer) An optional minimal interval in milliseconds between the start of the failed run and the subsequent retry run. The default behavior is that unsuccessful runs are immediately retried.
	// +kubebuilder:validation:Optional
	MinRetryIntervalMillis *float64 `json:"minRetryIntervalMillis,omitempty" tf:"min_retry_interval_millis,omitempty"`

	// Same set of parameters as for databricks_cluster resource.
	// +kubebuilder:validation:Optional
	NewCluster []JobTaskNewClusterParameters `json:"newCluster,omitempty" tf:"new_cluster,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	NotebookTask []JobTaskNotebookTaskParameters `json:"notebookTask,omitempty" tf:"notebook_task,omitempty"`

	// An optional block controlling the notification settings on the job level (described below).
	// +kubebuilder:validation:Optional
	NotificationSettings []JobTaskNotificationSettingsParameters `json:"notificationSettings,omitempty" tf:"notification_settings,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	PipelineTask []JobTaskPipelineTaskParameters `json:"pipelineTask,omitempty" tf:"pipeline_task,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	PythonWheelTask []JobTaskPythonWheelTaskParameters `json:"pythonWheelTask,omitempty" tf:"python_wheel_task,omitempty"`

	// (Bool) An optional policy to specify whether to retry a job when it times out. The default behavior is to not retry on timeout.
	// +kubebuilder:validation:Optional
	RetryOnTimeout *bool `json:"retryOnTimeout,omitempty" tf:"retry_on_timeout,omitempty"`

	// An optional value indicating the condition that determines whether the task should be run once its dependencies have been completed. When omitted, defaults to ALL_SUCCESS.
	// +kubebuilder:validation:Optional
	RunIf *string `json:"runIf,omitempty" tf:"run_if,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	RunJobTask []JobTaskRunJobTaskParameters `json:"runJobTask,omitempty" tf:"run_job_task,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	SQLTask []TaskSQLTaskParameters `json:"sqlTask,omitempty" tf:"sql_task,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	SparkJarTask []JobTaskSparkJarTaskParameters `json:"sparkJarTask,omitempty" tf:"spark_jar_task,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	SparkPythonTask []JobTaskSparkPythonTaskParameters `json:"sparkPythonTask,omitempty" tf:"spark_python_task,omitempty"`

	// Task to run against the inputs list.
	// +kubebuilder:validation:Optional
	SparkSubmitTask []JobTaskSparkSubmitTaskParameters `json:"sparkSubmitTask,omitempty" tf:"spark_submit_task,omitempty"`

	// string specifying an unique key for a given task.
	// +kubebuilder:validation:Optional
	TaskKey *string `json:"taskKey,omitempty" tf:"task_key,omitempty"`

	// (Integer) An optional timeout applied to each run of this job. The default behavior is to have no timeout.
	// +kubebuilder:validation:Optional
	TimeoutSeconds *float64 `json:"timeoutSeconds,omitempty" tf:"timeout_seconds,omitempty"`

	// (List) An optional set of system destinations (for example, webhook destinations or Slack) to be notified when runs of this job begins, completes or fails. The default behavior is to not send any notifications. This field is a block and is documented below.
	// +kubebuilder:validation:Optional
	WebhookNotifications []TaskWebhookNotificationsParameters `json:"webhookNotifications,omitempty" tf:"webhook_notifications,omitempty"`
}

type TaskPipelineTaskInitParameters struct {

	// (Bool) Specifies if there should be full refresh of the pipeline.
	FullRefresh *bool `json:"fullRefresh,omitempty" tf:"full_refresh,omitempty"`

	// The pipeline's unique ID.
	PipelineID *string `json:"pipelineId,omitempty" tf:"pipeline_id,omitempty"`
}

type TaskPipelineTaskObservation struct {

	// (Bool) Specifies if there should be full refresh of the pipeline.
	FullRefresh *bool `json:"fullRefresh,omitempty" tf:"full_refresh,omitempty"`

	// The pipeline's unique ID.
	PipelineID *string `json:"pipelineId,omitempty" tf:"pipeline_id,omitempty"`
}

type TaskPipelineTaskParameters struct {

	// (Bool) Specifies if there should be full refresh of the pipeline.
	// +kubebuilder:validation:Optional
	FullRefresh *bool `json:"fullRefresh,omitempty" tf:"full_refresh,omitempty"`

	// The pipeline's unique ID.
	// +kubebuilder:validation:Optional
	PipelineID *string `json:"pipelineId" tf:"pipeline_id,omitempty"`
}

type TaskPythonWheelTaskInitParameters struct {

	// Python function as entry point for the task
	EntryPoint *string `json:"entryPoint,omitempty" tf:"entry_point,omitempty"`

	// Named parameters for the task
	NamedParameters map[string]*string `json:"namedParameters,omitempty" tf:"named_parameters,omitempty"`

	// Name of Python package
	PackageName *string `json:"packageName,omitempty" tf:"package_name,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type TaskPythonWheelTaskObservation struct {

	// Python function as entry point for the task
	EntryPoint *string `json:"entryPoint,omitempty" tf:"entry_point,omitempty"`

	// Named parameters for the task
	NamedParameters map[string]*string `json:"namedParameters,omitempty" tf:"named_parameters,omitempty"`

	// Name of Python package
	PackageName *string `json:"packageName,omitempty" tf:"package_name,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type TaskPythonWheelTaskParameters struct {

	// Python function as entry point for the task
	// +kubebuilder:validation:Optional
	EntryPoint *string `json:"entryPoint,omitempty" tf:"entry_point,omitempty"`

	// Named parameters for the task
	// +kubebuilder:validation:Optional
	NamedParameters map[string]*string `json:"namedParameters,omitempty" tf:"named_parameters,omitempty"`

	// Name of Python package
	// +kubebuilder:validation:Optional
	PackageName *string `json:"packageName,omitempty" tf:"package_name,omitempty"`

	// (List) Parameters passed to the main method.
	// +kubebuilder:validation:Optional
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type TaskRunJobTaskInitParameters struct {

	// (String) ID of the job
	JobID *float64 `json:"jobId,omitempty" tf:"job_id,omitempty"`

	// (Map) Job parameters for the task
	JobParameters map[string]*string `json:"jobParameters,omitempty" tf:"job_parameters,omitempty"`
}

type TaskRunJobTaskObservation struct {

	// (String) ID of the job
	JobID *float64 `json:"jobId,omitempty" tf:"job_id,omitempty"`

	// (Map) Job parameters for the task
	JobParameters map[string]*string `json:"jobParameters,omitempty" tf:"job_parameters,omitempty"`
}

type TaskRunJobTaskParameters struct {

	// (String) ID of the job
	// +kubebuilder:validation:Optional
	JobID *float64 `json:"jobId" tf:"job_id,omitempty"`

	// (Map) Job parameters for the task
	// +kubebuilder:validation:Optional
	JobParameters map[string]*string `json:"jobParameters,omitempty" tf:"job_parameters,omitempty"`
}

type TaskSQLTaskFileInitParameters struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type TaskSQLTaskFileObservation struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type TaskSQLTaskFileParameters struct {

	// If source is GIT: Relative path to the file in the repository specified in the git_source block with SQL commands to execute. If source is WORKSPACE: Absolute path to the file in the workspace with SQL commands to execute.
	// +kubebuilder:validation:Optional
	Path *string `json:"path" tf:"path,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	// +kubebuilder:validation:Optional
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type TaskSQLTaskInitParameters struct {

	// block consisting of following fields:
	Alert []SQLTaskAlertInitParameters `json:"alert,omitempty" tf:"alert,omitempty"`

	// block consisting of following fields:
	Dashboard []SQLTaskDashboardInitParameters `json:"dashboard,omitempty" tf:"dashboard,omitempty"`

	// block consisting of single string fields:
	File []TaskSQLTaskFileInitParameters `json:"file,omitempty" tf:"file,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters map[string]*string `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// block consisting of single string field: query_id - identifier of the Databricks SQL Query (databricks_sql_query).
	Query []SQLTaskQueryInitParameters `json:"query,omitempty" tf:"query,omitempty"`

	// The ID of the SQL warehouse that dbt should execute against.
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type TaskSQLTaskObservation struct {

	// block consisting of following fields:
	Alert []SQLTaskAlertObservation `json:"alert,omitempty" tf:"alert,omitempty"`

	// block consisting of following fields:
	Dashboard []SQLTaskDashboardObservation `json:"dashboard,omitempty" tf:"dashboard,omitempty"`

	// block consisting of single string fields:
	File []TaskSQLTaskFileObservation `json:"file,omitempty" tf:"file,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters map[string]*string `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// block consisting of single string field: query_id - identifier of the Databricks SQL Query (databricks_sql_query).
	Query []SQLTaskQueryObservation `json:"query,omitempty" tf:"query,omitempty"`

	// The ID of the SQL warehouse that dbt should execute against.
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type TaskSQLTaskParameters struct {

	// block consisting of following fields:
	// +kubebuilder:validation:Optional
	Alert []SQLTaskAlertParameters `json:"alert,omitempty" tf:"alert,omitempty"`

	// block consisting of following fields:
	// +kubebuilder:validation:Optional
	Dashboard []SQLTaskDashboardParameters `json:"dashboard,omitempty" tf:"dashboard,omitempty"`

	// block consisting of single string fields:
	// +kubebuilder:validation:Optional
	File []TaskSQLTaskFileParameters `json:"file,omitempty" tf:"file,omitempty"`

	// (List) Parameters passed to the main method.
	// +kubebuilder:validation:Optional
	Parameters map[string]*string `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// block consisting of single string field: query_id - identifier of the Databricks SQL Query (databricks_sql_query).
	// +kubebuilder:validation:Optional
	Query []SQLTaskQueryParameters `json:"query,omitempty" tf:"query,omitempty"`

	// The ID of the SQL warehouse that dbt should execute against.
	// +kubebuilder:validation:Optional
	WarehouseID *string `json:"warehouseId,omitempty" tf:"warehouse_id,omitempty"`
}

type TaskSparkJarTaskInitParameters struct {
	JarURI *string `json:"jarUri,omitempty" tf:"jar_uri,omitempty"`

	// The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use SparkContext.getOrCreate to obtain a Spark context; otherwise, runs of the job will fail.
	MainClassName *string `json:"mainClassName,omitempty" tf:"main_class_name,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type TaskSparkJarTaskObservation struct {
	JarURI *string `json:"jarUri,omitempty" tf:"jar_uri,omitempty"`

	// The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use SparkContext.getOrCreate to obtain a Spark context; otherwise, runs of the job will fail.
	MainClassName *string `json:"mainClassName,omitempty" tf:"main_class_name,omitempty"`

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type TaskSparkJarTaskParameters struct {

	// +kubebuilder:validation:Optional
	JarURI *string `json:"jarUri,omitempty" tf:"jar_uri,omitempty"`

	// The full name of the class containing the main method to be executed. This class must be contained in a JAR provided as a library. The code should use SparkContext.getOrCreate to obtain a Spark context; otherwise, runs of the job will fail.
	// +kubebuilder:validation:Optional
	MainClassName *string `json:"mainClassName,omitempty" tf:"main_class_name,omitempty"`

	// (List) Parameters passed to the main method.
	// +kubebuilder:validation:Optional
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type TaskSparkPythonTaskInitParameters struct {

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. s3:/, abfss:/, gs:/), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with /Repos. For files stored in a remote repository, the path must be relative. This field is required.
	PythonFile *string `json:"pythonFile,omitempty" tf:"python_file,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type TaskSparkPythonTaskObservation struct {

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. s3:/, abfss:/, gs:/), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with /Repos. For files stored in a remote repository, the path must be relative. This field is required.
	PythonFile *string `json:"pythonFile,omitempty" tf:"python_file,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type TaskSparkPythonTaskParameters struct {

	// (List) Parameters passed to the main method.
	// +kubebuilder:validation:Optional
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`

	// The URI of the Python file to be executed. databricks_dbfs_file, cloud file URIs (e.g. s3:/, abfss:/, gs:/), workspace paths and remote repository are supported. For Python files stored in the Databricks workspace, the path must be absolute and begin with /Repos. For files stored in a remote repository, the path must be relative. This field is required.
	// +kubebuilder:validation:Optional
	PythonFile *string `json:"pythonFile" tf:"python_file,omitempty"`

	// Location type of the Python file, can only be GIT. When set to GIT, the Python file will be retrieved from a Git repository defined in git_source.
	// +kubebuilder:validation:Optional
	Source *string `json:"source,omitempty" tf:"source,omitempty"`
}

type TaskSparkSubmitTaskInitParameters struct {

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type TaskSparkSubmitTaskObservation struct {

	// (List) Parameters passed to the main method.
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type TaskSparkSubmitTaskParameters struct {

	// (List) Parameters passed to the main method.
	// +kubebuilder:validation:Optional
	Parameters []*string `json:"parameters,omitempty" tf:"parameters,omitempty"`
}

type TaskWebhookNotificationsInitParameters struct {

	// (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	OnDurationWarningThresholdExceeded []WebhookNotificationsOnDurationWarningThresholdExceededInitParameters `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
	OnFailure []WebhookNotificationsOnFailureInitParameters `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
	OnStart []WebhookNotificationsOnStartInitParameters `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
	OnSuccess []WebhookNotificationsOnSuccessInitParameters `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type TaskWebhookNotificationsObservation struct {

	// (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	OnDurationWarningThresholdExceeded []WebhookNotificationsOnDurationWarningThresholdExceededObservation `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
	OnFailure []WebhookNotificationsOnFailureObservation `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
	OnStart []WebhookNotificationsOnStartObservation `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
	OnSuccess []WebhookNotificationsOnSuccessObservation `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type TaskWebhookNotificationsParameters struct {

	// (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	// +kubebuilder:validation:Optional
	OnDurationWarningThresholdExceeded []WebhookNotificationsOnDurationWarningThresholdExceededParameters `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
	// +kubebuilder:validation:Optional
	OnFailure []WebhookNotificationsOnFailureParameters `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
	// +kubebuilder:validation:Optional
	OnStart []WebhookNotificationsOnStartParameters `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
	// +kubebuilder:validation:Optional
	OnSuccess []WebhookNotificationsOnSuccessParameters `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type TriggerInitParameters struct {

	// configuration block to define a trigger for File Arrival events consisting of following attributes:
	FileArrival []FileArrivalInitParameters `json:"fileArrival,omitempty" tf:"file_arrival,omitempty"`

	// Indicate whether this schedule is paused or not. Either PAUSED or UNPAUSED. When the pause_status field is omitted and a schedule is provided, the server will default to using UNPAUSED as a value for pause_status.
	PauseStatus *string `json:"pauseStatus,omitempty" tf:"pause_status,omitempty"`
}

type TriggerObservation struct {

	// configuration block to define a trigger for File Arrival events consisting of following attributes:
	FileArrival []FileArrivalObservation `json:"fileArrival,omitempty" tf:"file_arrival,omitempty"`

	// Indicate whether this schedule is paused or not. Either PAUSED or UNPAUSED. When the pause_status field is omitted and a schedule is provided, the server will default to using UNPAUSED as a value for pause_status.
	PauseStatus *string `json:"pauseStatus,omitempty" tf:"pause_status,omitempty"`
}

type TriggerParameters struct {

	// configuration block to define a trigger for File Arrival events consisting of following attributes:
	// +kubebuilder:validation:Optional
	FileArrival []FileArrivalParameters `json:"fileArrival" tf:"file_arrival,omitempty"`

	// Indicate whether this schedule is paused or not. Either PAUSED or UNPAUSED. When the pause_status field is omitted and a schedule is provided, the server will default to using UNPAUSED as a value for pause_status.
	// +kubebuilder:validation:Optional
	PauseStatus *string `json:"pauseStatus,omitempty" tf:"pause_status,omitempty"`
}

type VolumesInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type VolumesObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type VolumesParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

type WebhookNotificationsInitParameters struct {

	// (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	OnDurationWarningThresholdExceeded []OnDurationWarningThresholdExceededInitParameters `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
	OnFailure []OnFailureInitParameters `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
	OnStart []OnStartInitParameters `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
	OnSuccess []OnSuccessInitParameters `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type WebhookNotificationsObservation struct {

	// (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	OnDurationWarningThresholdExceeded []OnDurationWarningThresholdExceededObservation `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
	OnFailure []OnFailureObservation `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
	OnStart []OnStartObservation `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
	OnSuccess []OnSuccessObservation `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type WebhookNotificationsOnDurationWarningThresholdExceededInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type WebhookNotificationsOnDurationWarningThresholdExceededObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type WebhookNotificationsOnDurationWarningThresholdExceededParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type WebhookNotificationsOnFailureInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type WebhookNotificationsOnFailureObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type WebhookNotificationsOnFailureParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type WebhookNotificationsOnStartInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type WebhookNotificationsOnStartObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type WebhookNotificationsOnStartParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type WebhookNotificationsOnSuccessInitParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type WebhookNotificationsOnSuccessObservation struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type WebhookNotificationsOnSuccessParameters struct {

	// ID of the system notification that is notified when an event defined in webhook_notifications is triggered.
	// +kubebuilder:validation:Optional
	ID *string `json:"id,omitempty" tf:"id,omitempty"`
}

type WebhookNotificationsParameters struct {

	// (List) list of notification IDs to call when the duration of a run exceeds the threshold specified by the RUN_DURATION_SECONDS metric in the health block.
	// +kubebuilder:validation:Optional
	OnDurationWarningThresholdExceeded []OnDurationWarningThresholdExceededParameters `json:"onDurationWarningThresholdExceeded,omitempty" tf:"on_duration_warning_threshold_exceeded,omitempty"`

	// (List) list of notification IDs to call when the run fails. A maximum of 3 destinations can be specified.
	// +kubebuilder:validation:Optional
	OnFailure []OnFailureParameters `json:"onFailure,omitempty" tf:"on_failure,omitempty"`

	// (List) list of notification IDs to call when the run starts. A maximum of 3 destinations can be specified.
	// +kubebuilder:validation:Optional
	OnStart []OnStartParameters `json:"onStart,omitempty" tf:"on_start,omitempty"`

	// (List) list of notification IDs to call when the run completes successfully. A maximum of 3 destinations can be specified.
	// +kubebuilder:validation:Optional
	OnSuccess []OnSuccessParameters `json:"onSuccess,omitempty" tf:"on_success,omitempty"`
}

type WorkloadTypeClientsInitParameters struct {
	Jobs *bool `json:"jobs,omitempty" tf:"jobs,omitempty"`

	Notebooks *bool `json:"notebooks,omitempty" tf:"notebooks,omitempty"`
}

type WorkloadTypeClientsObservation struct {
	Jobs *bool `json:"jobs,omitempty" tf:"jobs,omitempty"`

	Notebooks *bool `json:"notebooks,omitempty" tf:"notebooks,omitempty"`
}

type WorkloadTypeClientsParameters struct {

	// +kubebuilder:validation:Optional
	Jobs *bool `json:"jobs,omitempty" tf:"jobs,omitempty"`

	// +kubebuilder:validation:Optional
	Notebooks *bool `json:"notebooks,omitempty" tf:"notebooks,omitempty"`
}

type WorkloadTypeInitParameters struct {
	Clients []ClientsInitParameters `json:"clients,omitempty" tf:"clients,omitempty"`
}

type WorkloadTypeObservation struct {
	Clients []ClientsObservation `json:"clients,omitempty" tf:"clients,omitempty"`
}

type WorkloadTypeParameters struct {

	// +kubebuilder:validation:Optional
	Clients []ClientsParameters `json:"clients" tf:"clients,omitempty"`
}

type WorkspaceInitParameters struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type WorkspaceObservation struct {
	Destination *string `json:"destination,omitempty" tf:"destination,omitempty"`
}

type WorkspaceParameters struct {

	// +kubebuilder:validation:Optional
	Destination *string `json:"destination" tf:"destination,omitempty"`
}

// JobSpec defines the desired state of Job
type JobSpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     JobParameters `json:"forProvider"`
	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider JobInitParameters `json:"initProvider,omitempty"`
}

// JobStatus defines the observed state of Job.
type JobStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        JobObservation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true

// Job is the Schema for the Jobs API.
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:subresource:status
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,databricks}
type Job struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	Spec              JobSpec   `json:"spec"`
	Status            JobStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// JobList contains a list of Jobs
type JobList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []Job `json:"items"`
}

// Repository type metadata.
var (
	Job_Kind             = "Job"
	Job_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: Job_Kind}.String()
	Job_KindAPIVersion   = Job_Kind + "." + CRDGroupVersion.String()
	Job_GroupVersionKind = CRDGroupVersion.WithKind(Job_Kind)
)

func init() {
	SchemeBuilder.Register(&Job{}, &JobList{})
}
