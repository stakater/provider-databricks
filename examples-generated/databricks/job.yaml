apiVersion: databricks.crossplane.io/v1alpha1
kind: Job
metadata:
  annotations:
    meta.upbound.io/example-id: databricks/v1alpha1/job
  labels:
    testing.upbound.io/example-name: this
  name: this
spec:
  forProvider:
    description: This job executes multiple tasks on a shared job cluster, which will
      be provisioned as part of execution, and terminated once all tasks are finished.
    jobCluster:
    - jobClusterKey: j
      newCluster:
      - nodeTypeId: ${data.databricks_node_type.smallest.id}
        numWorkers: 2
        sparkVersion: ${data.databricks_spark_version.latest.id}
    name: Job with multiple tasks
    task:
    - newCluster:
      - nodeTypeId: ${data.databricks_node_type.smallest.id}
        numWorkers: 1
        sparkVersion: ${data.databricks_spark_version.latest.id}
      notebookTask:
      - notebookPath: ${data.databricks_current_user.me.home}/AA/BB/CC
      taskKey: a
    - dependsOn:
      - taskKey: a
      existingClusterId: ${databricks_cluster.shared.id}
      sparkJarTask:
      - mainClassName: com.acme.data.Main
      taskKey: b
    - jobClusterKey: j
      notebookTask:
      - notebookPath: ${data.databricks_current_user.me.home}/AA/BB/CC
      taskKey: c
    - pipelineTask:
      - pipelineId: ${databricks_pipeline.this.id}
      taskKey: d
